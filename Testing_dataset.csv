source_text,reference_summary
"Anime is a style of animation popular in Japanese films and television series. It often combines stark, colorful graphics with action-packed plots. Early anime films were intended primarily for a Japanese audience. Therefore, they used many cultural references unique to Japan. For example, the large eyes of anime characters are commonly perceived in Japan as multifaceted “windows to the soul.” Much of anime is aimed at children, but it is sometimes marked by adult themes and subject matter. Anime developed in the early 20th century. Short anime films were produced in the late 1910s, but few have survived into the 21st century. In the early days of the film industry, the film itself was easily damaged and extremely flammable. In addition, catastrophes such as a major earthquake in 1923 and World War II destroyed both films and equipment. However, as film processes improved, so did the techniques and output.Modern anime began in 1956 and found lasting success in 1961 with the establishment of Osamu Tezuka’s Mushi Productions. Tezuka was a leading figure in modern manga. Manga is a dense Japanese comic book style that contributed greatly to anime. Tezuka wrote the manga series Tesuwan Atomu (“Mighty Atom”; 1952–68). It is a futuristic story about a robot boy and the adventures he faces. In 1963 Tezuka animated Tesuwan Atomu for television, and it became extremely popular. It was syndicated to several countries, including the United States, where it was released as Astro Boy.","Anime, a captivating style of Japanese animation, is renowned for its vivid visuals and compelling narratives. Originally crafted for a Japanese audience, early anime films featured culturally rich references, such as the symbolic use of large eyes representing the ""windows to the soul."" While primarily geared toward children, anime occasionally explores more mature themes. Its origins can be traced back to the early 20th century, surviving short films from the late 1910s. Overcoming challenges like fragile film and wartime setbacks, modern anime flourished in 1956 and gained significant traction in 1961 with the establishment of Osamu Tezuka's Mushi Productions. Tezuka, a manga pioneer, transformed his series Tesuwan Atomu into the beloved animated show Astro Boy in 1963, marking a transformative era in anime history."
"The popularity of anime only grew. By the 1980s more money was dedicated to production. Classic manga series were developed into anime. These included Dragon Ball, which follows a young boy searching for seven dragon balls. If he collects them all, he will be granted a wish. During this time technological advances allowed for tighter, more fluid animation. The 1990s saw the introduction of the Internet and DVDs, both of which helped anime reach an even broader audience. Children’s anime was a success internationally. Japanese game designer Satoshi Tajiri created Pokémon as a video game in 1996. By the next year producers were filming an anime television series involving the characters. It was exported to various countries and was still in production in the early 21st century. At the same time writers were incorporating epic folk adventures into anime. For example, Miyazaki Hayao’s Princess Mononoke (1997) weaves a story of people versus gods. In 2002 his fantasy adventure Spirited Away (2001) won an Academy Award for best animated feature film. It follows a young girl as she navigates her way through a spirit world.The first adult anime to reach a wider Western audience was Akira (1988), an apocalyptic science-fiction feature-length film. It was based on director Katsuhiro Otomo’s manga series of the same name. Anime films exported to Western countries are usually in the science fiction, fantasy, and violent action genres. Other forms include romance, soap operas, and humor. Most of them incorporate action sequences.","Anime's popularity soared in the 1980s, marked by increased production budgets and the adaptation of classic manga series like Dragon Ball. Technological advancements in animation during this era allowed for more seamless and dynamic visuals. The 1990s witnessed the advent of the Internet and DVDs, facilitating broader global access to anime, especially children's content. Pokémon, originally a video game by Satoshi Tajiri, transformed into a successful anime series exported worldwide. Simultaneously, anime embraced epic narratives, as seen in Miyazaki Hayao's Princess Mononoke (1997) and the Academy Award-winning Spirited Away (2001). Breaking ground in the Western market, Akira (1988) introduced adult-oriented anime, focusing on apocalyptic science fiction. Anime exported to the West typically falls within genres like science fiction, fantasy, and violent action, although romance, soap operas, and humor also find their place, often featuring captivating action sequences."
"The coronavirus pandemic has yielded many surprising insights for the global film and TV business. One of the most curious new facts to emerge is that Japanese anime might just be the world’s most COVID-resistant form of popular entertainment.

During the height of pandemic lockdowns in 2020, when total U.S. box office sales fell 80 percent for the year and Japan’s theatrical market slipped 45 percent, Japan’s total anime industry contracted just 3.5 percent, with a market value of about $21.3 billion (more than 2.4 trillion yen). In that same fraught year, the anime business also produced its biggest theatrical hit of all time: Demon Slayer the Movie: Mugen Train, an action-packed period fantasy that earned nearly $48 million in North America, $365 million in Japan and $504 million worldwide, becoming the biggest theatrical blockbuster of any kind in 2020 (it beat the Chinese war film The Eight Hundred, which took in $461 million in its home market). And the outsized earnings for anime have only continued. The top three titles at the Japanese box office in 2021 were all anime hits; and Jujutsu Kaisen 0, a dark fantasy anime based on a manga series of the same name by Gege Akutami, brought in $106 million there earlier this year, as well as a healthy $34 million in North America for a $187 million worldwide total.According to consultancy Parrot Analytics, global demand for anime content grew 118 percent over the past two years, making it one of the fastest-growing content genres throughout the pandemic (the firm measures its demand metric by combining consumption data with social media activity, social video and independent research).

“Even in pandemic times, still the anime market thrived,” noted Kana Koido, a partner at Japanese indie distributor The Klockworx, during a recent panel discussion at the Far East Film Festival. “Japan is such a unique market, where even though total box office in 2020 was almost half of what it had been in 2019, still there was this rare content that did better than ever.” 

Those who are tapped into Japan’s anime industry say the precursors for these boom times have been building for years. During the decade before the pandemic, from 2009 to 2019, Japan’s anime industry doubled in total market value to $22.1 billion, according to the Association of Japanese Animations.
","Japanese anime has proven remarkably resilient amid the pandemic. In 2020, while global box offices suffered, the anime industry contracted by only 3.5%, maintaining a market value of $21.3 billion. Demon Slayer the Movie: Mugen Train became the top-grossing film globally, earning $504 million. The trend persisted in 2021, with anime dominating the Japanese box office. Jujutsu Kaisen 0 exemplified this success, grossing $187 million globally. Parrot Analytics reported a 118% surge in global demand for anime content over the past two years, marking it as a pandemic-resistant genre."
"The key force behind such growth has been a widening demographic embrace of anime culture, both within Japan and among consumers virtually everywhere. Once the province only of otaku — Japan’s hard-core anime and manga fans, formerly stereotyped as socially awkward misfits too absorbed in their fantasy worlds to participate in “normal society” — anime is already far along the well-trodden path of niche subcultures that have found themselves suddenly embraced by mainstream society as the next cool thing.

“Over the past five to 10 years, in Japan and in the West, there’s almost been this anime renaissance that has happened, where it went from being this thing you would get bullied for liking to being something all kinds of people want to talk about,” says 27-year-old anime influencer Joseph Tetsuro Bizinger, who goes by Joey the Anime Man on YouTube, where his channel has grown over the past decade to 3.2 million followers. “It’s going through this motion that gaming went through in the 1990s, where if you played games you were a nerd, until suddenly everyone played games. That’s why anime films are just becoming such a massive thing. It’s not just a few nerds from your class who go see [the latest anime release] — now the entire class is going to go.”

Bizinger adds: “And I think that’s the big reason why the streaming sites are trying to get as much anime as possible, because they see the bigger potential in it now.” 

During the AnimeJapan convention in Tokyo in March, Netflix revealed that it would launch 40 new anime titles, spanning a growing range of genres, in 2022 alone. Characteristically, the streamer had data to justify the expansion: In 2021, over half of all Netflix subscribers worldwide watched at least some anime content on the platform. ","Anime's growth extends beyond otaku fandom, captivating a global mainstream audience. Once niche and associated with isolation, anime has undergone a renaissance, akin to gaming in the 1990s. Influencer Joey the Anime Man attributes this surge to broader societal acceptance. Netflix, noting the trend, plans 40 new anime titles in 2022, responding to over half of its 2021 global subscribers engaging with anime content, highlighting its widespread appeal."
"Competitive tennis play requires a combination of the major physiological variables; however, the specifics of these variables have yet to be determined appropriately. General strength and flexibility training have been suggested as being beneficial for performance and injury prevention, yet specific guidelines are lacking. This paper provides a review of specific studies that relate to competitive tennis, and highlights the need for tennis-specific training as opposed to generalised physical training. It identifies specific studies that support the premise that tennis has physiological requirements which need to be understood when designing training and research programmes.","Competitive tennis requires specific physiological training, yet current guidelines are vague. While general strength and flexibility are beneficial, this review emphasizes the need for tennis-specific training. It highlights studies demonstrating tennis's unique physiological demands, underscoring the importance of tailored training and research to enhance performance and prevent injuries, and calls for more precise training guidelines in the sport."
"Studies in anthropometry showed that more research is needed in the area of physical development and its relationship to playing tennis. Muscle activity patterns have been studied for the different strokes, although more data are available relative to the service. During the service, skilled tennis players were found to display more consistent muscular activity with shorter periods of activation, implying a higher level of coordination than less skilled players. In profiling players, positive correlations were found between tournament play and a number of fitness parameters. More research is needed to develop assessment measures that are tennis specific. Also, longitudinal studies will provide greater insight into player profiles. The general consensus on fitness development was that tennis players should incorporate flexibility, strength and endurance training in their programmes to minimise asymmetry and injuries, while simultaneously enhancing performance. Tennis was found to have both aerobic and anaerobic components, with the predominant energy supply coming from phosphagen energy system. These findings suggest training programmes should be designed specific to the actual energy and muscular demands of the game. The need for further research in all areas certainly still exists in order to gain a better understanding of the game.","This review highlights the need for more research in anthropometry and its relation to tennis, noting that skilled players show more consistent and efficient muscle activity, particularly in serving. Positive correlations exist between fitness parameters and tournament play. It emphasizes the necessity of flexibility, strength, and endurance training for injury prevention and performance enhancement. Tennis combines aerobic and anaerobic elements, primarily utilizing the phosphagen energy system, suggesting a need for game-specific training programs. Overall, further research is crucial for a deeper understanding of tennis's physical demands."
"The aim of the study was to explore the role of tennis in the promotion of health and prevention of disease. The focus was on risk factors and diseases related to a sedentary lifestyle, including low fitness levels, obesity, hyperlipidaemia, hypertension, diabetes mellitus, cardiovascular disease, and osteoporosis. A literature search was undertaken to retrieve relevant articles. Structured computer searches of PubMed, Embase, and CINAHL were undertaken, along with hand searching of key journals and reference lists to locate relevant studies published up to March 2007. These had to be cohort studies (of either cross sectional or longitudinal design), case–control studies, or experimental studies. Twenty four studies were identified that dealt with physical fitness of tennis players, including 17 on intensity of play and 16 on maximum oxygen uptake; 17 investigated the relation between tennis and (risk factors for) cardiovascular disease; and 22 examined the effect of tennis on bone health. People who choose to play tennis appear to have significant health benefits, including improved aerobic fitness, a lower body fat percentage, a more favourable lipid profile, reduced risk for developing cardiovascular disease, and improved bone health.","This study investigates tennis's role in promoting health and preventing diseases associated with sedentary lifestyles, like obesity, hypertension, and cardiovascular diseases. Analyzing 24 studies, it found that tennis enhances aerobic fitness, lowers body fat, improves lipid profiles, reduces cardiovascular disease risk, and boosts bone health. The research, encompassing various study designs, suggests significant health benefits for tennis players, indicating the sport's effectiveness in combatting lifestyle-related health issues."
"As of April 9, 2020, the coronavirus disease 2019 (COVID-19) pandemic had resulted in 1,521,252 cases and 92,798 deaths worldwide, including 459,165 cases and 16,570 deaths in the United States (1,2). Health care personnel (HCP) are essential workers defined as paid and unpaid persons serving in health care settings who have the potential for direct or indirect exposure to patients or infectious materials (3). During February 12–April 9, among 315,531 COVID-19 cases reported to CDC using a standardized form, 49,370 (16%) included data on whether the patient was a health care worker in the United States; including 9,282 (19%) who were identified as HCP. Among HCP patients with data available, the median age was 42 years (interquartile range [IQR] = 32–54 years), 6,603 (73%) were female, and 1,779 (38%) reported at least one underlying health condition. Among HCP patients with data on health care, household, and community exposures, 780 (55%) reported contact with a COVID-19 patient only in health care settings. Although 4,336 (92%) HCP patients reported having at least one symptom among fever, cough, or shortness of breath, the remaining 8% did not report any of these symptoms. Most HCP with COVID-19 (6,760, 90%) were not hospitalized; however, severe outcomes, including 27 deaths, occurred across all age groups; deaths most frequently occurred in HCP aged ≥65 years. These preliminary findings highlight that whether HCP acquire infection at work or in the community, it is necessary to protect the health and safety of this essential national workforce","As of April 9, 2020, during the COVID-19 pandemic, 9,282 (19%) of 49,370 U.S. cases with occupational data were health care personnel (HCP). They had a median age of 42, 73% were female, and 38% had underlying health conditions. Most infections occurred in health care settings, with 92% showing symptoms like fever, cough, or shortness of breath. While 90% were not hospitalized, there were severe outcomes, including 27 deaths, across all age groups, emphasizing the need to protect this essential workforce."
"laboratory-confirmed COVID-19 patient in health care, household, or community settings, the majority reported contact that occurred in health care settings. However, there were also known exposures in households and in the community, highlighting the potential for exposure in multiple settings, especially as community transmission increases. Further, transmission might come from unrecognized sources, including presymptomatic or asymptomatic persons (6,7). Together, these exposure possibilities underscore several important considerations for prevention. Done alone, contact tracing after recognized occupational exposures likely will fail to identify many HCP at risk for developing COVID-19. Additional measures that will likely reduce the risk for infected HCP transmitting the virus to colleagues and patients include screening all HCP for fever and respiratory symptoms at the beginning of their shifts, prioritizing HCP for testing, and ensuring options to discourage working while ill (e.g., flexible and nonpunitive medical leave policies). Given the evidence for presymptomatic and asymptomatic transmission (7), covering the nose and mouth (i.e., source control) is recommended in community settings where other social distancing measures are difficult to maintain.†† Assuring ¶ https://www.bls.gov/cps/tables.htm#charemp. ** https://data.census.gov/cedsci/. †† https://www.cdc.gov/coronavirus/2019-ncov/prevent-getting-sick/cloth-facecover.html. source control among all HCP, patients, and visitors in health care settings is another promising strategy for further reducing transmission. Even if everyone in a health care setting is covering their nose and mouth to contain their respiratory secretions, it is still critical that, when caring for patients, HCP continue to wear recommended personal protective equipment (PPE) (e.g., gown, N95 respirator [or facemask if N95 is not available], eye protection, and gloves for COVID-19 patient care). Training of HCP on preventive measures, including hand hygiene and PPE use, is another important safeguard against transmission in health care settings","The majority of healthcare personnel (HCP) with COVID-19 reported exposure in healthcare settings, though household and community transmissions were also significant. This highlights the risk of exposure from various sources, including presymptomatic or asymptomatic individuals. Effective prevention measures include screening HCP for symptoms, prioritizing testing, encouraging nonpunitive sick leave policies, and implementing source control like mask-wearing in community and healthcare settings. Additionally, the consistent use of personal protective equipment (PPE) and training in hygiene and PPE use are crucial for reducing transmission in healthcare environments."
"Three-dimensional (3-D) high-speed photography was used to compare different forehand techniques of high performance players. Subjects, who hit a topspin forehand drive with the hitting limb moving almost as a single unit (Gs: single-unit group), were compared with players whose individual segments of the upper limb moved relative to each other (Gm: multisegment group) when playing the same stroke. The Direct Linear Transformation method was used for 3-D space reconstruction from 2-D images recorded from laterally placed phase-locked cameras operating at 200 fps. A third Photosonics camera operating at 100 fps filmed from overhead. Significant differences between the groups were recorded at the shoulder and elbow joints at the completion of the backswing. Maximal elbow joint angular velocities occurred 0.06 sec prior to impact, with the Gm group recording a significantly higher mean value for elbow extension than the Gs group. At impact, however, the Gm group recorded a significantly higher level of elbow flexion than the Gs group and achieved a higher mean angular velocity at the wrist joint than the Gs group. The Gm group recorded a higher racket tip linear velocity at impact and higher postimpact ball velocity when compared to the Gs group. The Gm technique of racket movement produced higher racket and ball velocities for this group of high performance players","A study using 3-D high-speed photography compared forehand techniques of high-performance tennis players. Players using a single-unit arm movement (Gs group) were contrasted with those using a multi-segment technique (Gm group). Significant differences were observed at the shoulder and elbow during the backswing. The Gm group exhibited higher elbow extension velocity before impact and greater elbow flexion and wrist velocity at impact, resulting in higher racket tip and post-impact ball velocities. This indicates the multi-segment technique's effectiveness in achieving greater speed in high-performance play."
"Clinical description from coronavirus disease 2019 (COVID-19) outbreak in China reveals that most patients (81%) present with influenza-like illness (ILI) or mild pneumonia, and 19% of cases experience severe or critical pneumonia [1]. Fever, cough, fatigue, and myalgia are usually the main symptoms. The expression of COVID-19 ILI seems non-specific; no specific symptom can lead to suspecting a case without any notion of exposure [2], [3], [4], [5], [6], [7]. A major French cluster of COVID-19 began on March 1st, 2020 in the city of Mulhouse, France (less than 30 miles from our hospital). After clinical examination of the first patients, we noticed that many cases reported anosmia. The description of anosmia and other ENT symptoms is scarce with COVID-19. For instance, a recent review on COVID-19 by ENT specialists on March 26 emphasised that ENT symptoms were uncommon with COVID-19 as nasal congestion and rhinorrhea were observed in less than 5% of cases. However, they noticed that there were few reports of anosmia and dysgeusia with no real description of symptoms [8]. Recently, in April, descriptions of cases of anosmia in a multicentric cohort have been associated with COVID-19 [9], [10], [11]. We aimed to describe the prevalence and features of anosmia in COVID-19 patients.","The clinical analysis of the COVID-19 outbreak in China showed that 81% of patients presented with mild symptoms like influenza, while 19% suffered severe pneumonia. Common symptoms included fever, cough, fatigue, and myalgia, with no unique symptom indicating COVID-19 without known exposure. A significant observation from a major French COVID-19 cluster in Mulhouse was the prevalence of anosmia (loss of smell). Despite being initially considered uncommon, recent studies in April have increasingly associated anosmia with COVID-19, leading to a focus on its prevalence and characteristics in patients."
"A multicentric European study published on April 6 conducted by Lechien et al. reported 357 patients with olfactory dysfunction related to COVID-19 [11]. We mostly used this publication to discuss our results, as it is the only publication with a large cohort of patients with COVID-19-related olfactory dysfunction. The mean age of our population was 47 (± 16) years, and 67% were females. The prevalence of asthma in our study was ≥ 10% and we did not have any COPD patient, which is uncommon in patients with COVID-19. Patients with anosmia seemed to be younger with a predominance of females, they had fewer comorbidities with a lower Charlson comorbidity index (< 1), and more often presented with asthma in comparison with the population usually described with COVID-19; the same population characteristics were described by Lechien et al. Until recently, ENT symptoms had not been reported with COVID-19, except for nasal congestion and rhinorrhea [2], [3], [4], [5], [6], [7], [8]. However, 54 (47%) of our 114 COVID-19 patients reported anosmia. Lechien et al. reported anosmia in 86% (n = 357/417) of their patients. This higher frequency may be explained by their population profiles, which were ambulatory cases that consulted at ENT consultations (patients with a mean age of 37 [± 11.4] years without cardiovascular comorbidities) and for whom it is probably easier to relate functional symptoms than patients with oxygen therapy or critical patients. Anosmia was therefore a frequent symptom in COVID-19 patients in our French study and in this European study. However, few descriptions of ENT symptoms are available, especially in Asian studies. These differences between Asia and Europe should be discussed. We made several assumptions. First, the theoretical possibility of a mutation of SARS-CoV-2 viral genome associated with a clinical impact, but not yet described. On the other hand, it is difficult to precisely report ENT symptoms of critical patients. These symptoms may seem of less importance when considering the potential severity of the disease [15]. Finally, Lechien et al. discussed the affinity of SARS-CoV-2 for tissues and individual possible genetic features. Their main argument was that the angiotensin-converting enzyme 2 (as receptor of SARS-CoV-2) can be specific to an ethnic group. Anosmia was associated with dysgeusia in 85% of cases and in more than half of cases with rhinorrhea (57%). However, 70% of our patients with anosmia did not present with nasal obstruction. This leads to suspecting another pathogenesis for anosmia than mechanical nasal obstruction. In addition, anosmia during viral rhinitis with nasal obstruction usually resolves within three days [16], while we observed a mean duration of anosmia of nine days. The concept of anosmia after viral infection is known as post-infectious/post-viral olfactory loss (POL). Different kind of viruses can induce POL, including coronaviruses such as HCoV-229E [17]. However, medical literature data indicates that the duration of POL can be long: a study of 63 patients with POL reported that after one year 80% of patients had subjective recovery [18]. In our study, only one patient did not recover at the end of the study follow-up (after a follow-up of 28 days); 80% of our patients recovered within 14 days. Compared with POL, the outcome of COVID-19-related acute anosmia most frequently seems favourable in the short term. Our patients had the same other symptoms (other than ENT symptoms) as those reported in other studies [2], [3], [4], [5], [6], [7]. However, just like Lechien et al., we observed that diarrhea was reported in more than 50% of patients. Except for one study (occurrence of 33%), the occurrence of diarrhea is < 20% in the medical literature [19]. The frequency of diarrhea seems to be high in patients with anosmia. One of our study limitations was the limited number of patients. However, our study is, to our knowledge, the main monocentric cohort of confirmed COVID-19 patients with anosmia in France and in the medical literature. Our results are similar to those published by the recent multicentric European study performed by Lechien et al","A multicentric European study by Lechien et al. and our research both found a high prevalence of anosmia in COVID-19 patients, predominantly younger females with fewer comorbidities. While ENT symptoms were previously underreported, anosmia was observed in 47% of our patients and 86% in Lechien's study. Anosmia often co-occurred with dysgeusia and without nasal obstruction, suggesting a different pathogenesis. Recovery was typically within 14 days, indicating a favorable short-term outcome. Additionally, over 50% of patients with anosmia reported diarrhea, a higher frequency than generally observed in COVID-19 cases."
"There are three well described syndromes in the current SARSCoV-2 outbreak: asymptomatic, mild URTI, and severe systemic disease such as bilateral interstitial pneumonia (1). We and many others have noticed a sudden increase in presentations of an otherwise asymptomatic anosmia during the early stages of the pandemic within the UK population. This correlates with personal communication reports from colleagues in Italy and China. We present a case report of one confirmed COVID-19 positive patient with supporting evidence for a fourth syndrome of this viral infection, namely Isolated Sudden-Onset Anosmia (ISOA). Case report A 48-year-old neurosurgeon presented for telephone consultation with a sudden onset of complete anosmia over seventy two hours without any other symptoms. He was otherwise fit and well, with no comorbidities and a normal BMI. Based on the suspicions from anecdotal reports from other countries, he was advised to self-isolate. He did not develop any further symptoms but underwent PCR testing two days later, confirming SARSCoV-2 infection. He remains otherwise asymptomatic to date (six days since presentation). Other evidence In the absence of a gold standard confirmed COVID-19+ testing in an otherwise isolated sudden onset anosmia, the other evidence is circumstantial: the increase in reported and referred sudden anosmia correlating with the number of diagnosed cases of SARS-CoV-2 in the early days of the pandemic within the UK, reports on social media and the increase in searches for the topic on search engines correlating with case numbers. One of the authors has experienced a nine-fold increase in referrals for sudden onset, otherwise asymptomatic, anosmia in her rhinology practice over the last three weeks. The presentation in all of these cases is the same: complete subjective loss of smell and taste over 24 to 72 hours without other significant symptoms of an URTI.","During the early stages of the COVID-19 pandemic, a sudden increase in isolated anosmia cases was observed in the UK, mirroring reports from Italy and China. This led to identifying a potential fourth syndrome associated with SARS-CoV-2: Isolated Sudden-Onset Anosmia (ISOA). A case report of a 48-year-old asymptomatic neurosurgeon, who developed complete anosmia without other symptoms and later tested positive for COVID-19, exemplifies this syndrome. The pattern of anosmia emerging rapidly over 24 to 72 hours without other significant symptoms was commonly reported in UK cases and corroborated by increased referrals and social media discussions."
"Conclusion and recommendations We posit that there is a heretofore unrecognised syndrome of SARS-CoV-2 infection: Isolated Sudden-Onset Anosmia (ISOA). Current guidelines for self-isolation do not recognise this and at least one of the patients in the case series was given official contradictory advice to return to work which fortunately they did not comply with. They developed a full-blown syndrome within 24 hours of the anosmia, meaning they would have been at work when they would have been at peak infectiousness. Although we await further, more rigorous evidence of ISOA as a syndrome we feel that the balance of risks is such that treating sudden onset anosmia as a diagnostic symptom of SARS-CoV-2 infection in the current pandemic is warranted. We urge all healthcare practitioners with patients presenting with ISOA to treat these patients as possible COVID-19 positive with appropriate precautions and to avoid prescribing oral immunosuppressants in these cases. We similarly suggest that public health advice be updated with ISOA as the fourth syndrome of SARS-CoV-2.   ","
The study proposes recognizing Isolated Sudden-Onset Anosmia (ISOA) as a distinct SARS-CoV-2 infection syndrome, not currently acknowledged in self-isolation guidelines. Instances of ISOA developing into full COVID-19 symptoms highlight its potential as an early indicator of infection, suggesting individuals with sudden anosmia should be treated as presumptively COVID-19 positive. The authors recommend updating healthcare practices and public health advice to include ISOA as a diagnostic symptom and urge caution against prescribing oral immunosuppressants to these patients, advocating for heightened awareness and appropriate precautions."
"Travel and COVID-19 Spread Continued introductions of SARS-CoV-2 from outside the United States contributed to the initiation and acceleration of domestic COVID-19 cases in March. After Chinese authorities halted travel from Wuhan and other cities in Hubei Province on January 23, followed by U.S. restrictions on non-U.S. travelers from China issued on January 31 (effective February 2), air passenger journeys from China decreased 86%, from 505,560 in January to 70,072 in February. However, during February, 139,305 travelers arrived from Italy and 1.74 million from all Schengen countries,* where the outbreak was spreading widely and rapidly. Travelers from Italy and all Schengen countries decreased 74% to 35,877 and 50% to 862,432, respectively, in March.† Genomic analysis of outbreak strains suggested an introduction from China to the state of Washington around February 1.§ However, examination of strains collected from northern California during early February to mid-March indicated multiple introductions resulting from international travel (from China and Europe) as well as from interstate travel.¶ Sequencing of strains collected in the New York metropolitan area in March also suggested origins in Europe and other U.S. regions.** Returning cruise ship travelers also contributed to amplification during this time (3). Persons from many countries are in close contact on cruises, and crew members continue to work on ships for multiple voyages. As a result, passengers returning from cruises contributed to the early acceleration phase. For example, 101 persons who had been on nine separate Nile River cruises during February 11–March 5 returned to 18 states and had a positive test result for SARS-CoV-2, nearly doubling the total number of known COVID-19 cases in the United States at that time","
In March, the spread of COVID-19 in the U.S. was accelerated by travelers from China, Italy, and Schengen countries, despite significant decreases in air travel following travel restrictions. Genomic analyses indicated multiple virus introductions from these regions, particularly in Washington, northern California, and New York. Additionally, returning cruise ship travelers significantly contributed to the early case surge. For instance, passengers from Nile River cruises returned to 18 states, substantially increasing the U.S. case count, underscoring the role of international and interstate travel in the pandemic's spread."
"vents and Gatherings Various gatherings of persons from different locations, followed by return to their home communities, played a notable role in the early U.S. spread of COVID-19. During February 2020, the number of confirmed cases originating in the United States was low and appeared contained; thus, federal and local jurisdictions did not recommend restrictions on gatherings. However, during the last week of February, several large events led to further spread of the disease. These included Mardi Gras celebrations in Louisiana with more than 1 million attendees, an international professional conference held in Boston, Massachusetts, with approximately 175 attendees, and a funeral in Albany, Georgia, with more than 100 attendees (Figure 1). In the weeks after these events, amplifications in the host locations contributed to increasing U.S. case counts (5). Dougherty County, Georgia, a small rural county that includes Albany, had one of the highest cumulative incidences of COVID-19 (1,630/100,000 population) in the country. The substantial transmissibility of the virus and severity of COVID-19 triggered a series of recommendations, beginning in mid-March, to limit mass gatherings and travel (Table). Go to: Workplaces and Settings Contributing to Accelerated Spread Skilled nursing and long-term care facilities (6) and hospitals (7) are settings in which persons at higher risk for severe COVID-19 illness are in close contact with staff members, many of whom work at multiple facilities. Other workplaces also facilitated amplification of virus transmission, including critical infrastructure sectors, such as multiple meat packing facilities in rural areas. Clusters of cases related to religious service attendance have been reported within the United States and worldwide (8). Congregate, high-density settings also might contribute to the spread of COVID-19 (9). For example, population density might account for the very high numbers of COVID-19 cases in the New York metropolitan area (Box). Public health actions aimed at reducing COVID-19 spread in high-risk settings have focused on infection control measures, including identifying and isolating ill persons, cleaning and disinfection, restricting visitors, physical distancing through shift work, and appropriate use of personal protective equipment (Table). To protect health care capacity and slow community spread of COVID-19, local, state, and federal authorities issued stay-at-home orders, and closed schools and nonessential workplaces. On April 3, CDC issued guidance for use of cloth face coverings in public areas to reduce spread, based on increasing evidence of transmission in the absence of symptoms","
In the U.S., early COVID-19 spread was significantly influenced by events and gatherings, such as Mardi Gras in Louisiana, a conference in Boston, and a funeral in Albany, Georgia. These events led to notable case amplifications. Workplaces, particularly in healthcare, long-term care, and meatpacking facilities, also accelerated spread. High-density areas like New York experienced a surge in cases. Public health measures, including stay-at-home orders, school closures, and guidance for cloth face coverings, were implemented to control the spread, especially in high-risk settings."
"BACKGROUND: Although several therapeutic agents have been evaluated for the treatment of coronavirus disease 2019 (Covid-19), no antiviral agents have yet been shown to be efficacious. METHODS: We conducted a double-blind, randomized, placebo-controlled trial of intravenous remdesivir in adults who were hospitalized with Covid-19 and had evidence of lower respiratory tract infection. Patients were randomly assigned to receive either remdesivir (200 mg loading dose on day 1, followed by 100 mg daily for up to 9 additional days) or placebo for up to 10 days. The primary outcome was the time to recovery, defined by either discharge from the hospital or hospitalization for infection-control purposes only. RESULTS: A total of 1062 patients underwent randomization (with 541 assigned to remdesivir and 521 to placebo). Those who received remdesivir had a median recovery time of 10 days (95% confidence interval [CI], 9 to 11), as compared with 15 days (95% CI, 13 to 18) among those who received placebo (rate ratio for recovery, 1.29; 95% CI, 1.12 to 1.49; P<0.001, by a log-rank test). In an analysis that used a proportional-odds model with an eight-category ordinal scale, the patients who received remdesivir were found to be more likely than those who received placebo to have clinical improvement at day 15 (odds ratio, 1.5; 95% CI, 1.2 to 1.9, after adjustment for actual disease severity). The Kaplan–Meier estimates of mortality were 6.7% with remdesivir and 11.9% with placebo by day 15 and 11.4% with remdesivir and 15.2% with placebo by day 29 (hazard ratio, 0.73; 95% CI, 0.52 to 1.03). Serious adverse events were reported in 131 of the 532 patients who received remdesivir (24.6%) and in 163 of the 516 patients who received placebo (31.6%). CONCLUSIONS: Our data show that remdesivir was superior to placebo in shortening the time to recovery in adults who were hospitalized with Covid-19 and had evidence of lower respiratory tract infection. (Funded by the National Institute of Allergy and Infectious Diseases and others; ACTT-1 ClinicalTrials.gov number, NCT04280705. opens in new tab.)","
A double-blind, randomized, placebo-controlled trial evaluated the efficacy of remdesivir in 1062 hospitalized adults with COVID-19 and lower respiratory tract infection. Patients receiving remdesivir had a median recovery time of 10 days, compared to 15 days for those on placebo. Remdesivir also showed a lower mortality rate and a higher likelihood of clinical improvement by day 15. While serious adverse events were reported in 24.6% of remdesivir patients versus 31.6% for placebo, the study concluded that remdesivir significantly shortened recovery time in hospitalized COVID-19 patients with lower respiratory tract infection."
"Abstract Oil cakes have been in use for feed applications to poultry, fish and swine industry. Being rich in protein, some of these have also been considered ideal for food supplementation. However, with increasing emphasis on cost reduction of industrial processes and value addition to agro-industrial residues, oil cakes could be ideal source of proteinaceous nutrients and as support matrix for various biotechnological processes. Several oil cakes, in particular edible oil cakes offer potential benefits when utilized as substrate for bioprocesses. These have been utilized for fermentative production of enzymes, antibiotics, mushrooms, etc. Biotechnological applications of oil cakes also include their usages for vitamins and antioxidants production. This review discusses various applications of oil cakes in fermentation and biotechnological processes, their value addition by implementation in feed and energy source (for the production of biogas, bio-oil) as well. Introduction There has been an increased exploitation of organic residues from various sectors of agriculture and industries over the past few decades. Crop residues such as bran, husk, bagasse, and fruit seeds are utilised as a potential raw material in bioprocesses as they provide an excellent substratum for the growth of microorganism supplying the essential nutrients to them (Pandey and Soccol, 1998, Pandey and Soccol, 2000, Pandey, 1994, Pandey et al., 2000a, Pandey et al., 2000b, Pandey et al., 2000c, Pandey et al., 2000d, Pandey et al., 1999a, Pandey, 1992). Their application in bioprocesses also offers advantages in bioremediation and biological detoxification of hazardous compounds. Their application in the field of fermentation technology has resulted in the production of bulk-chemicals and value-added products such as amino acid, enzymes, mushrooms, organic acids, single-cell protein (SCP), biologically active secondary metabolites, etc. (Pandey, 2003, Pandey et al., 1999a, Pandey et al., 1999b, Soccol et al., 2005, Nampoothiri et al., 2002, Vandenberghe et al., 2000). This review focuses on the various process related to the value-addition of oil cakes (residue obtained after oil extraction) by their utilisation in bioprocesses for the production of industrial bio-products. Biotechnological applications of sunflower oil cake (SuOC), sesame oil cake (SOC), soy bean cake (SBC), coconut oil cake (COC), mustard oil cake (MOC), palm kernel cake (PKC), groundnut oil cake (GOC), cottonseed cake (CSC), canola oil cake (CaOC), olive oil cake (OOC), rapeseed cake (RSC) is emphasised in detail.","This review highlights the increasing use of oil cakes, a byproduct of oil extraction, in various biotechnological and fermentation processes. Rich in protein, these cakes are valuable for feed applications in poultry, fish, and swine industries and for food supplementation. Their utilization extends to the fermentative production of enzymes, antibiotics, vitamins, antioxidants, and mushrooms. The review focuses on different oil cakes like sunflower, sesame, soybean, coconut, and others, emphasizing their role in value addition and their potential as a sustainable source of nutrients for microbial growth, contributing to bioprocesses for industrial bio-products."
"Chemical composition of oil cakes The composition and nutritional availability of oil cakes widely vary based on the quality of the seed or nuts, method of oil extraction, storage parameters, etc. The chemical composition of the oil cakes was widely studied by many authors and some of them are given in Table 1. SBC has rich amino acid profile. It is an excellent source of amino acids such as tryptophan, threonine and lysine but is deficient in methionine. SuOC has about 27% crude protein while dehulled SuOC has high protein Biotechnological applications of oil cake Oil cakes have been widely used for the production of industrial enzymes, antibiotics, biopesticides, vitamins and other biochemicals. They have also been commonly used as feed supplement. Table 3 shows some important applications of oil cakes. As growth supplement for nematodes The media containing linseed oil-cake agar, mustard oil-cake agar, neem oil-cake agar, beef extract agar, Emerson agar and YPSS agar were used for growing an endoparasite of nematodes. In general, maximum radial growth of most of the isolates was recorded on linseed oil-cake agar medium, whereas neem oil-cake agar medium supported least growth of all the isolates of C. anguillulae. Linseed oil-cake agar medium also maintained the typical characters of the fungus and clear visibility of Conclusions Oil cakes are rich in fibre, protein and energy contents. They offer potential benefits when used as substrates in developing bioprocesses for the production of organic chemicals and biomolecules. Studies using them for the production of industrial enzymes have shown promising results. Mixed substrate fermentation has been more advantageous for such applications. While edible oil cakes are used as feed source and protein hydrolysate, some of the non-edible cakes find its application a","Oil cakes, derived from various seeds and nuts, have diverse chemical compositions and are rich in proteins and amino acids. They are increasingly utilized in biotechnological applications for producing industrial enzymes, antibiotics, biopesticides, vitamins, and other biochemicals. Oil cakes also serve as effective growth supplements for nematodes and other microorganisms. Studies highlight their potential as substrates in bioprocesses for organic chemical production, with mixed substrate fermentation showing particular promise. Edible oil cakes are used as feed supplements, while non-edible varieties find applications in other biotechnological processes, showcasing their versatility and utility in various industrial sectors."
"Supplementing the rice straw substrate colonized by the mushroom, Pleurotus sajor-caju, with powdered oil seed cakes (mustard, niger, sunflower, cotton, and soyabean) increased the mushroom yields between 50 and 100%, compared to the unsupplemented substrate. Oil seed cake supplementation also effected an increase in the solubility of the rice straw substrate; there was an increase in the contents of free sugars and amino acids, and a decrease in cellulo-hemicellulosics. Correspondingly, there was also an increase in the activities of carboxymethylcellulase, hemicellulase, and protease. In vitro dry matter enzymatic digestibility measured by two-step enzymatic digestibility of the spent straw (material remaining from the straw substrate, supplemented with the oil seed cakes), indicated a significant increase over that of the spent straw derived from the unsupplemented lot.","Supplementing rice straw substrates with powdered oil seed cakes (mustard, niger, sunflower, cotton, and soyabean) significantly enhanced the yield of Pleurotus sajor-caju mushrooms, increasing yields by 50 to 100%. This supplementation also improved the solubility of rice straw, leading to higher levels of free sugars and amino acids, and a reduction in cellulo-hemicellulosics. Enzymatic activities of carboxymethylcellulase, hemicellulase, and protease also increased"
"The in vitro growth of Ganoderma mycelia on six agro-wastes namely, broad bean stalks (BBS), cotton stalk (CS), maize straw (MS), rice straw (RS), sugarcane bagasse (SCB) and wheat straw (WS) supplemented with wheat bran (WB) or corn gluten (CG) was evaluated. Among the substrates used, CS appeared best followed by SCB and RS. WB showed best supplementation for mycelial growth. CO2 emission values exhibited accurate measurements to decide the suitability of such agro-waste for growth rather than visual observations. CS+RS+SCB+WB in combination proven its superiority for in vitro growth and active spawn development substrate. In mushroom house, this particular formula proved its superiority and was on par with recommended EG formula; it gave the highest yield (195.16 g Kg−1), biological efficiency (19.52%), protein (16.69%), polysaccharides (3.613%) and minerals (3433 mg/100 g). Spawn running period was the shortest in treatments inoculated with agro-waste-based spawns. With 40% biochar, days required to the complete mycelium colonization and fructification were 10.60 and 23.00, respectively. At 10% biochar, highest yields (238.40 g Kg−1), biological efficiencies (23.84%), protein (19.58%) and minerals (4092 mg/100 g) were obtained. The higher the biochar level, the higher the reduction in emitted CO2, the loss in C and the increase in N of Ganoderma post mushroom substrates (GPMSs). Under greenhouse conditions, almost all the tested GPMSs, at 0.125 or 0.25%, encouraged the reproduction of reniform nematodes and improved plant growth criteria.","
This study evaluated the in vitro growth of Ganoderma mycelia using various agro-wastes (broad bean stalks, cotton stalk, maize straw, rice straw, sugarcane bagasse, wheat straw) supplemented with wheat bran or corn gluten. Cotton stalk, when combined with rice straw, sugarcane bagasse, and wheat bran, showed superior growth and active spawn development, matching the performance of the standard EG formula in mushroom cultivation. Optimal results in yield, biological efficiency, protein content, polysaccharides, and minerals were achieved using 10% biochar. Higher levels of biochar led to reduced CO2 emissions and altered carbon and nitrogen content in the post-mushroom substrates. "
"A study was carried out to compare the compositing efficiency of spent litter (a mixture of partially decomposed pig manure and sawdust) in turned and forced-aerated piles. Duplicate piles were built with manual turning (every 4 days) during composting, and duplicate piles were set up with forced aeration using an air pump. The present study demonstrated that the efficiency of composting in the turned and forced-aerated piles was similar. Spent litter in these piles reached maturity at the same time (60 days). The forced-aerated piles went through similar physical, chemical, and microbial changes with the turned piles during composting. The forced-aerated composting system was also as effective as the turned system in eliminating Salmonella sp. in the spent litter. These results suggest that a forced-aerated composting system could be used as an alternative method in composting spent litter. The similarities in temporal changes in temperature, chemical, and microbiological properties of the forced-aerated piles, compared with the turned piles, indicate that addition of a bulking agent under forced aerated composting of spent litter is not necessary. The partially decomposed sawdust in the spent litter provided enough free air space, allowing the delivery of oxygen for the microorganisms in the spent litter piles.","
A study comparing composting methods of spent litter (mix of decomposed pig manure and sawdust) found that both turned and forced-aerated systems are similarly efficient. Both reached maturity in 60 days, underwent comparable physical, chemical, and microbial changes, and effectively eliminated Salmonella sp. The forced-aerated system, using an air pump, proved to be a viable alternative to manual turning, with the decomposed sawdust in the spent litter providing sufficient air space for microbial oxygenation, thereby negating the need for additional bulking agents."
"Spent litter (a mixture of partially composted pig manure and sawdust) was taken from pig pens employing the pig-on-litter system with and without the addition of a commercial bacterial product (Odor control (OC)-organic fertilizers (OF)). A duplicate series of windrows was set up with spent litter which contained the bacterial product and a further duplicate series was set up with spent litter which did not contain the bacterial product. All four sets had their initial moisture content adjusted to 60% but one of each duplicate pair had its moisture content adjusted to 60% during the entire period of further composting in windrows. The rate of further (windrow) composting was significantly different in the litter which contained no bacterial product and which only had its moisture content adjusted at the beginning of the experiment. Decomposition was incomplete in this set even after day 91. In the three other sets, the rate of decomposition was faster and the spent litter became stabilised by day 56. This result suggests that if the bacterial product has been added during the initial pig-on-litter composting process, moisture adjustment during further (windrow) composting is not important. Conversely, if moisture was adjusted during further composting, the addition of bacterial product during initial pig-on-litter composting would be of no value. Such a finding is of remarkable significance in the further composting of spent litter since this indicates that the process could be run on a much more economical basis.","
In a study comparing composting methods of spent litter from pig pens, the addition of a commercial bacterial product and moisture adjustment were evaluated. Spent litter with the bacterial product showed faster decomposition and stabilization by day 56, regardless of continuous moisture adjustment. However, litter without the bacterial product and only initial moisture adjustment decomposed incompletely even after 91 days. This suggests that adding the bacterial product during initial composting is crucial for efficient decomposition, rendering continuous moisture adjustment unnecessary. This finding indicates potential for a more economical composting process of spent litter."
"MSW) compost contains a significant amount of humic substances. In this study, the compost consisted of residual MSW with the metal, plastic and glass removed. In order to enhance degradation processes and the degree of composting humification, complex microorganisms (Bacillus casei, Lactobacillus buchneri and Candida rugopelliculosa) and ligno-cellulolytic (Trichoderma and White-rot fungi) microorganisms were respectively inoculated in the composting process. During the MSW composting, humic acid (HA) was extracted and purified. Elements (C, N, H, O) and spectroscopic characteristics of the HA were determined using elementary analyzer, UV, Fourier transform infrared (FTIR), and fluorescence spectroscopy. The elements analysis, UV, FTIR and fluorescence spectra all led to the same conclusion, that is inoculations with microbes led to a greater degree of aromatization of HA than in the control process (CK) with no inoculation microbes. This indicated that inoculation with microbes in composting would improve the degree humification and maturation processes, in the following order: lingo-cellulolytic > complex microorganisms > CK. And mixed inoculation of MSW with complex microorganisms and lingo-cellulolytic during composting gave a greater degree of HA aromatization than inoculation with complex microorganisms or lingo-cellulolytic alone. But comparing with the HA of soil, the HA of MSW compost revealed a lower degree of aromatization.","This study explored enhancing municipal solid waste (MSW) composting by inoculating it with complex (Bacillus casei, Lactobacillus buchneri, Candida rugopelliculosa) and ligno-cellulolytic (Trichoderma, White-rot fungi) microorganisms. Humic acid (HA) extracted from the compost showed greater aromatization when inoculated with these microbes, compared to the control with no inoculation. Mixed inoculation resulted in the highest degree of HA aromatization, though it was still lower than soil HA. This indicates that microbial inoculation can significantly improve the humification and maturation process of MSW composting."
"Poor management of crop residues leads to environmental pollution and composting is a sustainable practice for addressing the challenge. However, knowledge about composting with pure crop straw is still limited, which is a novel and feasible composting strategy. In this study, pure corn straw was in-situ composted for better management. Community structure of β-glucosidase-producing microorganisms during composting was deciphered using high-throughput sequencing. Results showed that the compost was mature with organic matter content of 37.83% and pH value of 7.36 and pure corn straw could be composted successfully. Cooling phase was major period for cellulose degradation with the highest β-glucosidase activity (476.25 μmol·p-Nitr/kg·dw·min) and microbial diversity (Shannon index, 3.63; Chao1 index, 500.81). Significant compositional succession was observed in the functional communities during composting with Streptomyces (14.32%), Trichoderma (13.85%) and Agromyces (11.68%) as dominant genera. β-Glucosidase-producing bacteria and fungi worked synergistically as a network to degrade cellulose with Streptomyces (0.3045**) as the key community revealed by multi-interaction analysis. Organic matter (−0.415***) and temperature (−0.327***) were key environmental parameters regulating cellulose degradation via influencing β-glucosidase-producing communities, and β-glucosidase played a key role in mediating this process. The above results indicated that responses of β-glucosidase-producing microorganisms to cellulose degradation were reflected at both network and individual levels and multi-interaction analysis could better explain the relationship between variables concerning composting cellulose degradation. The work is of significance for understanding cellulose degradation microbial communities and process during composting of pure corn straw.","
This study focuses on composting pure corn straw, using high-throughput sequencing to analyze the community structure of β-glucosidase-producing microorganisms. The compost matured successfully with significant cellulose degradation during the cooling phase, indicated by high β-glucosidase activity and microbial diversity. Streptomyces, Trichoderma, and Agromyces were dominant in the compost's microbial community. Multi-interaction analysis revealed Streptomyces as a key player in cellulose degradation, influenced by organic matter and temperature. This research provides insights into the microbial processes and community dynamics involved in composting cellulose degradation, particularly in pure corn straw composting."
"Lignocellulosic crop residues (LCCRs) are produced in large quantities worldwide and are effective carbon-rich materials for the production of soil conditioners. However, in many countries, LCCRs are frequently burnt after harvest to facilitate land preparation, which causes massive environmental pollution and loss of plant nutrients (Kim Oanh et al., 2018). The incorporation of LCCRs into soil reduces the amount of plant-available nitrogen as the microbial biomass which develops during decomposition of the lignocellulosic plant material needs more nitrogen than the amount that is provided by the substrate and the final breakdown products of LCCRs tend to be phytotoxic (Ocio et al., 1991). In most developing countries, LCCRs are commonly used as a part of feeding ingredients for the ruminants. However, they have a low nutritional value due to their poor digestibility, nitrogen deficiency and high levels of anti-nutritional components (lignin and silica) (Van Soest, 2006; Aquino et al., 2020). The most commonly used practice to increase the nutritive value of LCCRs is treatment of the LCCRs with chemicals such as urea, ammonia or sodium hydroxide (Aquino et al., 2020), with sodium hydroxide being recommended by the Food and Agriculture Organization (FAO) (2008). However, these chemicals are expensive and hazardous, and can cause a variety of environmental effects such as sodium contamination of the soil coupled with air pollution and water pollution (Liu et al., 1999). The search for cost-effective, fast, and sustainable alternative processes for the better management of LCCRs to solve environmental issues is therefore of paramount importance and one of the greatest challenges in agriculture. Aerobic composting has been extensively studied and the results have shown that it can be an eco-sustainable green approach for LCCR treatment and agricultural development. The bulk of research on aerobic composting can be found on the Web of Science Core Collection database (Fig. 1). This natural bioprocess enhances the long-term sustainability of agriculture by converting agriculture wastes into nutrient-rich compost (Kausar et al., 2016). Furthermore, the compost can be applied as a soil conditioner, organic fertilizer, and plant growth stimulator, thus reducing dependence on chemical fertilizers for crop production. The results of recent research on compost application have shown the positive effects of compost use on the environmental resilience and climate adaptation, that has been observed as improved plant growth, stabilization of soils, and reduced air pollution and water pollution (Lim et al., 2016; Xia Guo et al., 2019). The compost should be highly mature and stable in order to be used safely in agriculture without adverse effects on plants. Immature compost may produce phytotoxic compounds that may disrupt seed germination and plant growth (Makan, 2015). The ordinary composting of LCCRs is intensely dilatory due to the low nitrogen content of the carbon-rich LCCRs. This limitation can be overcome by using microorganisms with both nitrogen-fixing and cellulose-degrading properties (Yu et al., 2017). Numerous nitrogen-fixing bacteria such as Azomonas agilis, Stenotrophomonas spp., Bacillus spp., Streptomyces spp., Pseudomonas spp., Paenibacillus azotofixans, and Gluconacetobacter spp. (Table 2) produce lignocellulolytic enzymes (Leschine et al., 1988; Kyaw et al., 2018; Latt et al., 2018). Furthermore, the inoculation of two cellulolytic nitrogen-fixing Bacillus strains in composting of rice straw has been shown to reduce the composting time by 40%–43% and increased the levels of total nitrogen, phosphorus, and potassium in the compost (Abdel-Rahman et al., 2016). Additionally, the application of different bacterial agents with both cellulolytic and nitrogen-fixing properties has been shown to boost lignocellulose degradation by increasing the activities of key enzymes during straw composting (Wei et al., 2019). Unlike a fungal consortium, cellulolytic nitrogen-fixing bacteria (CNFB) do not need a nitrogen (N2) source partner as they have the ability to satisfy their nitrogen requirements through fixation of atmospheric N2 (Leschine and Canale-Parola, 1989). The completion of a composting process and subsequent use of the compost as a soil conditioner are extremely reliant on the capacity of the microflora present during the composting process. The addition of CNFB to the composting material showed several benefits in different domains like agriculture and waste management (Wei et al., 2019; Kausar et al., 2011; Abdulla, 2007). Despite large number of past reviews on organic waste composting, this study is the first to present a detailed and comprehensive review of the potential application of CNFB in LCCR composting. Thus, various studies on CNFB, including screening of the microorganisms and methods for essays on the enzyme activity, have been reviewed. In addition, the effectiveness of compost application in sustainable agriculture has been discussed","
This comprehensive review addresses the management of lignocellulosic crop residues (LCCRs) and their environmental impact. Commonly burnt post-harvest, causing pollution and nutrient loss, LCCRs are also used as low-nutrition ruminant feed. Chemical treatments like sodium hydroxide improve their nutritional value but pose environmental risks. Aerobic composting emerges as a sustainable alternative, transforming LCCRs into nutrient-rich compost for soil conditioning and reducing chemical fertilizer reliance. The key innovation is using cellulolytic nitrogen-fixing bacteria (CNFB), which accelerates composting and enhances nutrient content. This eco-friendly approach benefits both agriculture and waste management, emphasizing the importance of mature, stable compost for avoiding phytotoxic effects."
"ignocellulosic crop residue composting by CNFB Studies have revealed that key microorganisms involved in nitrogen transformation during the composting process are mostly cellulose-decomposing bacteria. Nitrogen-fixing bacterial genera, such as Stenotrophomonas, Xanthomonas, Pseudomonas, Klebsiella, Alcaligenes, Achromobacter, and Caulobacter, isolated from the compost materials (Pepe et al., 2013), have been previously described to be involved in organic matter degradation during composting (Insam and de Bertoldi, 2007). While composting Some applications of compost in sustainable agriculture Compost is the final product of aerobic microbial decomposition of biodegradable materials. While chemical fertilizers improve the soil only by adding nutrients, the use of mature compost in agriculture improves the soil's organic matter content, resistance to soil erosion, groundwater keeping ability, carbon sequestration, nutrient content, and plant disease resistance (Pergola et al., 2018). Compost is a natural, safe and environment-friendly option for the recovery of organic fertility in the Conclusions and future perspectives Inoculation of compost materials with CNFB has been shown to be the most environment-friendly and the quickest way to recycle lignocellulosic biomass back into the soil and enhance the physicochemical properties and the biological properties of the soil. Bacteria with both cellulolytic and nitrogen-fixing traits reduce the overall time required for composting, and accelerate the composting performance of the lignocellulosic waste by decreasing the C/N ratio, reducing odors and adding more value","In summary, inoculating compost with cellulose-decomposing and nitrogen-fixing bacteria (CNFB) offers an efficient and eco-friendly method to recycle lignocellulosic biomass into soil, enhancing its properties. This technique speeds up composting, optimizes the carbon-to-nitrogen ratio, minimizes odors, and adds value. Its use in sustainable agriculture improves soil quality, boosts nutrient content, and increases resistance to erosion, benefiting both the environment and agricultural productivity."
"Various agricultural and kitchen waste residues were assessed for their ability to support the production of a complete cellulase system by Aspergillus niger NS-2 in solid state fermentation. Untreated as well as acid and base-pretreated substrates including corn cobs, carrot peelings, composite, grass, leaves, orange peelings, pineapple peelings, potato peelings, rice husk, sugarcane bagasse, saw dust, wheat bran, wheat straw, simply moistened with water, were found to be well suited for the organism’s growth, producing good amounts of cellulases after 96 h without the supplementation of additional nutritional sources. Yields of cellulases were higher in alkali treated substrates as compared to acid treated and untreated substrates except in wheat bran. Of all the substrates tested, wheat bran appeared to be the best suited substrate producing appreciable yields of CMCase, FPase and β-glucosidase at the levels of 310, 17 and 33 U/g dry substrate respectively. An evaluation of various environmental parameters demonstrated that appreciable levels of cellulases could be produced over a wide range of temperatures (20–50 °C) and pH levels (3.0–8.0) with a 1:1.5 to 1:1.75 substrate to moisture ratio","In a study exploring solid-state fermentation, Aspergillus niger NS-2 was found to efficiently produce cellulases using various agricultural and kitchen wastes, including corn cobs, carrot and potato peelings, grass, and more. The organism thrived on these substrates, particularly wheat bran, without needing additional nutrients, achieving high enzyme yields especially in alkali-treated materials. Cellulase production was effective across a broad temperature range (20-50 °C) and pH levels (3.0-8.0), with optimal substrate-to-moisture ratios between 1:1.5 and 1:1.75, demonstrating a versatile and sustainable method for enzyme production."
"During the last few decades, interest in the use of lignocellulosic residues for biofuel production has increased due to their relative abundance, renewable nature and availability as almost zero cost substrates. Cellulose, the main component of lignocellulosic biomass, has attracted worldwide attention in its capacity to produce greener and cleaner fuels by producing fermentable sugars that can then be converted to second-generation bioethanol. The bioconversion of cellulose to fermentable sugars requires the synergistic action of complete cellulase system comprising of endoglucanases (EC 3.2.1.4) which act randomly on soluble and insoluble cellulose chains, exoglucanases (cellobiohydrolases; EC 3.2.1.91) which liberate cellobiose from the reducing and non-reducing ends of cellulose chains, and β-glucosidases (EC 3.2.1.21) which liberate glucose from cellobiose (Milala et al., 2005, Bansal et al., 2011, Deswal et al., 2011). The costs of cellulase account for more than 40% of the total processing cost (Ahamed and Vermette, 2008, Deswal et al., 2011). The availability of low-cost cellulases could be one solution to meet the increasing demand of biofuels. Hence, the use of low-cost technologies as well as cheaper substrates can help to reduce cellulase prices. Moreover, the ability of some microorganisms to make use of lignocellulosic substrates as their growth medium to produce cellulases can make the bioconversions more economically viable. Cellulases are produced by several microorganisms including bacteria, actinomycetes and fungi, but the latter are of great interest because they excrete their enzymes extracellularly (Bollok and Reczey, 2005). Trichoderma reesei is the most efficient producer of endo- and exo-glucanases (Miettinen-Oinnonen and Suominen, 2002), but does not excrete a sufficient amount of β-glucosidase (Bollok and Reczey, 2005) for which Aspergillus strains are known to be good producers (Juhasz et al., 2003). The major obstacle to using cellulosic residues for biofuel production is the recalcitrant nature, low yields and high cost of cellulases. The recalcitrant nature can be overcome by physical, chemical and thermal pretreatments while the enzyme yields can be enhanced by exploring the diverse environments for efficient natural microbial variants or tailoring the existing strains. On the other hand, the enzyme production costs can be reduced by adopting suitable fermentation processes that employ cheap and waste cellulosic residues as the inducers. Taking into consideration all the above mentioned problems, scientific dedication targets the economy of the cellulase production. Both solid and liquid fermentation systems have been used for enzyme production, but the former has greater advantages as it requires less capital, lower energy, a simple fermentation medium, has superior productivity, does not require a rigorous control of fermentation parameters and produces less wastewater. Moreover, an easy control of bacterial contamination and lower costs of downstream processing make it more attractive (Pandey, 1994, Krishna, 2005, Sherief et al., 2010). Solid state fermentation (SSF) when carried out with different agricultural and kitchen waste residues adds value by decreasing the cost of enzyme production, reducing the quantity of solid waste and boosting the environmentally friendly management of agricultural and domestic wastes including corn cobs, carrot peelings, composite, grass, leaves, orange peelings, pineapple peelings, potato peelings, rice husk, sugarcane baggage, saw dust, wheat bran, wheat straw, which are increasing as a result of the rising population (da Silva et al., 2005, Bansal et al., 2011). The Aspergillus species are known to use a broad range of lignocellulosic substrates (Lockington et al., 2002, Kang et al., 2004, Wang et al., 2006, Gao et al., 2008) for the production of cellulases. In the present work, focus was placed on the production of complete cellulase complex from locally isolated Aspergillus niger under SSF on different agricultural and kitchen waste residues","The rising interest in using lignocellulosic residues for biofuel production stems from their abundance and renewable nature. Cellulose, a key component of these residues, is central to producing second-generation bioethanol. The high cost of cellulase, crucial for converting cellulose to fermentable sugars, poses a challenge. Emphasizing cost-effective production, research focuses on fungi like Aspergillus niger for cellulase production using solid state fermentation (SSF) on agricultural and kitchen wastes. This approach promises lower costs, reduced waste, and sustainable biofuel production, addressing both economic and environmental concerns."
"Lignocellulosic crop residues (LCCRs) mean biomass left in the field once economic components are harvested from crops. During crop harvest periods, vast quantities of crop residues are produced annually in the form of cereal straws, sugarcane leaves and woody stalks. The LCCRs are generally used as animal feed, rural homes and shed thatching, domestic and industrial fuel, etc. (Gupta et al., 2017). Even after the consumption of CR for these activities, a significant portion of total production is dumped in the field or burnt. Proper disposal of this significant chunk of LCCRs is a great challenge. Farmers, especially in the developing countries, prefer burning, as it clears the field rapidly and economically, allowing tillage and land preparation easily for the next crop. Burning agricultural residues emits air pollutants such as carbon-di-oxide (CO2), nitrous oxide (N2O), methane (CH4), carbon monoxide (CO), Ammonia (NH3), nitrogen oxides (NOx), sulphur-di-oxide (SO2), non-methane hydrocarbons, volatile and semi-volatile organic compounds and particulate matter (Mittal et al., 2009; Zhang et al., 2011). The crop residues can be used as livestock fodder, media for mushroom cultivation or can be incorporated into the field. These can also be utilized for the production of compost, biogas, biochar or biofuel (Goswami et al., 2020). Out of these methods, the on-field or in-situ residue retention is a better option as it handles a large quantity of residue with additional benefits of improving soil's physical properties and reducing soil erosion (Garg, 2017). The crop residue retention recycles crucial carbon content and nutrients in the soil, boosting the soil microbial biomass and moisture retention capacity, thereby increasing the soil fertility (Chen et al., 2017). The optimized practice of crop residue retention not only helps in soil water and nutrients conservation but also maintains crop productivity in the agro-ecosystem (Li and Delvaux, 2019). Complete removal of crop residue from the field is harmful to the soil quality, whereas leaving excessive amounts can affect seed-soil contact, increases the carbon: nitrogen (C: N) ratio and keep the soil cool and wet (Clay et al., 2019). Hence this technique has to be adopted with a balanced approach following proper mixing of residue in soil and timely application of nitrogen to maintain the C: N ratio of soil. For the breakdown of lignocellulose components, the synergistic action of several enzyme families secreted by the lignocellulose degrading microorganisms (LCDMOs) is required. These enzymes act as a cocktail executing multiple complementary and synchronized oxidative, hydrolytic and non-hydrolytic activities (Madeira et al., 2017; Payne et al., 2015). Numerous reviews on the conversion of LCCRs into biofuel and some on enzymatic activities related to a particular or a group of microorganisms are available (Gupta et al., 2016; Lal, 2005; Prasad et al., 2019; Wan and Li, 2012). However, a specific review of the earlier works related to the entire LCDMOs and associated enzymatic activities, solely and in consortia, is not yet available. This review puts up a critical discussion on the previous studies unveiling the diverse potential of LCDMOs along with the factors favouring the rapid decomposition and key researchable issues in this line, which will surely help researchers in planning and executing future work","Lignocellulosic crop residues (LCCRs), such as cereal straws and sugarcane leaves, are often underutilized or burned, causing environmental harm. Alternatives like livestock fodder, compost, and biofuel production offer sustainable uses. On-field retention improves soil quality by recycling carbon and nutrients, enhancing microbial biomass, and conserving water. However, it requires a balanced approach to avoid soil quality degradation. The decomposition of LCCRs for biofuel involves enzymes from lignocellulose-degrading microorganisms (LCDMOs). Research gaps exist in understanding the complete potential of LCDMOs and their enzymatic activities, highlighting areas for future studies in this field."
"Introduction Bakery products such as cakes are widely consumed all over the world; hence, their enrichment with vitamins, minerals, polyphenols and fibers is considered as an effective way to produce high nutritional value foods. Achieving this goal is possible using fruits and vegetables in the formulation of food products. As FAO (2019) reported, losses of food amount US$310 billion and US$680 billion respectively in developing and industrialized countries which consists of waste of root crops, fruits and vegetables (40–50%). Because of having high moisture content, fruits and vegetables are so perishable; thus, the use of various preservation methods is necessary to increase their shelf life and reduce the waste of agricultural products, cost of disposal and environmental problem (Cassano, Figoli, Tagarelli, Sindona, & Drioli, 2006; Salehi, 2019c, 2019d). Producing various fruit or vegetable based food by-products can be an operative solution for controlling of this loss (Salehi, 2017; Salehi, Kashaninejad, & Jafarianlari, 2017). As shown in Fig. 1, after slicing the fruits and vegetables, drying treatments are used to reduce the water activity of the fresh ones and also manufacturing new food products such as powder of fruits and vegetable (Salehi, Kashaninejad, Akbari, Sobhani, & Asadi, 2016). Powder of the dried fruits and vegetables is known as a good source of nutrients for bakery products. Different mechanical and chemical methods are used in food industries to reduce the moisture content of the waste of the fruits and vegetables and turning them into powders. In food industry, there are different technologies to dry the fruits and vegetables such as solar dryer, microwave heating, infrared irradiation, super-heated steam drying, fluidized drying, flash drying, freeze drying, and vacuum drying (Sagar & Kumar, 2010). It should be mentioned that the applied drying system has the key role in final moisture content, quality and shelf life of the obtained powder (Kiharason & Isutsa, 2019). In addition, the production of this by-product diminishes the amount of waste as well as saving the cost in food factories (Kruczek, Drygaś, & Habryka, 2016). As shown in Table 1, the effect of powder of dried apple (Chen, Rubenthaler, Leung, & Baranowski, 1988; Masoodi, Sharma, & Chauhan, 2002; Rupasinghe, Wang, Pitts, & Astatkie, 2009; Salehi, Kashaninejad, & Alipour, 2016), quince (Salehi & Kashaninejad, 2017a), orange (Benjamin, Akingbala, & Baccus-Taylor, 2007; Romero-Lopez, Osorio-Diaz, Bello-Perez, Tovar, & Bernardino-Nicanor, 2011), various berries (Y. Kim, 2008; H. J. Lee, 2014; Park & Chung, 2014), grape (Bender et al., 2017; Mildner-Szkudlarz, Siger, Szwengiel, & Bajerska, 2015; Mildner-Szkudlarz, Bajerska, Zawirska-Wojtasiak, & Górecka, 2013; Walker, Tseng, Cavender, Ross, & Zhao, 2014), mango (Noor Aziah, Lee Min, & Bhat, 2011; Siew Chuen, 2010), peach (N Grigelmo-Miguel, Carreras-Boladeras, & Martin-Belloso, 2001; Nuria Grigelmo-Miguel, Carreras-Boladeras, & Martín-Belloso, 1999), melon (Al-Sayed & Ahmed, 2013; An, 2014), carrot (Mahsa Majzoobi, Poor, Jamalian, & Farahnaky, 2016; Salehi, Kashaninejad, Akbari, et al. 2016; Sharoba, Farrag, & Abd El-Salam, 2013), Pumpkin (Bhat & Bhat, 2013; I.; Woo, Kim, Song, Lee, & Choi, 2006), and mushroom (Arora, Kamal, & Sharma, 2017; Salehi, Kashaninejad, Asadi, & Najafi, 2016; Sheikh, Kumar, Islam, & Mahomud, 2010) were studied on different properties of the cakes. Therefore, in this present study, the effects of using powder of different fruits and vegetables on the nutritional values, physicochemical properties, organoleptic aspects and microbial attributes of the cakes were reviewed.","This study highlights the potential of enriching bakery products, particularly cakes, with powders derived from dried fruits and vegetables to enhance their nutritional value. Global food losses, particularly in fruits and vegetables, are significant; drying and powdering these items can reduce waste and extend shelf life. The research reviews the impact of incorporating various fruit and vegetable powders, like apple, orange, berries, grape, mango, peach, melon, carrot, pumpkin, and mushroom, on the nutritional, physicochemical, organoleptic, and microbial qualities of cakes. This approach not only improves food nutrition but also offers a sustainable solution for food waste management."
"Introduction Mango (Mangifera indica L. Anacardiacea) is one of the most important tropical fruits in the world and currently ranked 5th in total world production among the major fruit crops (FAO, 2004). As mango is a seasonal fruit, about 20% of fruits are processed for products such as puree, nectar, leather, pickles, canned slices and chutney and these products experience worldwide popularity and have also gained increased importance in the US and European markets (Loelillet, 1994). During processing of mango, by-products such as peel and kernel are generated. Peel contributes about 15–20% of the fruit (Beerh, Raghuramaiah, Krishnamurthy, & Giridhar, 1976). As peel is not currently utilized for any commercial purposes, it is discarded as a waste and becoming a source of pollution. This waste should be treated as a specialized residue due to high levels of residual phenolics, which may have adverse environmental impacts mainly because of the inhibition of seed germination properties of polyphenols (Negro, Tommasi, & Miceli, 2003). Therefore, industry has increasing cost for its waste treatment. While a number of investigations have been conducted on the composition and possible utilization of mango seed kernel, studies on peels are limited. Peels are the major by-products obtained during the processing of various fruits and these were shown to be a good source of polyphenols, carotenoids and other bioactive compounds which posses various beneficial effects on human health (Larrauri et al., 1999, Rodriguez de Sotillo et al., 1994a, Wolfe et al., 2003). Apple pomace has been shown to be a good source of polyphenols and exhibits strong antioxidant and anti-proliferative activity (Wolfe et al., 2003). Grape pomace, which is a wine industry by-product serves as a good source of anthocyanins, catechins, flavanoids, phenolic acids and dietary fibre (Larrauri et al., 1999, Mazza, 1995, Mazza and Miniati, 1995). Citrus peel is also a rich source of pectins and flavanoids such as hesperidins, eriocitrin and nobiletin (Anagnostopoulou et al., 2006, Coll et al., 1998, Li et al., 2005, Mandalari et al., 2006). Banana and tomato peels are reported to be a good source of carotenoids (Baysal et al., 2000, Subaigo et al., 1996). Aqueous extract of potato peel was shown to provide a good source of phenolic acids (Rodriguez de Sotillo, Hadley, & Holm, 1994b) and exhibited good antioxidant activity (Rodriguez de Sotillo et al., 1994a). Mango peels were found to contain polyphenols and dietary fibre (Larrauri, Ruperez, Borroto, & Saura-calixto, 1996). Though considerable work was done with regard to enzymes like amylase and protease, among others, in mango pulp, very few reports are available with regard to enzymes in mango peel. Prabha and Patwardhan, 1986, Saby John et al., 2002 and Robinson, Loveys, and Chako (1993) reported the presence of polyphenol oxidase in mango peel, while Saby John et al. (2002) also reported the presence of peroxidase. India is the major producer of mango, and peeled raw mangoes are processed for the preparation of amchur and ripe mangoes are processed for mango pulp and fruit bars. Therefore, both raw and ripe peels are available in large quantities as a by-product in mango processing industry. In the present study, valuable bioactive compounds such as polyphenols, carotenoids, dietary fibres and enzymes in the raw and ripe peels of two Indian mango varieties, namely, Badami (Alphonso) and Raspuri were determined with the aim of exploiting the potential value of the peel.","
Mango, a major tropical fruit, generates significant by-products like peels during processing, which often go unused and contribute to pollution. However, these peels are rich in beneficial compounds like polyphenols, carotenoids, and dietary fibers. This study focuses on analyzing the bioactive components in the peels of two Indian mango varieties, Badami (Alphonso) and Raspuri, to explore their potential uses. Previous research indicates peels from various fruits, including mango, are valuable sources of antioxidants and other health-promoting substances, suggesting the possibility of converting this waste into a resource."
"Abstract The β-carotene contents of forty vegetables and fourteen fruits were determined using the AOAC open-column (magnesia and Hyflo Super Cel mixture) chromatographic method and compared with a newly developed reverse-phase HPLC method, in which carotenoids were separated isocratically on an octadecylsilane (C18) column using a ternary mixture of acetonitrile, methanol and ethyl acetate. Results obtained showed that the AOAC method gave falsely elevated results for samples containing α-carotene, as well as those with very low β-carotene concentrations. On the other hand, the HPLC method successfully separated and quantitated the major carotenoids present; namely, lutein, cryptoxanthin, lycopene, γ- and α-carotenes in addition to β-carotene. The carotenoid composition of most of the green vegetables was rather consistent, comprising only lutein and β-carotene. In contrast, there was no clear pattern of carotenoids present in the other vegetables and fruits, where several other carotenoids were detected in varying proportions. The vitamin A activity, expressed as μg of retinol equivalent (RE), was calculated on the basis of all pro-vitamin A carotenoids (cryptoxanthin, γ-, α- and β-carotenes) detected. Most of the green leafy vegetables, including several local vegetables, had high RE. Several green non-leafy and other vegetables were found to have low and medium RE. None of the fruits studied may be said to have high vitamin A activity. RE calculated on the basis of results from the AOAC method was found to be erroneously low for samples with significant proportions of pro-vitamin A carotenoids other than β-carotene, and falsely elevated for those with α-carotene. Total carotenoid concentrations can be estimated by taking absorbance readings of sample extracts directly in a spectrophotometer or by the HPLC method. The study clearly shows that the HPLC method would give a more complete picture of the carotenoid composition as well as a more accurate quantitation of the vitamin A value of the vegetables and fruits. The nutritional significance of the findings is obvious since these foods are important sources of vitamin A for the majority of the communities in the country. GIVE SUMMARY IN ONE PARAGRAPH OF 60 WORDS","This study compares the AOAC open-column chromatographic method and a reverse-phase HPLC method for determining β-carotene content in 40 vegetables and 14 fruits. The AOAC method showed inaccuracies, especially with α-carotene-rich samples and those with low β-carotene levels, while the HPLC method accurately quantified various carotenoids including lutein, cryptoxanthin, lycopene, γ-, α-, and β-carotenes. The carotenoid composition varied among the vegetables and fruits, affecting their vitamin A activity (expressed as retinol equivalent). The study concludes that HPLC provides a more comprehensive and accurate assessment of the carotenoid content and vitamin A value in these foods, highlighting their nutritional importance."
"In birds, carotenoid-based plumage coloration is more dependent on physical condition and foraging abilities and less constrained developmentally than is melanin-based coloration. Thus, female mate choice for honest signals should result in more intense sexual selection on carotenoid- than on melanin-based plumage coloration. Using variation in sexual dimorphism as an indirect measure of the intensity of sexual selection, we tested the prediction that variation in sexual dimorphism is driven more by change in carotenoid-based coloration between males and females than by change in melanin-based coloration. Examination of historical changes in carotenoid- versus melanin-based pigmentation in 126 extant species of Cardueline finches supported this prediction. We found that carotenoid-derived coloration changed more frequently among congeners than melanin-based coloration. In both sexes, increase in carotenoid-based coloration score, but not in melanin-based coloration score, was strongly associated with increase in sexual dichromatism. In addition, sexual dimorphism in carotenoid-based coloration contributed more to overall dichromatism than dimorphism in melanin-based plumage. Our results supported the hypothesis that melanin-based and carotenoid-based coloration have fundamentally different signal content and suggest that combining melanin-based and carotenoid-based coloration in comparative analyses is not appropriate.","In birds, carotenoid-based plumage coloration is more dependent on physical condition and foraging abilities and less constrained developmentally than is melanin-based coloration. Thus, female mate choice for honest signals should result in more intense sexual selection on carotenoid- than on melanin-based plumage coloration. Using variation in sexual dimorphism as an indirect measure of the intensity of sexual selection, we tested the prediction that variation in sexual dimorphism is driven more by change in carotenoid-based coloration between males and females than by change in melanin-based coloration. Examination of historical changes in carotenoid- versus melanin-based pigmentation in 126 extant species of Cardueline finches supported this prediction. We found that carotenoid-derived coloration changed more frequently among congeners than melanin-based coloration. In both sexes, increase in carotenoid-based coloration score, but not in melanin-based coloration score, was strongly associated with increase in sexual dichromatism. In addition, sexual dimorphism in carotenoid-based coloration contributed more to overall dichromatism than dimorphism in melanin-based plumage. Our results supported the hypothesis that melanin-based and carotenoid-based coloration have fundamentally different signal content and suggest that combining melanin-based and carotenoid-based coloration in comparative analyses is not appropriate."
"Introduction Health professionals have consistently advocated the daily consumption of five portions of fruit and vegetables as a means of protecting against the pathogenesis of degenerative diseases including coronary heart disease, cancers and other free radical-mediated conditions (Kritchevsky, 1999). Fruit and vegetables contain a wide range of compounds including the antioxidant vitamins C and E, minerals, phenolics and carotenoids. Carotenoids are natural pigments, providing orange, yellow, red and purple colours throughout the natural world. These pigments are produced by all higher plants, along with some bacteria and algae (Britton et al., 1995). They are derived from the terpenoid family and are biosynthetically related to other secondary metabolites such as tocopherols and ubiquinones (Fig. 1 and Table 1). Within plant tissue they are associated with photosynthetic membranes and are involved in photoprotection and light energy assimilation (Britton et al., 1995). Carotenoids possess a range of important and well-documented biological activities. They are potent antioxidants and free radical scavengers (Grassmann et al., 2002), and can modulate the pathogenesis of cancers (van Poppel and Goldbohm, 1995) and coronary heart disease (Kritchevsky, 1999). Lycopene intake in particular is associated with a decreased incidence of prostate cancer (Giovannucci, 1999), while high levels of β-carotene are correlated with a reduction in the risk of developing lung cancer (Block et al., 1992). A number of carotenoids including α-carotene, β-carotene and β-cryptoxanthin have pro-vitamin A activity, since they are converted to retinal by mammals. This role is of particular importance, especially in developing countries where the dietary deficiency of vitamin A can lead to blindness and premature childhood mortality (Mayne, 1996). The xanthophylls (oxo-carotenoids), lutein and zeaxanthin are also known to provide protection against age-related macular degeneration, mediated by their ability to quench single oxygen and blue light in the retina (Landrum and Bone, 2001). Significant advancement in the metabolic engineering of health-promoting phytochemicals (such as carotenoids) into food crops has been achieved. For example in rice endosperm the carotenoid pathway has been introduced resulting in the engineering of ‘Golden Rice’ (Ye et al., 2000), while in tomato both β-carotene (Römer et al., 2000) and lycopene (Fraser et al., 2002) content has been elevated. In order to extend these approaches to other stable food crops it is vital that basal levels are determined to facilitate future rational engineering. Their wide distribution throughout the plant kingdom means that carotenoids are a ubiquitous part of the diet, however this is not represented in the current food tables prepared by the USDA (Holden et al., 1999). Little standardized information is available on the content of individual carotenoids in foods, with data often presented as ‘total carotenoids’ or as pro-retinal equivalents. However, the development of a polymeric C30 stationary phase has enabled the separation of geometric isomers of common carotenoids (Sander et al. 1994, Fraser et al., 2002). These improvements will lead to more accurate assessments being made of the content of carotenoids in both individual produce and the total diet (Lessin et al., 1997). The most frequently used analytical technique presently used to provide a global profile of metabolites present in a given tissue is GC–MS (Fiehn et al., 2000). Important plant products such as carotenoids are however, not amenable to GC separation and often do not ionise efficiently preventing MS detection. This paper describes the application of robust and established extraction and HPLC techniques to the screening of carotenoids, along with tocopherols and chlorophylls, in a selection of commonly consumed fruits and vegetables. These data may be used in the development of comprehensive food tables, or in the investigation of differences in the metabolic profile of tissues.","
Health professionals recommend consuming five portions of fruits and vegetables daily to protect against degenerative diseases. These foods contain antioxidants, vitamins, minerals, phenolics, and carotenoids. Carotenoids, responsible for various natural colors, are potent antioxidants and are linked to reduced risks of cancers and heart disease. They also have pro-vitamin A activity, crucial in preventing blindness and childhood mortality in developing countries. Recent advancements in metabolic engineering have increased carotenoid content in crops like rice and tomatoes. However, standardized information on carotenoid content in foods is limited. This paper focuses on using HPLC techniques to analyze carotenoids, tocopherols, and chlorophylls in fruits and vegetables, aiding in developing comprehensive food tables and understanding metabolic profiles."
"Abstract The aim of this work was to evaluate some physical and chemical properties of watermelon rind and sharlyn melon peel powders and its utilization as partially, substituted of wheat flour at levels of 2.5%, 5.0% and 7.5% or fat at levels of 5.0%, 10% and 15% in cake making. Watermelon rinds had higher moisture, ash, fat, protein and carbohydrates 10.61%, 13.09%, 2.44%, 11.17% and 56.00%, respectively as compared to sharlyn melon peels. On the other hand, sharlyn melon peels had higher content crud fiber (29.59%) than in watermelon rinds (17.28%). The water absorption capacity (WAC) and oil absorption capacity (OAC) of sharlyn melon peels was higher than that of watermelon rinds being 7.7, 7.13 (g water/g) and 2.24, 1.65 (g oil/g), respectively. Watermelon rinds showed significantly greater free radical scavenging activity and β-carotene (39.7% and 96.44%), respectively compared to sharlyn melon peels. It contained different types of phenolic compounds, the most abundant one was 4-hydroxybenzoic acid (958.3 μg/g dw) followed by vanillin (851.8 μg/g dw), while the lowest phenolic compound was coumaric acid (8.8 μg/g dw). On the other hand four phenolic compounds were identified in sharlyn melon peels namely, 4-hydroxybenzoic acid, vanillin, chlorgenic acid, and coumaric acid. The incorporation of WMR and SMP powders in cakes batter at all the studied levels enhanced the volume and specific volume of the baked cakes to overcome, those of the control. These materials also retard staling of cakes and inhibition the lipids oxidation and free fatty acids formation during storage. It is revealed that, substitution of 5% flour and 10% fat with watermelon rinds and sharlyn melon peels produced acceptable cakes which were not significantly different with the control.","
This study evaluated the physical and chemical properties of watermelon rind and sharlyn melon peel powders for use in cake making, substituting wheat flour (at 2.5%, 5%, 7.5%) or fat (at 5%, 10%, 15%). Watermelon rinds were found to have higher moisture, ash, fat, protein, and carbohydrate content compared to sharlyn melon peels, which had more crude fiber. Watermelon rinds also showed greater free radical scavenging activity and β-carotene content, and a diverse range of phenolic compounds. Incorporating these powders into cake batter improved the volume and specific volume of cakes, reduced staling, and inhibited lipid oxidation and free fatty acids formation during storage. Substituting 5% flour and 10% fat with these powders resulted in cakes comparable to control samples."
"Introduction Watermelon is extensively cultivated in tropical to temperate climatic regions and is favored by consumers owing to its health benefits and low-calorie content [1]. Based on data from the Food and Agriculture Organization, watermelon is second only to citrus among all fruits in terms of output [2]. China is the largest producer of watermelon in the world, with an annual output of approximately 79.3 million tons in 2019 [3]. According to the method used to remove the peel, watermelon rind accounts for 15 to 30 % of the total weight of the fruit [4]. However, watermelon peel is often considered as agricultural waste with little value in food processing industries, leading to environmental pollution and waste of resources [5]. Therefore, it is crucial to explore an integrated and eco-friendly solution for the utilization of watermelon peel. Recently, agricultural waste, among various applications, has gained significant attention as a potential raw material for pectin production [6]. Due to its multifunctionality and high level of safety, pectin is widely utilized in the development of novel foods, nutritional restoration, drug delivery systems, disease treatment, and tissue engineering [7]. Although pectin is present in most plants, commercially available sources are limited to citrus peels or apple pomace [8]. The production of pectin is severely hindered by constraints in raw material availability. The prices of pectin have been rising steadily due to a lack of supply and rising demand. The price of pectin increased by over double to $21 per kilogram in 2019 from $12 per kilogram in 2009, and it continues to rise [9]. Previous studies have shown that the yield, purity, and molar mass of extracted watermelon peel are not only comparable to commercially available citrus peel pectin but demonstrate branching degree with longer galactan side chains and greater protein interaction [10]. Agricultural waste has high moisture content that causes a rapid deterioration rate [11]; thus, watermelon peel needs to be converted to a stable powder when processing pectin [12]. Therefore, the drying process is a crucial operation for the subsequent treatment of agricultural waste. In industrial production, artificial drying has rapidly replaced natural drying due to its advantages of controlled drying conditions, faster drying time, and good material quality [12]. Hot-air-drying (HD) is a conventional drying technique used in industrial production because its equipment is simple and easy to handle [13]. However, high temperature involved in the HD process facilitates the caramelization reaction and shrinkage, leading to the deterioration in product taste, color, and nutritional. However, there are no reports on the exploration of novel drying methods of agricultural waste to improve product quality. Freeze-drying (FD) employs the sublimation method to remove water from plants. Compared to samples dried by other processes, FD samples exhibit high porosity, minimal nutritional degradation, and excellent rehydration properties. Xu et al. [14] examined the impact of drying methods on the structure and functional properties of pectin extracted from okra, revealing that the FD pectin samples exhibited lower molecular weight, higher antioxidant activity, and better retention of the homogalacturonan main chain. Qin et al. [15] extracted pectin from the naturally dried, freeze dried, and subcritical dimethyl ether-dried fruits as well as fresh Chinese quince fruits, and results revealed that the FD sample had the highest yield (10.49 %), molar mass (Mw 65,120 g/mol), and water holding capacity. Li et al. [16] have suggested that different drying methods could affect the physical and chemical properties of pectin, and appropriate processing methods can be selected accordingly. Earlier studies mainly focused on the effects of various drying methods on raw materials, but less on the extraction process, including the parameter optimization, extraction mechanism, and pectin properties. In this study, the fresh watermelon peel was dried by FD, and then the response surface methodology (RSM) method was used to optimize processing parameters, and the extraction mechanism of pectin from FD watermelon peel was explored by analyzing the appearance, microscopic images, and extraction model during the extraction process, physicochemical properties (color, moisture, ash, protein, molecular weight, degree of methylation, and monosaccharide composition), and emulsifying properties","Watermelon, primarily cultivated in tropical to temperate regions, is a popular fruit due to its health benefits and low-calorie content. With China being the largest producer, watermelon rind, often discarded as waste, constitutes 15-30% of the fruit's total weight, posing environmental challenges. This study focuses on utilizing watermelon peel, an underexploited agricultural waste, for pectin production, a substance widely used in food and pharmaceutical industries. Commercially, pectin is mainly derived from citrus peels or apple pomace, and its rising demand has significantly increased its price. Watermelon peel pectin, exhibiting desirable properties, offers a promising alternative. The study explores freeze-drying (FD) as a novel method for processing watermelon peel to improve pectin quality, contrasting with traditional hot-air-drying. Response Surface Methodology (RSM) is employed to optimize processing parameters, and the study delves into the extraction mechanism, examining the physicochemical and emulsifying properties of pectin extracted from FD watermelon peel."
"Introduction Pectin is a heteropolysaccharide and widely exists in plant cell walls. Commercial pectins are usually obtained from citrus peel and apple pomace [1]. In the food industry, pectin is well known for being used as a gelling agent, thickener and emulsifier. Additionally, pectin also exhibits some functional characteristics in the context of human physiology; for example, it can adsorb heavy metals and transport drugs and has anticancer and anti-inflammatory properties. Pectin quality is affected by the properties of the raw material, as well as pretreatment and extraction processes. The source and maturity degree of the raw material have a significant influence on pectin properties, e.g., galacturonic acid content and molecular weight [2]. Blanching prior to drying of the raw material is important for the recovery of premium quality pectin. Parameters of the extraction process, including the solution pH, the type of acid, extraction temperature, and extraction time also have obvious influences on the quality characteristics of pectins [3]. Various drying methods have been used in food processing; the most common methods are sun-drying and lyophilization. Sun-drying is a low-cost way to preserve food, but it is restricted to good day sunshine and requires long drying time. Lyophilization is a well-known method that produces high quality dehydrated products due to the low temperature during the drying process, but the high energy consumption leads to its high cost. Recently, subcritical dimethyl ether (DME) extraction as a new technique has attracted a great deal of attention, and been applied in the food, fuel and other industrial fields. Besides its application in the extraction of lipophilic and water-soluble substances from dried and high moisture samples [4,5], the unique dewatering ability of subcritical DME has also been explored. Kanda and Makino [6] proposed a method for dewatering high-moisture coal which used subcritical DME as a solvent. The water in the coal was dissolved in subcritical DME, and the maximum dehydration rate was 98.3%. Öhrman and Pettersson [7] and Oshita et al. [8] further reported the use of subcritical DME for dewatering biomass such as sewage sludge. In comparison with other drying technologies, subcritical DME dewatering process consumes less energy because DME can be efficiently recycled by vaporizing and compressing. Moreover, the dewatering process is carried out at low temperatures, which prevents the degradation of biologically active components. In addition, the whole dewatering process can be completed in 5–8 h. So subcritical DME dewatering is a quick, low-cost, and effective drying method, and it is suitable to dry the raw materials for pectin extraction. Chinese quince (Chaenomeles sinensis Koehne) is a species belonging to the Rosaceae family. Its ripe fruits are rich in phenolics, pentacyclic triterpene acids, dietary fiber, and pectin [9]. In East Asia, Chinese quince fruits are used as food and folk medicine. It has been proved to have some biological and pharmaceutical activities, such as antioxidant, antiulcerogenic [10] and anti-influenza viral activities [11]. Recent studies have demonstrated that Chinese quince fruit are also rich in pectin and can be used as a potential source of commercial pectin. Drying is a critical step in pectin production, which can affect the quality of pectin. Many studies have reported the effects of different drying conditions on structural and functional properties of pectin [12]. However, few studies have examined the influence of drying pretreatment methods on the properties of the extracted pectin. In this study, three drying methods, namely sun-drying, lyophilization, and subcritical DME dewatering technology, were selected for the drying treatment of Chinese quince fruit. The properties of pectins extracted from the fresh fruit and from fruits dried by these three methods were investigated.","Pectin, a heteropolysaccharide found in plant cell walls, is mainly derived from citrus peel and apple pomace and used widely in the food industry as a gelling agent, thickener, and emulsifier. It also has beneficial health properties, including heavy metal adsorption, drug transport, anticancer, and anti-inflammatory effects. The quality of pectin is influenced by the raw material's source and maturity, as well as pretreatment and extraction processes. Common drying methods in pectin production include sun-drying and lyophilization, each with its advantages and limitations. Recently, subcritical dimethyl ether (DME) extraction has emerged as an energy-efficient, low-temperature alternative. This study investigates the impact of three drying methods (sun-drying, lyophilization, subcritical DME) on the properties of pectin extracted from Chinese quince fruit, a rich source of pectin and other bioactive compounds. The study aims to assess how these drying techniques affect the quality of the extracted pectin, contributing to the optimization of pectin production."
"Introduction Increasing epidemiological data (Rissanen et al., 2003) suggest that a high intake of fruits, berries and vegetables offers a number of health benefits against degenerative diseases and can promote longevity. In addition to high levels of vitamin C, berries contain phytochemicals that significantly contribute to their antioxidant and anticarcinogenic properties. The exploitation of health-promoting bioactive compounds of berries in diverse areas of food and health products is rapidly increasing. Many types of healthy juices and jams as well as dietary supplements containing various bioactive compounds from berries are available all over the world. Red raspberry (Rubus idaeus L.) is an economically important berry crop with a high free radical scavenging capacity and it contains numerous bioactive compounds with potential health benefits (de Ancos et al., 2000a). Mullen et al. (2002a) have identified as many as 11 anthocyanins in raspberries. However, cyanidin-3-sophoroside and cyanidin-3-glucoside are the major compounds (de Ancos et al., 1999). Recently, it has been shown that anthocyanins are important antioxidants in raspberry (Mullen et al., 2002a). However, in humans the bioavailability of dietary anthocyanins is low (Mazza et al., 2002; Wu et al., 2002). Raspberry anthocyanin composition seems to depend on the genotype so that late cultivars appear to have a higher content of anthocyanins than the early ones (de Ancos et al., 1999). Processing, in particular freezing, increased the total anthocyanin concentrations in some raspberry cultivars, but decreases it in others (de Ancos et al., 2000b). In addition, storage temperatures above 0 °C have been shown to increase the content of anthocyanins (Kalt et al., 1999). Ellagic acid is a phenolic compound found in many plants. However, more commonly it is found as ellagitannins. Ellagitannins occur in high concentrations in strawberries and raspberries, which contain about three times more ellagic acid than walnuts and pecans (Daniel et al., 1989; Maas et al., 1991a). Ellagic acid is a bioactive compound of potential protective effects against certain cancer types (Maas et al., 1991a; Stoner and Morse, 1997). Further, ellagitannins have been shown to contribute significantly to the antioxidant activity and vasodilation properties of raspberries (Mullen et al., 2002a). Along with free ellagic acid and ellagic acid conjugates, two ellagitannins (lambertianin C and sanguiin H-6) in significant quantities were recently found (Mullen et al., 2002a) in raspberry. The content of sanguiin H-6 was higher than that of lambertianin C. In strawberry, the ellagic acid content was highest in green fruit and intermediate in mid-ripe fruit and lowest in full-ripe fruit (Williner et al., 2003). The levels of ellagic acid contents varied in strawberry from 0.78 mg/g dry weight in cv. Camarosa to 0.31 mg/g dry weight in cv. Milsei (Williner et al., 2003), and in raspberry from 244 mg/kg fresh weight (fw) in cv. Zeva to 207 mg/kg fw in Autumn Bliss (de Ancos et al., 2000a). Frozen storage and processing decrease the total content of ellagic acid and its derivates (de Ancos et al., 2000a; Zafrilla et al., 2001). However, the effect of frozen storage seems to be cultivar-dependent (de Ancos et al., 2000a). Flavonols such as quercetin and kaempferol possess antioxidant activity and have been suggested to play an important role in the protective effects of berries and vegetables (Hubbard et al., 2003; Knekt et al., 2002). Quercetin, in particular, is known to be a powerful antioxidant (Makris and Rossiter, 2001). There is also experimental evidence for its arterial blood pressure reducing properties (Duarte et al., 2001). Further, quercetin inhibits the growth of human breast carcinoma cells (Choi et al., 2001). Epidemiological data supporting the health-benefits of quercetin intake have also been published (Knekt et al., 2002). Recently, three quercetin conjugates (quercetin-3-rutinoside, quercetin-3-clucoside and quercetin-3-glucuronide), as well as kaempferol glucuronide were identified in raspberry (Mullen et al., 2002a). Compared to quercetin, only minor amounts of kaempferol is found in raspberries (Mullen et al., 2002b). In general, the levels of flavonols in raspberry are considerably lower than those in some other berries such as black currant (Häkkinen et al., 1999; Mikkonen et al., 2001). Flavonols are quite stable when berries are heated during jam processing (Zafrilla et al., 2001). However, the following storage (20 °C, 6 months) seems to decrease the flavonol content significantly. Further, Häkkinen et al. (2000a) found no loss in quercetin content during 9 months of frozen storage. The health-promoting properties of berry plants are affected by cultural, genetic and processing factors. In raspberry, the effects of storage and processing on antioxidant activity and phenolic compounds are relatively well known (de Ancos et al., 2000a; de Ancos et al., 2000b; Häkkinen et al., 2000a; Rommel and Wrolstad, 1993a, Rommel and Wrolstad, 1993b; Zafrilla et al., 2001), but limited information is available on the influence of cultural factors or genotype on health-promoting properties. However, increasing data suggest (de Ancos et al., 2000a; Mikkonen et al., 2001; Prior et al., 1998) that genotype may have a profound influence on the content of bioactive compounds in berries. Consequently, extensive plant breeding programmes have been initiated to increase the levels of compounds with potential health benefits. In this paper, we show that the genotype and the environment both significantly affect the phenolic compounds in raspberry cultivars grown in northern European conditions.","This introduction emphasizes the health benefits of consuming fruits, particularly berries like red raspberries, which are known for their high antioxidant and anticarcinogenic properties. Red raspberries contain significant bioactive compounds, including anthocyanins and ellagic acid, known for their health-promoting effects such as cancer prevention and antioxidant activity. The study notes that the bioavailability of these compounds in humans is low. It also highlights the variability in anthocyanin composition among raspberry cultivars and how processing and storage conditions affect their content. Ellagic acid, found in high concentrations in raspberries and strawberries, contributes to the antioxidant properties of raspberries. The study explores how different raspberry cultivars, particularly in northern European conditions, vary in their phenolic compound content due to genetic and environmental factors. It also discusses the stability of flavonols like quercetin during processing and storage. The paper aims to demonstrate the significant influence of genotype and environment on the health-promoting properties of raspberries."
"INTRODUCTION Free oxygen radicals may be involved in several pathologic conditions (1). Oxidation of LDLs is thought to play an important role in the development of atherosclerosis (2). Free oxygen radicals are apparently involved at different stages of cancer development (3). Free radicals may contribute to the autoimmune destruction of β cells, leading to diabetes (4), and may impair insulin action (5). Reactive oxygen species have also been proposed as mediators of inflammatory damage in asthma (6) and in joints in rheumatoid arthritis (7). Furthermore, it has been suggested that the oxidation of lens proteins by free radicals plays an important role in the process leading to cataract (8). Flavonoids are products of plant metabolism and have different phenolic structures (9). They are effective antioxidants because of their free radical scavenging properties and because they are chelators of metal ions (10); thus, they may protect tissues against free oxygen radicals and lipid peroxidation. Flavonoids may also be activated by mechanisms that apparently are not directly dependent on their antioxidative properties. Under certain conditions they may also behave as prooxidants (11). A wide range of different biological activities, including antibacterial, antithrombotic, vasodilatory, antiinflammatory, and anticarcinogenic effects mediated by different mechanisms, are associated with flavonoid compounds (12). In vitro studies indicate considerable differences in the antioxidative potential of different flavonoid subgroups, depending on their chemical structures (11). Because of differences in their chemical structure, bioavailability, distribution, and metabolism (11), different flavonoid compounds may have different effects on human health. Of the few prospective studies in humans that have predicted the effects of flavonoids on cardiovascular disease risk, some showed an inverse association (13, 14, 15, 16, 17), whereas others showed no association (18, 19, 20, 21). Studies of cancer have also given contradictory results (15, 22, 23). Most of these previous studies investigated the effects of total intakes of selected flavonols and flavones, for which food-composition data were available. In the present cohort study we extended the analyses beyond cardiovascular diseases and cancer to other chronic diseases associated with oxidative stress etiology. Flavanones were included in our analyses in addition to flavonols and flavones. To show potential differences in the effects of various flavonoids, we also investigated separately the effects of the major flavonoids quercetin, kaempferol, myricetin, naringenin, and hesperitin.","
This introduction discusses the role of free oxygen radicals in various pathological conditions, including atherosclerosis, cancer, diabetes, asthma, rheumatoid arthritis, and cataracts. It highlights the importance of flavonoids, natural plant metabolites with phenolic structures, known for their antioxidant properties, and their potential in combating these conditions. Flavonoids can scavenge free radicals and chelate metal ions, protecting tissues from oxidative stress and lipid peroxidation. However, they can also act as prooxidants under certain conditions. Flavonoids exhibit a range of biological activities, such as antibacterial, antithrombotic, vasodilatory, anti-inflammatory, and anticarcinogenic effects. The study acknowledges the variability in the antioxidative potential of different flavonoid subgroups due to their distinct chemical structures, bioavailability, distribution, and metabolism. Previous human studies on the effects of flavonoids on cardiovascular disease and cancer have shown mixed results. This cohort study aims to extend the analysis to other chronic diseases linked to oxidative stress and includes a broader range of flavonoids like flavanones, quercetin, kaempferol, myricetin, naringenin, and hesperitin, to understand their distinct health impacts."
"Introduction Osmotic dehydration or “dewatering-impregnation-soaking” (DIS) process has been generally considered useful as a pre-treatment to subsequent stabilisation process, since the reduction of water availability (considering both system mobility and water activity) is in most cases not sufficient to guarantee the shelf-stability. Thus, the food stability can be achieved using a drying (convective, microwave or freeze-drying), canning or freezing final process in order to permit a desired shelf-life. Nevertheless, the importance of the microbial aspects during the process appears to be fundamental if the osmotic dehydration process has to be implemented in a so-called “hurdle technology” where the DIS step is associated with other “hurdles”, e.g. refrigeration or use of preservatives. In such a situation, typical of “minimally processed fruits” where an osmotic step has been proposed (Dalla Rosa, Bressa, Mastrocola, & Pittia, 1995; Askar, 1998; Moreno, Chiralt, Escriche, & Serra, 1998; Tapia, Lopez-Malo, Consuegra, Corte, & Welti-Chanes, 1999; Leunda, Guerrero, & Alzamora, 2000), the initial microbial load is not reduced by the following processes and the additional hurdles have the only role of slowing down the microbial growth. Furthermore the microbial contamination of DIS-processed foods could result from the contact between the raw material and a contaminated concentrated solution to be used as osmotic medium (Dalla Rosa & Mastrocola, 2000). The sanitation of the used solution among cycles of DIS process comes out in consequence as an absolute necessity to maintain under control the level of process contamination (Dalla Rosa, Bressa, Giavedoni, & Pinnavaia, 1992), especially if raw material from animal origin has to be treated (Collignan, 2000; Ricoul & Nesvabda, 2000). Unfortunately, the literature on these aspects of the implementation of the DIS process is very scarce and only in the last few years some papers regarding the microbial growth potential in osmosed products were published (Tapia, Aguilar, Diaz, & Roa, 1995; Bodnaruk, Draughon, & Mount, 1995; Gianotti, Sacchetti, Pinnavaia, & Dalla Rosa, 2000). Interesting results were observed about the reduction of microbial growth rates determined by a short-time osmotic treatment of kiwifruit (Dalla Rosa, Mastrocola, Maltini, & Sacchetti, 1999; Gianotti et al., 2000), even if the reached water activity values (Aw around 0.99–0.98) could not determine any inhibition of microbial growth. It is thus of interest to evaluate the potential shelf-life of high moisture fruit products (HMFP) minimally processed by osmotic treatment. The initial microbial load plays a primary role in the evaluation of the shelf-life of minimally processed products. Its extent is determined by contamination phenomena that could occur both at environmental level or during harvest and/or processing. The osmotic process, and in particular the hygienic state of the solution, could influence the contamination of an osmodehydrated product and thus its shelf-life. There is an increasing interest in the ability of the micro-organisms to adhere to food surface and form biofilms able to enhance their resistance to removal and inactivation. Various papers contributed to this knowledge on adhesion to surfaces of food plants (Notermans, Dormans, & Mead, 1991), packaging materials (Guerzoni, Lanciotti, Sinigaglia, & Gardini, 1994), whole fruit surfaces (Pao & Eldon Brown, 1998), due to the bacteria suspended in liquid media. Few information, however, are available about the influence of liquid solutions on fruit slices surface. In the study reported in this paper, the interest was addressed to adhesion phenomena occurring when foods are put in contact with an yeast-inoculated viscous solution at different sucrose concentrations, by simulating a DIS process. Furthermore, the microbial growth on short-time osmotically treated kiwifruit slices was computed using predictive modelling by setting the initial microbial load at a given level and considering as a variable the concentration of the solution used as osmotic agent and then impregnating the fruits.","This introduction discusses the use of osmotic dehydration, or the ""dewatering-impregnation-soaking"" (DIS) process, as a pre-treatment in food preservation. While DIS alone often doesn't ensure shelf-stability due to insufficient water removal, it is effectively combined with other stabilization processes like drying, canning, or freezing. In the context of ""hurdle technology,"" where DIS is paired with additional preservation methods like refrigeration or preservatives, the importance of controlling initial microbial load becomes crucial, especially for minimally processed fruits. The sanitation of the osmotic solution used in DIS is vital to control process contamination, particularly when treating animal-derived raw materials.

Recent studies have focused on microbial growth in osmotically treated products, noting the need for more research in this area. For instance, studies have shown that a short-time osmotic treatment can reduce microbial growth rates in kiwifruit, even though the water activity levels achieved do not inhibit microbial growth. This research emphasizes the significance of the initial microbial load and the hygienic state of the osmotic solution in determining the shelf-life of high moisture fruit products (HMFP) minimally processed by osmotic treatment."
"Abstract Background Hydroxychloroquine and azithromycin combination therapy is often prescribed for coronavirus disease 2019 (COVID-19). Electrocardiographic (ECG) monitoring is warranted because both medications cause corrected QT-interval (QTc) prolongation. Whether QTc duration significantly varies during the day, potentially requiring multiple ECGs, remains to be established. Methods We performed 12‑lead ECGs and 12‑lead 24-h Holter ECG monitoring in all patients aged <80 years admitted to our medical unit for COVID-19, in oral therapy with hydroxychloroquine (200 mg, twice daily) and azithromycin (500 mg, once daily) for at least 3 days. A group of healthy individuals matched for age and sex served as control. Results Out of 126 patients, 22 (median age 64, 82% men) met the inclusion criteria. ECG after therapy showed longer QTc-interval than before therapy (450 vs 426 ms, p = .02). Four patients had a QTc ≥ 480 ms: they showed higher values of aspartate aminotransferase (52 vs 30 U/L, p = .03) and alanine aminotransferase (108 vs 33 U/L, p < .01) compared with those with QTc < 480 ms. At 24-h Holter ECG monitoring, 1 COVID-19 patient and no control had ≥1 run of non-sustained ventricular tachycardia (p = .4). No patients showed “R on T"" premature ventricular beats. Analysis of 24-h QTc dynamics revealed that COVID-19 patients had higher QTc values than controls, with no significant hourly variability. Conclusion Therapy with hydroxychloroquine and azithromycin prolongs QTc interval in patients with COVID-19, particularly in those with high levels of transaminases. Because QTc duration remains stable during the 24 h, multiple daily ECG are not recommendable.",
"Chloroquine (CQ) and hydroxychloroquine (HCQ) have recently become the focus of global attention as possible treatments for Coronavirus Disease 2019 (COVID-19). The current systematic review aims to assess their safety in short treatments (≤14 days), whether used alone or in combination with other drugs. Following the PRISMA and SWiM recommendations, a search was conducted using four health databases for all relevant English-, Chinese-, and Spanish-language studies from inception through 30 July 2021. Patients treated for any condition and with any comparator were included. The outcomes of interest were early drug adverse effects and their frequency. A total of 254 articles met the inclusion criteria, including case and case-control reports as well as cross-sectional, cohort, and randomised studies. The results were summarised either qualitatively in table or narrative form or, when possible (99 studies), quantitatively in terms of adverse event frequencies. Quality evaluation was conducted using the CARE, STROBE, and JADAD tools. This systematic review showed that safety depended on drug indication. In COVID-19 patients, cardiac adverse effects, such as corrected QT interval prolongation, were relatively frequent (0–27.3% and up to 33% if combined with azithromycin), though the risk of torsade de pointes was low. Compared to non-COVID-19 patients, COVID-19 patients experienced a higher frequency of cardiac adverse effects regardless of the regimen used. Dermatological adverse effects affected 0–10% of patients with autoimmune diseases and COVID-19. A broad spectrum of neuropsychiatric adverse effects affected patients treated with CQ for malaria with variable frequencies and some cases were reported in COVID-19 patients. Gastrointestinal adverse effects occurred regardless of drug indication affecting 0–50% of patients. In conclusion, CQ and HCQ are two safe drugs widely used in the treatment of malaria and autoimmune diseases. However, recent findings on their cardiac and neuropsychiatric adverse effects should be considered if these drugs were to be proposed as antivirals again.","
This systematic review evaluates the safety of chloroquine (CQ) and hydroxychloroquine (HCQ) in short treatments (≤14 days) for various conditions, focusing on their use in COVID-19. Analyzing 254 articles, it found that cardiac adverse effects, such as QT interval prolongation, were more frequent in COVID-19 patients (0–27.3%, increasing to 33% with azithromycin), though the risk of torsade de pointes was low. Dermatological and gastrointestinal side effects were also noted, and a range of neuropsychiatric effects were observed, especially in malaria treatments. The study concludes that while CQ and HCQ are generally safe, their potential cardiac and neuropsychiatric risks should be carefully considered, especially for antiviral use."
"Abstract Nowadays, food industry is facing challenges connected with the preservation of the highest possible quality of fruit products obtained after processing. Attention has been drawn to Aronia fruits due to numerous health promoting properties of their products. However, processing of Aronia, like other berries, leads to difficulties that stem from the preparation process, as well as changes in the composition of bioactive compounds. Consequently, in this study, Aronia commercial juice was subjected to different drying techniques: spray drying, freeze drying and vacuum drying with the temperature range of 40–80 °C. All powders obtained had a high content of total polyphenols. Powders gained by spray drying had the highest values which corresponded to a high content of total flavonoids, total monomeric anthocyanins, cyaniding-3-glucoside and total proanthocyanidins. Analysis of the results exhibited a correlation between selected bioactive compounds and their antioxidant capacity. In conclusion, drying techniques have an impact on selected quality parameters, and different drying techniques cause changes in the content of bioactives analysed. Spray drying can be recommended for preservation of bioactives in Aronia products. Powder quality depends mainly on the process applied and parameters chosen. Therefore, Aronia powders production should be adapted to the requirements and design of the final product.","This abstract summarizes a study on the impact of various drying techniques on the quality of Aronia fruit products, particularly focusing on the preservation of bioactive compounds. The study experimented with spray drying, freeze drying, and vacuum drying at temperatures ranging from 40–80 °C on commercial Aronia juice. The results showed that all the powders obtained had a high content of total polyphenols, with spray drying yielding the highest levels of total flavonoids, anthocyanins, cyanidin-3-glucoside, and proanthocyanidins. This indicates a correlation between the drying technique and the preservation of bioactive compounds and their antioxidant capacity. The study concludes that spray drying is preferable for retaining bioactives in Aronia products, and that the quality of the powder depends significantly on the chosen process and parameters, which should be tailored to the requirements of the final product."
"Abstract Turmeric is widely used in dietary supplements and functional foods owing to its high nutritive value with potential health benefits. The present study was carried out to study the effect of five different drying methods namely shade drying (SD), solar drying (SOD), hot air oven drying (HAD), microwave drying (MD), and freeze drying (FD) on the physicochemical properties, essential oil yield and volatile composition of turmeric. Results showed that while FD method led to the lowest moisture content (6.13%), MD method took the shortest drying time (0.5 h) and FD resulted in better color retention, lowest water activity and higher rehydration ratio as compared to other methods. FTIR analysis and glass transition temperature varied significantly with different drying methods. The maximum and minimum essential oil yield was obtained with FD (1.7% v/w) and HAD (0.35% v/w) methods, respectively. The major constituents were ar-turmerone (28.00–38.81%), α-turmerone (17.56–27.03%), β-turmerone (16.53–19.02%) and α-phellandrene (2.47–5.22%), respectively. Significant changes in the volatile constituents in the essential oil were found to be related to drying methods. The percentages of α-turmerone and β-turmerone in the oil significantly increased when the rhizomes were freeze dried. The results showed that freeze drying was the most effective drying method which retained the above mentioned characters as fresh turmeric and the present study will provide a theoretical basis for industrial processing of turmeric.","This abstract details a study investigating the impact of five different drying methods on turmeric's physicochemical properties, essential oil yield, and volatile composition. The methods tested were shade drying (SD), solar drying (SOD), hot air oven drying (HAD), microwave drying (MD), and freeze drying (FD). The study found that freeze drying resulted in the lowest moisture content and the highest essential oil yield, with ar-turmerone, α-turmerone, β-turmerone, and α-phellandrene as major constituents. Microwave drying was the fastest, while freeze drying preserved color, had the lowest water activity, and the highest rehydration ratio. There were significant changes in the volatile constituents of the essential oil depending on the drying method, with α-turmerone and β-turmerone percentages increasing significantly in freeze-dried samples. Overall, freeze drying was deemed the most effective method for retaining qualities akin to fresh turmeric, providing valuable insights for the industrial processing of turmeric."
"Introduction Black carrots (Daucus carota ssp. sativus var. atrorubens Alef.) have an appealing bluish-purple color with significant levels of anthocyanins, which show high heat, light, and pH stability. Recently, they have received increasing interest as a source of natural food colorant due to the legal restrictions for synthetic colorants and increasing consumer demand for natural pigments (Ekici et al., 2015). In addition to their colorant features, anthocyanin rich black carrots are indicated to exhibit health promoting properties including antioxidant (Kamiloglu et al., 2015, Koley et al., 2014), anti-inflammatory (Kamiloglu et al., 2016b, Mizgier et al., 2016) and anticancer (Sevimli-Gur, Cetin, Akay, Gulce-Iz, & Yesil-Celiktas, 2013) activities. Due to the seasonal and perishable nature, many fresh fruits and vegetables are subjected to some form of processing. Processing of foods of plant origin generates large amounts of by-products. Disposal of these by-products creates both a cost to the food manufacturer and a potential negative impact on the environment. Research over the past 20 years has revealed that many of these by-products could potentially serve as a source of valuable bioactive compounds (Huang et al., 2013, Wijngaard et al., 2012). In Turkey, around 2700 and 6900 tons of black carrot pomace (BCP), an industrial by-product of juice processing, was produced in 2009 and 2010, respectively. This trend is expected to continue and even to accelerate in upcoming years (Agcam & Akyildiz, 2015). BCP is considered as a potential food ingredient and has been used to improve the functional properties of cookies (Turksoy, Keskin, Ozkaya, & Ozkaya, 2011) and fermented black carrot juice (Tatoglu, 2014). Lately, more attention has been given to the bioavailability of polyphenols, a prerequisite for further physiological functions in the body. As human studies are time consuming, costly, and restricted by ethical concerns, in vitro models for investigating the effects of digestion have been developed and employed to predict the release of polyphenols from the food matrix and assess changes in their profiles prior to absorption. However, the diversity of in vitro digestion model conditions has limited the ability to compare results across different studies (Alminger et al., 2014). To overcome this issue, a standardized and practical static digestion model based on physiologically relevant conditions was proposed (Minekus et al., 2014). This model has already been used to study the bioaccessibility of certain polyphenols including anthocyanins (Pineda-Vadillo et al., 2016). In a previous study performed by our group (Kamiloglu et al., 2016a), we showed that polyphenols initially present in black carrots are largely preserved in BCP. Furthermore, the bioaccessibility of anthocyanins from BCP was found to be higher than black carrot. Considering the above, we suggest that BCP, a cheap and substantial source of polyphenols may be used to enrich food products. Bakery products including cakes are considered to be a good source of energy, however they have low antioxidant capacity. Hence, in order to increase the nutritional value of cake and to valorize BCP, in the present study we investigated the digestive stability of polyphenols from BCP enriched cakes and monitored changes in their antioxidant capacity using the standardized static in vitro digestion model of Minekus et al. (2014).","This study investigates the impact of elevated atmospheric CO2 levels (650 ppm) on Aconitum heterophyllum, an alpine rhizomatous herb, over three growing seasons using open-top chambers. The results indicate that elevated CO2 initially led to increased shoot morphometric parameters and biomass production in the first two seasons, but these effects declined in the third season. Additionally, elevated CO2 resulted in changes in nutrient composition, soil pH, and available nutrients. Flowering occurred earlier in elevated CO2 conditions, but with smaller and lighter seeds, leading to reduced seedling survival. These findings suggest complex responses of Aconitum heterophyllum to elevated CO2 and highlight the need for multi-season studies to understand its long-term implications in the context of climate change.
This introduction discusses the significance of black carrots, known for their high anthocyanin content and health-promoting properties, as a source of natural food colorants and bioactive compounds. It highlights the potential of industrial by-products like black carrot pomace (BCP) to serve as valuable sources of bioactive compounds. BCP, a by-product of juice processing, is described as a potential food ingredient used to enhance the functional properties of various food products. The introduction also introduces the concept of in vitro digestion models, which are employed to study the release and bioaccessibility of polyphenols from food matrices. The study aims to investigate the bioaccessibility and antioxidant capacity of polyphenols from BCP-enriched cakes using a standardized static in vitro digestion model."
"Abstract
We suggest an optimization approach of cluster-based undersampling to select appropriate instances. This approach can solve the data imbalance problem, which can lead to knowledge extraction for improving the performance of existing data mining techniques. Although data mining techniques among various big data analytics technologies have been successfully applied and proven in terms of classification performance in various domains, such as marketing, accounting and finance areas, the data imbalance problem has been regarded as one of the most important issues to be considered.

We examined the effectiveness of a hybrid method using a clustering technique and genetic algorithms based on the artificial neural networks model to balance the proportion between the minority class and majority class. The objective of this paper is to constitute the best suitable training dataset for both decreasing data imbalance and improving the classification accuracy. We extracted the properly balanced dataset composed of optimal or near-optimal instances for the artificial neural networks model. The main contribution of the proposed method is that we extract explorative knowledge based on recognition of the data structure and categorize instances through the clustering technique while performing simultaneous optimization for the artificial neural networks modeling. In addition, we can easily understand why the instances are selected by the rule-format knowledge representation increasing the expressive power of the criteria of selecting instances. The proposed method is successfully applied to the bankruptcy prediction problem using financial data for which the proportion of small- and medium-sized bankruptcy firms in the manufacturing industry is extremely small compared to that of non-bankruptcy firms.

","This study presents an optimization approach for addressing the data imbalance problem in data mining, with a focus on improving classification accuracy. The approach combines clustering techniques and genetic algorithms to create a balanced training dataset for artificial neural networks modeling. By recognizing the data structure and categorizing instances through clustering, the method optimizes the selection of instances, leading to improved classification performance. The proposed approach is successfully applied to the bankruptcy prediction problem using financial data, particularly in cases where the proportion of bankruptcy firms is small compared to non-bankruptcy firms in the manufacturing industry. This method enhances knowledge extraction and provides rule-format knowledge representation for a better understanding of instance selection criteria."
"For plants to grow they need resources and appropriate conditions that these resources are converted into biomass. While acknowledging the importance of co-drivers, the classical view is still that carbon, that is, photosynthetic CO2 uptake, ranks above any other drivers of plant growth. Hence, theory and modelling of growth traditionally is carbon centric. Here, I suggest that this view is not reflecting reality, but emerged from the availability of methods and process understanding at leaf level. In most cases, poorly understood processes of tissue formation and cell growth are governing carbon demand, and thus, CO2 uptake. Carbon can only be converted into biomass to the extent chemical elements other than carbon, temperature or cell turgor permit. Introduction The progress in scientific understanding is strongly influenced by the historical sequence of discoveries, the resulting paradigms and by the availability of methods. Break through discoveries have a long shadow and technical options open new avenues, but they may also confine the scientific mind to the doable. The functional understanding of plant growth, that is, how plants accumulate dry matter, is a good example. Following from Priestley's discovery of oxygen in 1774, Jan Ingenhousz, Jean Senebier and Theodore de Saussure's revolutionary discovery between 1779 and 1804 that plants ‘eat air’ [1, 2] instead of sucking the bulk of their dry matter from the substrate (as was believed before) had a lasting impact on the public and scientific understanding of plant growth. Since those early days, CO2 has been known as the substrate for photosynthesis, with plant growth considered the inevitable outcome. While there is no question that plant growth builds upon photosynthates (half of plant biomass is carbon), there are justified reasons to question the general assumption that photosynthesis is the rate controlling factor for plant growth. Just like C4 plants are often believed to be more productive than C3 plants, given the difference in photosynthetic capacity, although it is long known that such leaf level differences do not scale to ecosystem (field) level [3••, 4, 5], except under drought stress, when C4 species are more successful. Crop physiology back to the 1980s has disproven a direct linkage between the capacity for carbon uptake per unit leaf area and growth rate or yield, with tissue (leaf) duration and leaf area ratio as well as the regulation of development (phenology) identified as critical [7•, 8••, 9•]. In this essay, I will summarize evidence against the assumption of a growth limiting role of photosynthesis (source activity) under normal daylight conditions in the field, and will advocate a broader perception of what crop research and plant physiology have already arrived at, namely that tissue growth itself (sink activity) may be limited more than the provision of the carbohydrate building blocks produced by photosynthesis [6, 7•, 10, 11••]. There are five pathways through which tissue growth can be regulated, four of which are under environmental control, of which only one operates via carbon source activity, with the three other ones commonly dominating, when temperature, moisture or soil nutrients become restrictive (Figure 1). Here I will focus on the direct action of environmental drivers on tissue growth (pathway 2 in Figure 1) versus the classical assumption of a dominating role of pathway 1, with only brief comments on pathways 3 and 4. I will close by discussing the dilemma that leaf photosynthesis is almost always operating below light saturation, whereas net primary production, NPP, is commonly not constrained by the capacity of leaves to assimilate CO2, at multi-year time scales. This assessment will not account for conditions in which CO2 is made the ultimately limiting resource by rising the availability of all other resources.","The traditional view in plant physiology and growth modeling has prioritized photosynthetic carbon uptake (CO2 assimilation) as the primary driver of plant growth. This perspective has been shaped by historical discoveries and the availability of methods to study photosynthesis at the leaf level. However, the author challenges this view, suggesting that it does not fully reflect reality. Instead, the essay argues that poorly understood processes related to tissue formation and cell growth often govern the demand for carbon, influencing CO2 uptake. The author emphasizes that plant growth is not solely limited by photosynthesis but can be constrained by various environmental factors, including temperature, moisture, and soil nutrients. This broader perspective calls for a reevaluation of the role of photosynthesis in plant growth and highlights the complexity of the underlying processes."
"INTRODUCTION
Chloroplasts are the site of photosynthesis and a plethora of anabolic reactions essential for growth, development, and reproduction of plants. They derive from cyanobacterial ancestors, which were incorporated into the plant cell as endosymbionts (e.g. Bonen and Doolittle, 1975; Bauer et al., 2001). During evolution of higher plants, chloroplasts have successively lost their autonomy with respect to expression of genes that are essential for their function (Chellamuthu et al., 2013; Tanaka and Hanaoka, 2013). Genes coding for plastidial proteins, such as those involved in photosynthetic electron transport in the thylakoid membrane or the Calvin–Benson cycle of CO2 assimilation in the stroma, migrated to the nucleus and have been integrated into the genome of the host. To date, the majority of the over 3000 estimated proteins required in the chloroplasts are encoded by nuclear DNA and only a small number by the plastome, such as core components of both photosystems, for instance (Leister, 2003; Berry et al., 2013). Hence, it is indispensable that the protein equipment of the chloroplasts and thereby photosynthesis can adapt to new environmental cues, such as changing light intensities, temperature, drought, and other abiotic or biotic stress factors in the short and in the long term. In many cases, the response to a changing environment is reflected in a differential activity of nuclear gene expression, leading to the induction or suppression of photosynthesis-related genes (Eberhard et al., 2008). In an attempt to explain this obvious control of nuclear gene expression by changing demands of the chloroplasts, the concept of retrograde, or chloroplast-to-nucleus signaling, has been developed (Beck, 2005; Koussevitzky et al., 2008; Kleine et al., 2009; Kleine and Leister, 2013) comprising at least seven different signal classes.

It is, however, not the aim of this contribution to dissect individual retrograde signaling pathways in detail. Instead, the focus will be on the central role of sugars in light acclimation processes. Sugars are principle end products of photosynthesis and have the potential to modulate the expression of nuclear-encoded photosynthesis genes. Hence, the emphasis will be on sugar sensing and signaling. Moreover, an additional and probably provocative concept will be introduced that might help to understand how the concerted expression of nuclear- and plastome-encoded genes works. This concept demands that chloroplasts are capable of sensing the carbohydrate status in the surrounding cytosol—an idea that is enforced by recent reports on a plastidial hexokinase (Zhang et al., 2010) and an invertase (Vargas et al., 2008). Both enzymes would not fit into our current model of chloroplast metabolism. The hypothetical question will be asked whether the sugar status in the cytosol not only modulates the expression of nuclear-encoded photosynthesis genes, but can also be recognized by chloroplast and probably modulates the expression of plastome-encoded genes as well. Recent reports on mutants impaired in the day- and night-path of assimilate export from the chloroplast seem to support this idea, and they could even be helpful to unravel the basic principles of this hypothesis (Häusler et al., 2009; Heinrichs et al., 2012; Schmitz et al., 2012, 2014).

Furthermore, this contribution is solely focused on chloroplast-to-nucleus signaling. Mitochondrial retrograde signaling has been highlighted elsewhere (e.g. Leister, 2005; Rhoads and Subbaiah, 2007; Schwarzländer et al., 2012; Schwarzländer and Finkemeier, 2013).

ChatGPT
","
The introduction discusses the significance of chloroplasts in plants, emphasizing their role in photosynthesis and various essential anabolic processes. Chloroplasts originated from cyanobacterial ancestors through endosymbiosis and have gradually lost their autonomy in gene expression during plant evolution. Most genes required for chloroplast function are now located in the nucleus. This shift in gene location necessitates the ability of chloroplasts to adapt to changing environmental conditions, such as light intensity, temperature, and stress factors. The concept of retrograde signaling, where chloroplasts communicate with the nucleus to regulate nuclear gene expression, is introduced. While various retrograde signaling pathways exist, the focus of this contribution is on the role of sugars in light acclimation processes and their potential to modulate nuclear-encoded photosynthesis genes. The concept of chloroplasts sensing the carbohydrate status in the cytosol and its impact on gene expression, including plastome-encoded genes, is proposed. Additionally, this discussion is centered on chloroplast-to-nucleus signaling, with mitochondrial retrograde signaling addressed separately in other studies."
"Audio Description (AD) provides linguistic descriptions
of movies and allows visually impaired people to follow a
movie along with their peers. Such descriptions are by design mainly visual and thus naturally form an interesting
data source for computer vision and computational linguistics. In this work we propose a novel dataset which contains
transcribed ADs, which are temporally aligned to full length
HD movies. In addition we also collected the aligned movie
scripts which have been used in prior work and compare
the two different sources of descriptions. In total the MPII
Movie Description dataset (MPII-MD) contains a parallel
corpus of over 68K sentences and video snippets from 94
HD movies. We characterize the dataset by benchmarking different approaches for generating video descriptions.
Comparing ADs to scripts, we find that ADs are far more
visual and describe precisely what is shown rather than
what should happen according to the scripts created prior
to movie production.","Audio Description (AD) enhances movie accessibility for the visually impaired. The MPII Movie Description dataset aligns transcribed ADs with HD movies, serving as a resource for computer vision. With over 68K sentences and video snippets from 94 movies, it compares ADs to movie scripts. Results show ADs are visually focused, describing on-screen actions, while scripts emphasize pre-production intentions."
"Audio descriptions (ADs) make movies accessible to
millions of blind or visually impaired people1
. AD provides
an audio narrative of the “most important aspects of the visual information” [61], namely actions, gestures, scenes,
and character appearance as can be seen in Figures 1 and
2. AD is prepared by trained describers and read by professional narrators. More and more movies are audio transcribed, but it may take up to 60 person-hours to describe a
2-hour movie [44], resulting in the fact that only a small
subset of movies and TV programs are available for the
blind. Consequently, automating this would be a noble task.
In addition to the benefits for the blind, generating descriptions for video is an interesting task in itself requiring
to understand and combine core techniques of computer vision and computational linguistics. To understand the visual input one has to reliably recognize scenes, human activities,
and participating objects. To generate a good description
one has to decide what part of the visual information to verbalize, i.e. recognize what is salient.
Large datasets of objects [19] and scenes [73, 76] had an
important impact in the field and significantly improved our
ability to recognize objects and scenes in combination with
CNNs [40]. To be able to learn how to generate descriptions of visual content, parallel datasets of visual content
paired with descriptions are indispensable [59]. While recently several large datasets have been released which provide images with descriptions [31, 49, 53], video description datasets focus on short video snippets only and are
limited in size [12] or not publicly available [54]. TACoS
Multi-Level [58] and YouCook [17] are exceptions by providing multiple sentence descriptions and longer videos.
While these corpora pose challenges in terms of finegrained recognition, they are restricted to the cooking scenario. In contrast, movies are open domain and realistic, even though, as any other video sources (e.g. YouTube
or surveillance videos), have their specific characteristics.
ADs and scripts associated with movies provide rich multiple sentence descriptions. They even go beyond this by
telling a story which means they allow to study how to extract plots and understand long term semantic dependencies
and human interactions from the visual and textual data.","Audio descriptions (ADs) make movies accessible for the visually impaired, narrating vital visual details. Manual transcription is time-consuming, prompting the need for automation. Video description generation involves merging computer vision and linguistics. Existing datasets primarily cover images or short video snippets, limiting comprehensive learning. The MPII Movie Description dataset aligns ADs with scripts, offering a resource for understanding semantic dependencies and human interactions in realistic movies."
"In this work we present a novel dataset which provides transcribed ADs, which are aligned to full length HD
movies. For this we retrieve audio streams from Blu-ray
HD disks, segment out the sections of the AD audio and
transcribe them via a crowd-sourced transcription service
[2]. As the ADs are not fully aligned to the activities in
the video, we manually align each sentence to the movie.
Therefore, in contrast to [61, 62, 69], our dataset provides
alignment to the actions in the video, rather than just to the
audio track of the description. In addition we also mine
existing movie scripts, pre-align them automatically, similar to [14, 45] and then manually align the sentences to the
movie.
As a first study on our dataset we benchmark several approaches for movie description. First are nearest neighbour
retrieval using state-of-the-art visual features [32, 72, 76]
which do not require any additional labels, but retrieve sentences from the training data. Second, we adapt the approach of [59] by automatically extracting the semantic representation from the sentences using semantic parsing. This
approach achieves competitive performance on the TACoS
Multi-Level corpus [58] without using the annotations and
outperforms the retrieval approaches on our novel MPII
Movie Description dataset.
The main contribution of this work is our novel MPII
Movie Description dataset (MPII-MD) which provides transcribed and aligned AD and script data sentences. We provide access to our dataset on our web page. We hope that
our dataset will foster research in different areas including
video description, activity recognition, visual grounding,
and understanding of plots. Additionally we present an approach to semi-automatically collect and align AD data and
analyse the differences between ADs and movie scripts.","Introducing the MPII Movie Description dataset (MPII-MD): transcribed and aligned Audio Descriptions (ADs) from Blu-ray HD disks, manually synchronized with movie actions. Unlike prior datasets, MPII-MD aligns descriptions directly to video actions. Benchmarking various movie description approaches, including semantic parsing, demonstrates competitive performance. This dataset aims to propel research in video description, activity recognition, visual grounding, and plot understanding, offering accessible resources on their web page."
"This research investigates how movie ratings from professional critics, amateur communities, and viewers
themselves influence key movie performance measures (i.e., movie revenues and new movie ratings). Using movielevel data, the authors find that high early movie revenues enhance subsequent movie ratings. They also find that
high advertising spending on movies supported by high ratings maximizes the movie’s revenues. Furthermore, they
empirically show that sequel movies tend to reap more revenues but receive lower ratings than originals. Using
individual viewer–level data, this research highlights how viewers’ own viewing and rating histories and movie
communities’ collective opinions explain viewer satisfaction. The authors find that various aspects of these ratings
explain viewers’ new movie ratings as a measure of viewer satisfaction, after controlling for movie characteristics.
Furthermore, they find that viewers’ movie experiences can cause them to become more critical in ratings over time.
Finally, they find a U-shaped relationship between viewers’ genre preferences and genre-specific movie ratings for
heavy viewers.","This study explores the influence of ratings from critics, amateur communities, and viewers on movie performance. High early revenues positively affect subsequent ratings. Effective advertising with high ratings maximizes movie revenues. Sequels generate more revenue but receive lower ratings than originals. Viewer-level data reveals how personal histories and community opinions influence satisfaction. Various rating aspects explain new movie ratings. Viewer experiences make them more critical over time, and heavy viewers exhibit a U-shaped relationship between genre preferences and genre-specific ratings."
"Although e-cigarette use among US youth decreased in 2016 for the first time since 2011,1 2 with the introduction of the new generation of nicotine vapourisers, ‘pods,’ this trend may not continue. Pods are compact, lightweight, ultraportable and easy to use inconspicuously. Popularity of these devices has increased in the past year, most notably, one brand, Juul. Use of Juul and similar products (‘juuling’) among youth has parents, teachers and the lay public appropriately concerned. However, to date, there are no data on nicotine exposure among youth who use pod systems.","E-cigarette use among US youth declined in 2016, but the introduction of compact 'pods' has raised concerns about a resurgence. These devices, notably the brand Juul, are discreet and gaining popularity. Termed 'juuling,' their use among youth sparks worry. Despite this, there is a lack of data on nicotine exposure among pod system users."
"Egeria became the god of Fontaine after Remus' death, uniting the various tribes that remained after Remuria's destruction. She established Fontaine's laws and was known by various titles, including ""Noble Navigator,"" the ""Ruler of Rivers and Seas,"" and the ""Queen of All Waters.""[8] Little is currently known about Egeria's reign, although it is believed that she knew about Fontaine's future conundrums; rumors claim that the prophecy now spreading around Fontaine — that all Fontainians are born with sin, and that the waters will rise and dissolve the people of Fontaine, leaving only Focalors behind — are rooted in Egeria's last words.[11] In The Final Feast, Egeria states: ""The original sin is the fairest: Everyone sinks... Make the most of the final feast, because for the sinners, the curtain call has come,"" although this has not been identified as her last words.

Egeria is the alleged creator of the Oceanids, and although this view has been challenged by later researchers,[12] the Oceanids willingly followed Egeria and the strongest of them traveled all over Teyvat to follow Egeria's command of ""connect[ing] everyone in the world.""[13] Following Egeria's death, many of the Oceanids chose not to return to Fontaine, in part out of a refusal to recognize the new Hydro Archon Focalors,[13] and in part because Fontaine's waters suddenly grew bitter from pain and hate, and finding other sources of pure water was necessary for survival.[14] With Egeria's death, most of Fontaine's waters are no longer capable of naturally creating Oceanids.[15]

When the cataclysm struck and the Abyss' power emerged all over Teyvat, Egeria was among the Archons who fought at Tunigi Hollow. After she was slain, her body transformed into the pure, primordial waters of the Amrita, from which Greater Lord Rukkhadevata grew the Harvisptokhm. When even the Amrita began to succumb to the Abyss, Rukkhadevata summoned Simurgh, the Khvarena given to her long beforehand by the late Nabu Malikata, to drink from the Amrita and burst into thousands of motes of Khvarena which would then cleanse the Abyss' defilement.[9] The Pari, who are motes of Khvarena which have sentience, consider the Harvisptokhm their god.[16]","Egeria, posthumously Fontaine's god, united tribes and established laws. Tied to a prophecy, little is known about her reign. Allegedly creator of Oceanids, they followed her command to connect the world. After her death, Oceanids rejected the new Hydro Archon Focalors due to bitter Fontaine waters. Amid the Abyss' emergence, Egeria's body transformed into primordial waters, aiding in cleansing. The Harvisptokhm, viewed as a god by the Pari, emerged from this."
"An Oceanid legend states that after the Dragon of Water was removed from its position as the ""heart"" of the Primordial Sea, the Shade of Life, one of the Four Shades of the Primordial One, created Egeria as the Primordial Sea's new heart. Despite the Primordial One's alien origins, Egeria's substance and essence were formed entirely from material originating from Teyvat. At the time, no divine duty had been assigned to her.[17]

According to legend, the first Oceanid was born after Egeria shed the ""first tear,"" which then gave birth to all other Oceanids. Egeria bestowed a task to the Oceanids ""to seek an understanding of the diverse array of species and to love every creature."" The Oceanids, following their master's desire to connect everyone in the world, thus dispersed across the waters of Teyvat to act as spies,[Note 1] the most powerful of whom was Rhodeia of Loch.[13] However, Endora — communicating on Rhodeia's behalf — denies any ulterior motive on Egeria's part.

Egeria's followers soon desired to live on the surface, having seen and envied human life. Not wanting to refuse her followers, Egeria decided to fulfill the request herself, taking water from the Primordial Sea and inserting it into the Oceanids' ""blood"" vessels, thus creating humanoid forms for them to walk on land. This act of ""life"" did not go unnoticed by Celestia, who deemed it a sin and sentenced her to be sealed for her crimes, claiming that a prophecy would come to dissolve the people of Fontaine back into their original forms.","Legend tells of Egeria, created by the Shade of Life to replace the Dragon of Water as the Primordial Sea's heart. Despite the Primordial One's alien origins, Egeria's essence originated solely from Teyvat. She birthed the first Oceanid with a tear, tasking them to understand and love all species, dispersing to connect the world. Her followers, desiring human life, were granted humanoid forms by Egeria, deemed a sin by Celestia. A prophecy foretells Fontaine's people reverting, leading to Egeria's sealing for her ""crimes."""
"After Remuria was destroyed by conflicts and rebellions, Celestia commanded Egeria to return from her primeval prison to take over Remus' position and rule Fontaine.[18] Egeria returned to Fontaine and gathered the survivors, mediated between their feuds, and instructed them to establish new cities around flowing springs, thus commencing an era guided by law which has endured to the present day.[19] She was awarded a Gnosis,[17] ascended as the Hydro Archon, and became one of The Seven.[9]

She exiled all of the criminals from her nation, who lived in misery as they were shunned by society. Eventually, some of these criminals begged for forgiveness, which she heard through the waters. Egeria granted their wish for redemption, ordering them to guard her secret beneath the waves, which they did. This resulted in the construction of the Fortress of Meropide, a living place for them, with its main purpose to stop the path leading to the Primordial Sea, though this was eventually forgotten over time.

While knowing she could not make an enemy of the divine, Egeria did not want harm to befall her followers because of the prophecy. She assigned Focalors, one of her Oceanid followers, to be her successor, hoping that she would be able to concoct a plan to deceive Celestia.[20]","After Remuria's destruction, Celestia tasked Egeria with leading Fontaine. She united survivors, established cities around springs, and ushered in an era of law. Awarded a Gnosis, Egeria ascended as the Hydro Archon, becoming one of The Seven. She exiled criminals, later granting redemption to those who sought it. They built the Fortress of Meropide, protecting her secret beneath the waves. Knowing the prophecy, Egeria appointed Focalors as her successor to devise a plan against Celestia without harm to her followers."
"ve hundred years prior to the events of the main story, the cataclysm began. Egeria was among several gods who ventured to Tunigi Hollow to combat the forces of the Abyss spewing forth from the rift there. However, she was eventually slain during the conflict, and her body was subsequently turned into a pool of pure dew called the Amrita.[9]

As Egeria had been stained by corruption and unable to be reborn in a purer plane, Greater Lord Rukkhadevata grew the Harvisptokhm from the Amrita, allowing Egeria's consciousness to remain anchored to the mortal realm by dwelling within the Gaokerena, a giant lotus within the Harvisptokhm.[21] The power of the Harvisptokhm would maintain the seal and absorb the defilement at Tunigi Hollow, keeping the Abyss at bay for years to come while the Amrita nourished the Vourukasha Oasis around the Harvisptokhm.[16]

Eventually, as the corruption of the defilement began taking its toll on the Harvisptokhm, a Khvarena bird named Simurgh was forced to make her destined sacrifice by drinking the water of the Amrita and transmuting herself into limitless Khvarena lifeforms. This resulted in the creation of the sentient Pari and other Khvarena forms, who began to defend and worship the Harvisptokhm as their god.[16]","Five hundred years prior, Egeria and gods battled the Abyss at Tunigi Hollow. Slain, Egeria became Amrita. Unable to be reborn, Rukkhadevata grew the Harvisptokhm, anchoring Egeria's consciousness. Harvisptokhm's power sealed Tunigi Hollow, nourishing Vourukasha Oasis. As corruption grew, Simurgh sacrificed herself, creating Pari and defending the Harvisptokhm."
"Following Egeria's passing, she was succeeded as Hydro Archon by Focalors. However, the Oceanids, who worshipped Egeria and refused to recognize Focalors as the new Hydro Archon, ventured to the Harvisptokhm in search of their master.[22] Upon discovering what remained of their former god, the Oceanids spread across Teyvat to continue their former god's wish in exile.[23] Since then, many of the Oceanids have cut all ties with Fontaine.[13]

Over 400 years ago, Rene de Petrichor, Jakob, and Karl Ingold traveled to the Girdle of the Sands in hopes of finding a way to avert Fontaine's impending water crisis. There, Rene discovered that his and Jakob's physical constitutions were similar to the Gaokerena's, but Karl's was not.[24]","After Egeria's death, Focalors succeeded as Hydro Archon, but the Oceanids, loyal to Egeria, rejected Focalors. They searched for their former god at the Harvisptokhm and, upon discovering her remnants, scattered across Teyvat to fulfill her wish in exile, cutting ties with Fontaine. Over 400 years ago, Rene de Petrichor, Jakob, and Karl Ingold sought a solution to Fontaine's water crisis at the Girdle of the Sands. Rene and Jakob shared a constitution with the Gaokerena, unlike Karl."
"Zhongli is a calm, reserved, and polite man, who holds an air of nostalgia. Whereas he is said to have a stoic demeanor for duty, Zhongli also has a sentimental side.[2] He knows much about Liyue history and culture in part due to his time as the Geo Archon; like Venti, he has many experiences and memories, as he was a god well before The Seven even existed and one of the oldest still living in Teyvat. He holds philosophical ideas towards money and has great respect for Liyue's traditions, including those that have been forgotten or warped over time. Zhongli tends to be humble, being worried he comes off as a ""bourgeois parasite.""[3]

Zhongli tends to forget about Mora in transactions, agreeing to spend large sums of it without having any Mora on hand and even taking ""discounts"" as granted despite being an obvious scam.[4] He often ends up relying on his acquaintances for financial support, such as the Wangsheng Funeral Parlor or Childe. Although he works for Hu Tao,[5] he does not like her childish behavior.[6]","Zhongli, the Geo Archon, exudes calmness and politeness with a hint of nostalgia. Despite his stoic duty-bound demeanor, he harbors a sentimental side. Well-versed in Liyue's history, he, like Venti, predates The Seven and possesses profound memories. Zhongli values money philosophically and respects Liyue's traditions, fearing he might seem like a ""bourgeois parasite."" Surprisingly, he often forgets about Mora in transactions, relying on friends like the Wangsheng Funeral Parlor or Childe for financial aid, despite disliking the childish antics of his colleague Hu Tao."
"It is later revealed that Zhongli's ""carelessness"" stems from being the creator of Mora. With the Gnosis allowing him to create limitless Mora, he never had to worry about running low on his personal finances. Unfortunately, when he chose to live among mortals, he lacked the foresight to find an alternative for them to continue minting Mora in his absence, along with creating a retirement fund for himself. As a result, he shamelessly spends the Mora of others.

Being the reminiscent person he is, Zhongli enjoys Osmanthus wine as it was the drink he and his former Archon friends used to have when they met up in Liyue. He dislikes seafood as it reminds him of the promise he made to his people in the past when he fought a particularly annoying type of sea creature, although he does not mind eating them if they have been ground to a pulp.","Zhongli's apparent financial carelessness stems from being the creator of Mora, thanks to his Gnosis. Living among mortals, he overlooked ensuring a steady Mora source for them, shamelessly spending others' currency. His fondness for Osmanthus wine reflects nostalgia for moments with former Archon friends in Liyue. However, he avoids seafood due to a past promise, only accepting it if pulverized. This revelation adds depth to Zhongli's character, showcasing both his divine history and the quirks that tie him to mortal experiences."
"Zhongli uses the tall male model. He has fair skin, amber eyes with yellow diamond-shaped pupils and red eyeliner on the lower lids of his eyes, and mostly short dark brown hair with a longer fringe on the right side of his face and Geo-amber tips that glow when he uses his Elemental Skill or Elemental Burst. There is one section of his hair on the back of his head that is waist-length instead of being cut short.

Zhongli's form appears to be the same as the one he uses as an Archon, as seen in his Statues of The Seven and various cinematics that show him as an Archon.

The Geo Vision seen at the small of his back behaves like other characters' Visions in most gameplay; however, it is not a real Vision, and there are a select few gameplay mechanics that reflect this.","Zhongli, a tall figure with fair skin and amber eyes, sports short dark brown hair with a longer fringe on the right. Geo-amber tips glow during his Elemental Skill or Burst. Resembling his Archon form, the back features waist-length hair. His Geo Vision, seen at his back, mimics others but behaves uniquely in certain gameplay aspects, hinting at its non-authentic nature."
"roduct testing results and participants’ high urinary cotinine levels provide physiological evidence for significant nicotine exposure among pod users. Indeed, such high cotinine levels raise concerns about the potential for earlier and more significant nicotine addiction in teens. Although the exact physiological mechanisms of nicotine salts are not well studied, these compounds are believed to increase the amount and rate of nicotine uptake in e-cigarette users.7 Potential health risks of repeated inhalation of high doses of nicotine salts are unknown.

Study limitations include small sample size and a convenience sample of adolescents presenting to clinics in suburban Long Island, New York. These findings are not representative of the entire population of US adolescents and may not be generalisable to other e-cigarette user groups. Additionally, survey response to self-reported pod use in the past 7 days may introduce recall bias.

Clinicians must be aware of and educate their patients about the potential for long-term sequelae of using e-cigarettes, especially pods. Public health advocates and regulatory agencies must act now to restrict youth access to e-cigarettes before decades of progress in tobacco control is undone. On 24 April 2018, Food and Drug Administration announced several enforcement actions as part of a new Youth Tobacco Prevention Plan to stop youth use of and access to Juul and other e-cigarettes. Additionally, raising the legal age to 21 years (‘Tobacco 21’) to purchase tobacco products has gained traction as an evidenced-based measure to prevent teen access to all tobacco products, including e-cigarettes.","High urinary cotinine levels in pod users signal significant nicotine exposure, raising concerns about teen addiction. The study, limited by a small sample and location specificity, may not universally apply. Nicotine salts' physiological impact remains unclear. Clinicians must inform patients of long-term risks, urging regulatory action. Initiatives like the FDA's Youth Tobacco Prevention Plan and 'Tobacco 21' strive to curb youth access, safeguarding public health."
"News coverage of novel tobacco products including e-cigarettes has framed the use of these products with both positive and negative slants. Conflicting information may shape public knowledge, perceptions of e-cigarettes, and their harms. The objective of this study is to assess effects of exposure to conflicting news coverage on US adults’ beliefs about harms and benefits of e-cigarette use. We conducted a one-way between-subjects randomized controlled experiment in 2016 to compare the effects of viewing either 1) positive, 2) negative, 3) both positive and negative (conflicting) news headlines about the safety of using e-cigarettes, or 4) no-message. Participants were 2,056 adults aged 18 and older from an online survey panel. Outcomes were beliefs about harms (3-item scale, α=0.76) and benefits (3-item scale, α=0.82) of using e-cigarettes. Participants who viewed negative headlines reported increased beliefs about harms (B=0.164, p=0.039) and lower beliefs about benefits of e-cigarette use (B=−0.216, p=0.009), compared with those in the positive headlines condition. These differences were replicated in subgroup analyses among never e-cigarette users. In addition, never e-cigarette users who viewed conflicting headlines reported lower beliefs about benefits of e-cigarette use (B=−0.221, p=0.030) than the positive headlines condition. Valence of news coverage about e-cigarettes (positive, negative, or conflicting) could influence people’s beliefs about harms and benefits of e-cigarette use.","Exposure to news coverage significantly influences US adults' beliefs about e-cigarette harms and benefits. A randomized controlled experiment revealed that participants exposed to negative headlines held increased beliefs about harms and lower beliefs about benefits of e-cigarettes. These effects were consistent among never e-cigarette users, indicating a broader impact. Conflicting headlines also contributed to lower beliefs about benefits. This study emphasizes the role of media portrayal in shaping public perceptions of novel tobacco products, urging a nuanced approach to reporting for a more informed public."
"Abstract
We evaluated the in vitro digestibility of apple polyphenols mimicking elderly and adult digestion models (dynamic and static systems). The digestibility of total apple polyphenols in small intestine was much higher in the adult dynamic system (62 μg/100 g fresh apple) compared to the static system (20 μg/100 g fresh apple) and elderly dynamic digestion conditions (33 μg/100 g fresh apple). Elderly in vitro static digestion showed better antioxidant activity than the adult system (radical dotOH and ABTS+ methods). Thus, the in vitro dynamic digestion system can more truly reflect the digestion of apple polyphenols than static digestion system. Moreover, elderly digestion conditions negatively influenced the digestibility of apple polyphenols including chlorogenic acid, epicatechin, phlorizin, rutin, phloretin, hyperoside, proanthocyanidin B2, and quercetin. Hence, appropriate selection of in vitro digestion models for elderly is a prerequisite to exploring the digestibility of phytochemicals for the development of functional food products for elderly.

Introduction
The world's elderly population (aged more than 65) is expected to double from 11% to 22% in the first five decades of the 21st century (Hernández-Olivas, Muñoz-Pina, Andrés, & Heredia, 2020). As lifestyle, body composition, nutrition requirements, digestion ability and absorption of different kinds of foods decrease with the age, the wellness of the elderly population has become a global concern (Didier et al., 2015). Compared with the digestive system of adults, the function and composition of the digestive system of the elderly have changed, such as the reduction of pepsin levels and intestinal secretions, and a lower proportion of intestinal microflora firmicutes and bifidobacteria (groups with anti-inflammatory effects), while the number of some inflammation-promoting bacteria, such as enterobacteria is known to increase (Denis et al., 2016, Salles, 2007). Moreover, there are great differences in salivary secretion, gastrointestinal peristalsis function, and electrolyte composition of digestion fluids in different digestive systems. Hence, easily digestible food is the first choice to maintain the diet balance for the elderly, which not only includes protein, lipids, carbohydrate, and other micro-nutrients but also some phytochemicals from the plant, such as polyphenols, carotenoids, phytosterols, saponins, and others. Intake of polyphenols has an important functional role for human as it can provide protection against several chronic diseases such as cardiovascular, cancers, type II diabetes, neurodegenerative disease, and osteoporosis (Andriantsitohaina et al., 2012, Pandey and Rizvi, 2009, Tresserra-Rimbau et al., 2016, Wedick et al., 2012). Among all the fruits, apples are enriched with polyphenols, minerals, dietary fiber, and other nutrients (Qi, Chen, & Yang, 2003). Studies have shown that the intake of polyphenols is related to the prevention of diseases most likely to affect the elderly (obesity and related metabolic disorders) (Tiande et al., 2020; Tamura et al., 2020, Martino et al., 2019, Zou et al., 2020). However, these benefits are limited for the elderly because the change in the digestive system with age and inefficient absorption.

Many in vitro digestion models including static and dynamic systems have been explored to estimate the in vivo digestion behavior after meals since the 1990s, and most of the research was done by using static in vitro digestion model (Ferrua and Singh, 2010, Kamiloglu et al., 2017, Renata et al., 2017). Compared to dynamic models, static models just mimic digestion pH, enzyme, salt, and digestion time using glass containers which cannot accurately simulate the mechanical forces from GI peristalsis, digestive juices secretion, and the mixed reaction between food and digestive liquids in the internal environment of the human body (Liu et al., 2020, Teng and Chen, 2019). A new dynamic in vitro digestion system had been developed as dynamic in vitro human stomach and intestine (DIVHS) by Suzhou Key Laboratory of Green Chemical Engineering, Soochow Univesity (Suzhou, China) (Wang et al., 2019). The new DIVHS (Fig. 1) includes a J-shaped soft-elastic stomach followed by a duodenum vessel, an electromechanical driving instrument, a secreting and emptying system, and a temperature-controlled box. 3D-printed J-shape soft elastic silicone stomach vessel constitutes internal folds similar to morphological structures and geometrical dimensions of the actual human stomach and two silicone tubes to simulate intestinal secretory glands (Wang et al., 2019). A duodenum vessel contains the same silicone rubber as stomach, which has a similar length and diameter to in vivo conditions (DeSesso & Jacobson, 2001). Peristaltic contractions and sieving effect on the stomach and duodenum are provided by an electromechanical driving instrument, which creates the mechanical force on food similar to in vivo environment, and the system is equipped with an auxiliary gastric emptying device to control the emptying rate of the system by adjusting the tilting angles. A power-exponential model can regulate the gastric emptying rate, half-time, and lag phase time, similar to that obtained in vivo (Wang et al., 2019).

Based on the differences of digestive system function and composition between adults and elderly, as well as the differences between dynamic and static digestion systems, we speculated that there will be great differences in the digestion of polyphenols in different age groups and digestion systems. Therefore, in the present study, fresh apples were selected as polyphenols sources to explore the digestibility difference of polyphenols caused by the alterations of elderly GI. The adult and elderly GI conditions were carried out in a new DIVHS and in vitro static systems to explore the differences (qualitative and quantitative) in digestibility for apple polyphenols between different age groups and simulation methods. Further, the relationship between antioxidant activity of digestive juices and polyphenols was also analyzed.","The introduction discusses the importance of understanding the digestibility of apple polyphenols, particularly in the context of elderly individuals. The aging process leads to changes in the digestive system, making it essential to assess how polyphenols are digested and absorbed in elderly individuals to develop functional food products tailored to their needs.

Various factors, including reduced digestive enzyme levels, alterations in gastrointestinal peristalsis, and shifts in gut microflora composition, contribute to differences in digestion between adults and the elderly. The introduction highlights the significance of easily digestible foods for the elderly, including those rich in polyphenols, which offer potential health benefits.

The study employs in vitro digestion models, both static and dynamic, to mimic digestion in different age groups and assess the digestibility of apple polyphenols. The dynamic in vitro human stomach and intestine (DIVHS) system is introduced as a more sophisticated and accurate model for simulating digestion compared to static models.

The research aims to explore the differences in the digestibility of apple polyphenols between adults and the elderly, as well as between dynamic and static digestion systems. Additionally, the relationship between antioxidant activity and polyphenol digestion is investigated.

Overall, the introduction sets the stage for the study's objectives and highlights the importance of understanding polyphenol digestibility in the elderly population. It provides context for the research methodology and the rationale behind the experimental design."
"Introduction
Feedforward artificial neural networks (ANNs) are currently being used in a variety of applications with great success. Their first main advantage is that they do not require a user-specified problem solving algorithm (as is the case with classic programming) but instead they “learn” from examples, much like human beings. Their second main advantage is that they possess an inherent generalization ability. This means that they can identify and respond to patterns that are similar but not identical to the ones with which they have been trained. On the other hand, the development of a feed-forward ANN model also poses certain problems, the most important being that there is no prior guarantee that the model will perform well for the problem at hand. The whole ANN modelling procedure has been investigated with the aim of introducing systematic ways that would lead to ANN models with consistently good performance. The focus of these methods has been in virtually every aspect of ANN model development such as training data collection, data pre- and post-processing, different types of activation functions, initialization of weights, training algorithms and error functions.

While all of these affect ANN performance, increased attention has been especially directed to finding the best architecture. This is justified not only by the fact that it is directly associated with the model's performance but also because there is no theoretical background as to how this architecture will be found or what it should look like. The most typical method followed is a repetitive trial-and-error process, during which, a large number of different architectures is examined and compared to one another. Therefore, this process is very time-consuming and is mainly based on the human expert's past experience and intuition, thus involving a high degree of uncertainty. Despite the increased level of research activity, the described problem has not yet been answered definitively. Nevertheless, the different approaches can be categorized as follows: (i) empirical or statistical methods that are used to study the effect of an ANN's internal parameters and choose appropriate values for them based on the model's performance (Khaw et al., 1995; Maier and Dandy, 1998a, Maier and Dandy, 1998b; Benardos and Vosniakos, 2002). The most systematic and general of these methods utilizes the principles from Taguchi's design of experiments (Ross, 1996). The best combination of number of hidden layers, number of hidden neurons, choice of input factors, training algorithm parameters etc. can be identified with these methods even though they are mostly case-oriented. (ii) hybrid methods such as fuzzy inference (Leski and Czogala, 1999) where the ANN can be interpreted as an adaptive fuzzy system or it can operate on fuzzy instead of real numbers. (iii) constructive and/or pruning algorithms that, respectively, add and/or remove neurons from an initial architecture using a previously specified criterion to indicate how ANN performance is affected by the changes (Fahlman and Lebiere, 1990; Rathbun et al., 1997; Balkin and Ord, 2000; Islam and Murase, 2001; Jiang and Wah, 2003; Ma and Khorasani, 2003). The basic rules are that neurons are added when training is slow or when the mean squared error is larger than a specified value, and that neurons are removed when a change in a neuron's value does not correspond to a change in the network's response or when the weight values that are associated with this neuron remain constant for a large number of training epochs. Since both constructive and pruning algorithms are basically gradient descent methods, their convergence to the global minimum is not guaranteed and so they can be trapped to a local minimum close to the point of the search space from which the algorithm started. (iv) evolutionary strategies that search over topology space by varying the number of hidden layers and hidden neurons through application of genetic operators and evaluation of the different architectures according to an objective function (Bebis et al., 1997; Liu and Yao, 1997; Yao and Liu, 1997, Yao and Liu, 1998; Castillo et al., 2000; Arifovic and Gencay, 2001).

This paper proposes a methodology for determining the best architecture that falls into this last category. It is based on the use of a genetic algorithm (GA) and the development of novel criteria that quantify an ANN's performance (both training and generalization) as well as its complexity. The detailed presentation of the approach is given in Section 2 of the paper, and a critique of its main differences and advantages in comparison to similar methods is presented there, too, in order to highlight its originality.","
The introduction outlines the significance of feedforward artificial neural networks (ANNs) in diverse applications, emphasizing their ability to learn from examples and generalize patterns. However, it recognizes the challenge of determining the optimal ANN architecture, which is typically an iterative and time-consuming process. To address this, the paper proposes a novel genetic algorithm-based methodology for systematically identifying the best architecture by quantifying both performance and complexity. This approach offers a promising solution to the architecture problem in ANN development."
"Introduction Neural networks are well known as powerful tools in the area of pattern classification. In principle, multi-layer feed-forward networks with just a single hidden layer are universal approximators for arbitrary finite-input environment measures. This however does not imply that a neural network can easily learn the underlying functional mapping between the input data and the desired output. In fact, the main drawbacks of neural networks are problems associated with local minima and the slow convergence of the learning process. To tackle these problems, neural networks are increasingly using clustering techniques to reduce learning complexity. A cluster can be modeled by a hypersphere represented by its center, i.e., the “prototype” and its radius, which determines the “region of influence” of the cluster. Prototypes used in initializing the weights of back propagation networks are known to yield reductions in training time [1]. Various clustering techniques have also been used to reduce the number of neurons in radial basis function and probabilistic neural networks [2], [3], [4], [5], [6], [7]. In Ref. [8], a multi-objective genetic algorithm was employed to partition the pattern space into hyperspheres for mapping onto a hierarchical neural network to facilitate subsequent learning. In addition to these approaches devoted to reduce learning complexity and the number of hidden nodes, several existing neural network learning algorithms can themselves be regarded as some kind of clustering methodology, for example competitive learning [9], self-organizing map and learning vector quantization (LVQ) [10]. It is therefore quite evident that clustering techniques form the core learning procedure for numerous neural network models. Traditional clustering methods [11], [12], [13], [14] placed adjacent samples of the training set in a single cluster without taking into account their class assignments. The obvious drawback of these approaches is the missing class membership information, which is crucial for any classification learning procedure. Duda presented a training algorithm for cluster prototypes [15] while the LVQ approach [10] modifies the position of the prototypes through a training procedure on all input data. Both these algorithms require the number of prototypes to be defined and good initialization of the prototype values before training. Kong proposed a variant of these basic paradigms [16]. All these methods result in piecewise linear classifiers. The generalization capability is thus relatively poor. The distribution of the prototypes approximates the distribution of the learning data. This results in that each prototype of one class represents a cluster that encloses roughly equal number of learning samples. To form a complicated decision boundary, a large number of prototypes are therefore needed to precisely approximate the training data distribution. In RCE approach [17], prototypes can neither be modified nor removed, but any misclassification reduces the scope of the prototype vector. Thus, the RCE clustering technique does not minimize the number of clusters that a particular classification task requires. Musavi meanwhile presented a clustering algorithm [5] to reduce the number of nodes of RBF networks. As clusters are restricted from enclosing any samples of the other classes, this technique usually leads to a large number of clusters. In view of the drawbacks of methods discussed above, we present an efficient iterative locally trained clustering (LTC) technique, which generates clusters sequentially, moves cluster's centers generally away while enlarging their scope towards the Bayes decision surfaces by using local subsets of the training data. Clusters therefore grow to contain more and more samples within the Bayes decision region during training. The procedure for training a cluster is based on a local subset of training data. Thus, the complex training data-structures that are far from a cluster will not increase the complexity of the training procedure for this cluster. The ground ideas of this training procedure are decomposing a complicated data structure of the whole training set into a number of simple subsets, modifying and enlarging clusters to let them capture training samples as more as possible so long as the clusters are within the Bayes decision region. Therefore, this procedure simplifies the training and minimizes the number of clusters. The obtained clusters are then used to construct a feed-forward neural network, which contains piecemeal knowledge obtained from the individual local learning procedures. Finally, all the individual pieces of knowledge are integrated and generalized by training the constructed network using the entire set of training data. The resulting locally and globally trained (LGT) network is then applied on several benchmark classification problems to access its performance and compare it with other representative clustering approaches and neural networks.","In the field of pattern classification, neural networks are recognized for their power. While single-hidden-layer feed-forward networks are universal approximators, they face challenges related to local minima and slow convergence during learning. To address these issues, clustering techniques are increasingly integrated into neural network models to simplify learning complexity. Clusters are represented by hyperspheres with centers (prototypes) and radii that define their influence regions. Clustering methods are employed to reduce the number of neurons in various neural network types, including radial basis function networks and probabilistic neural networks. Traditional clustering techniques overlook class assignments, limiting classification capabilities. This paper introduces an iterative locally trained clustering (LTC) technique that sequentially generates clusters, expanding their influence regions toward Bayes decision surfaces. The LTC approach simplifies training, minimizes the number of clusters, and enhances generalization. The resulting locally and globally trained (LGT) neural network is evaluated on benchmark classification problems, demonstrating its performance compared to other clustering and neural network methods."
"Abstract Advanced Traveller Information Systems (ATIS) is one of the functional areas of Intelligent Transportation Systems (ITS) and it aims at providing real time traffic information to the travellers for making better travel decisions. This information would be most effective if provided to travellers during or before the start of their trip. Therefore, accurate prediction models are required in ATIS for conveying reliable information about the future state of traffic. Different methods used for the prediction of traffic parameters include historic averaging, regression analysis, Kalman filtering, time series analysis, machine learning, etc. The objective of this research is to explore the use of automated sensor data and data driven techniques for traffic state prediction under Indian traffic conditions. Travel time and traffic density (as an indicator of congestion) are used commonly to inform users about the state of a traffic system. However, these two parameters are spatial in nature and direct measurement from field is difficult. Therefore, estimation of these parameters from location based data is a challenge in many of the ITS implementations. The present study addresses the problem of estimation of traffic density with the help of location based sensors which are capable of measuring parameters such as volume and Time Mean Speed (TMS). Machine learning techniques namely, k-Nearest Neighbour (k-NN) and Artificial Neural Network (ANN) are selected as the estimation and prediction tool in this study, based on acceptable performance of the same in earlier studies.","The study focuses on Advanced Traveller Information Systems (ATIS), a component of Intelligent Transportation Systems (ITS) that provides real-time traffic information to travelers for better decision-making. To enhance the effectiveness of this information, accurate prediction models are essential for conveying reliable future traffic conditions. Various methods, including historic averaging, regression analysis, Kalman filtering, time series analysis, and machine learning, have been used for traffic parameter prediction. This research explores the use of automated sensor data and data-driven techniques for traffic state prediction in Indian traffic conditions, specifically addressing the challenge of estimating traffic density from location-based data. Machine learning techniques, namely k-Nearest Neighbour (k-NN) and Artificial Neural Network (ANN), are employed for traffic density estimation based on their proven performance in previous studies."
"Introduction The food industry is facing the challenge of developing new foods with increased health benefits and meeting consumers’ appreciation. In fact, with the surge in the incidence of cardiovascular diseases, cancer and type-2 diabetes, there is a need to develop new dietary strategies, especially with reference to the potential health properties of underutilized by-products of food processing (Hokayem et al., 2013, Schieber et al., 2001). Grape (Vitis vinifera) pomace, the by-product of winemaking, is a bioresource available on a large-scale as grape constitutes one of the main fruit crops in the world. Grape pomace contains both phenolics and dietary fibres, thus it can be referred to as “antioxidant dietary fibre”. Due to the close relationship between antioxidant and dietary fibre, and their common fate in the gut, it has been proposed that these food components have a joint role in prevention of human diseases (Perez-Jimenez et al., 2008). In vivo studies on human adults have demonstrated that grape pomace has a positive effect in the prevention of cardiovascular diseases (Perez-Jimenez et al., 2008). The anti-diabetic efficiency of grape polyphenols was tested in type-2 diabetic patients, resulting in improved insulin resistance and suppressed oxidative stress (Hokayem et al., 2013). These results have boosted the use of grape pomace as an ingredient in new functional foods, such as bread (Mildner-Szkudlarz, Zawirska-Wojtasiak, Szwengiel, & Pacynski, 2011), fish products (Pazos et al., 2005, Ribeiro et al., 2013), meat products (Sayago-Ayerdi, Brenes, & Goni, 2009) and yoghurt (Tseng & Zhao, 2013). The development of foods that provide additional health benefits beyond basic nutrients is also a trend in the fruit processing industry (Augusto, Falguera, Cristianini, & Ibarz, 2011). The aim of the present study was to assess the prospective use of a phytochemical- and fibre-rich ingredient recovered from winemaking by-products for the development of a new tomato-based product. Technological challenges raised by fortification were studied, such as: the choice of the particle size of the suspension, the incorporation of an adequate level of the new ingredient, the choice of pasteurisation conditions, the processing effect on phenolic stability and the need to address consumers’ liking.","The food industry is increasingly focused on creating healthier food options to address rising health concerns like cardiovascular diseases, cancer, and type-2 diabetes. This has led to a growing interest in utilizing underutilized by-products of food processing for their potential health benefits. One such by-product is grape pomace, generated during winemaking, which is rich in both phenolic compounds and dietary fiber, often referred to as ""antioxidant dietary fiber."" Research has shown that grape pomace can play a role in preventing diseases like cardiovascular diseases and type-2 diabetes. As a result, grape pomace has been incorporated into various functional foods, including bread, fish products, meat products, and yogurt. This study aims to explore the use of grape pomace, a phytochemical- and fiber-rich ingredient, obtained from winemaking by-products, in the development of a new tomato-based product. The study addresses various technological challenges, including particle size selection, ingredient incorporation, pasteurization conditions, phenolic stability during processing, and consumer preferences."
"Introduction Meat and meat products are essential components in the diets of developed countries. Their consumption is affected by various factors. The most important ones are product characteristics, consumer and environment related (Jiménez-Colmenero, Carballo, & Cofrades, 2001). Health promoting functional foods, prepared on basis of meat is becoming more and more popular. Chicken meat has many desirable nutritional characteristics such as a low lipid content and relatively high concentration of polyunsaturated fatty acids which can be further increased by specific dietary strategies (Bourre, 2005). However, a high degree of polyunsaturation accelerates oxidative processes leading to deterioration in meat flavor, color, texture and nutritional value (Mielnick, Olsen, Vogt, Adeline, & Skrede, 2006). The major strategies for preventing lipid oxidation are the use of antioxidants and restricting the access to oxygen during storage vacuum-packaging (Tang, Kerry, Sheehan, Buckley, & Morrissey, 2001). The antioxidant additives are added to fresh and further processed meats to prevent oxidative rancidity, retard development of off-flavors, and improve colour stability (Nam & Ahn, 2003). Synthetic antioxidants such as butylated hydroxytoluene (BHT) and butylated hydroxyanisole (BHA) have been used to control lipid oxidation in meat. However, recent concern over their use (Okada et al, 1990) has created a need and prompted research for alternatives antioxidants, particularly from natural sources. The use of natural preservatives to increase the shelf life of meat products is a promising technology since many vegetal substances have antioxidant and antimicrobial properties. Functional ingredients in meat products may improve the nutritional and health qualities and prolonging their self-life (Fernández-Ginés, Fernández-López, Sayas-Barberá, & Pérez-Alvarez, 2005). Plants' extracts rich in polyphenols are good candidates, since they are easily obtained from natural sources and they efficiently prevent lipid oxidation in food products. Grape seed extract has been evaluated for its antioxidative effect on a few meat types and has been reported to improve the oxidative stability of cooked beef (Ahn, Grun, & Fernando, 2002), turkey patties and cooled stored turkey meat (Lau and King, 2003, Mielnick et al., 2006). Dietary fiber has been considered as a functional ingredient in meat products (Cofrades et al., 2004, Serrano et al., 2006). The inclusion of dietary fiber may improve texture (Cofrades et al., 2004), increase the cooking yield due to water-holding and fat binding properties and also dietary fiber may generate technological properties that improve physicochemical and sensory properties (Jiménez-Colmenero et al., 2003). Dietary fiber and natural antioxidants are two dietary factors involved in health promoting. A natural product that combines high amounts of dietary fiber and phenolics antioxidants such as pehnolics acids, anthocyanidins, proanthocyanidins, catechins and other flavonoides is grape antioxidant dietary fiber (GADF) (Saura-Calixto, 1998, Saura-Calixto and Goñi, Saura-Calixto and Larrauri). Recently, GADF had been successfully used as an ingredient in minced fish (Sánchez-Alonso, Jiménez-Escrig, Saura-Calixto, & Borderías, 2007). The present study was designed to study the effect of grape antioxidant dietary fiber (GADF) on breast chicken hamburgers to reach two objectives: 1) To assess the effectiveness of GADF on lipid stability during refrigerated storage for increasing the shelf life of the food and 2) to incorporate dietary fiber in a meat product to enhance health-beneficial properties. Sensory qualities and acceptability by panellists were also evaluated.","Meat and meat products are staples in many diets, particularly in developed countries. The consumption of these products is influenced by various factors, including their characteristics, consumer preferences, and environmental concerns. In recent years, there has been a growing interest in the development of health-promoting functional foods based on meat. Chicken meat, in particular, is valued for its nutritional attributes, such as low lipid content and relatively high levels of polyunsaturated fatty acids. However, the high polyunsaturation can lead to oxidative processes, affecting the flavor, color, texture, and nutritional quality of meat. To combat lipid oxidation, antioxidants and vacuum packaging are commonly used. Natural antioxidants from plant sources have gained attention as alternatives to synthetic ones. Grape seed extract, rich in polyphenols, has shown promise in improving the oxidative stability of various meat products. "
"Introduction With an unprecedented number of vehicles and network infrastructure complexity, traffic congestion is continuously increasing, and significantly hampering the economic growth and development of countries (Shafiei, Gu, & Saberi, 2018). Therefore, the development of intelligent transportation systems (ITS) is more necessary than ever before (Mammeri, Zuo, & Boukerche, 2016; Simoni & Claudel, 2018; Troiano, Pasero, & Mesin, 2011). Road traffic measurements are a key component of many ITS applications, such as traffic congestion management and incident detection. Different types of sensors are used to collect traffic measurements, such as magnetic loops, radars counters, infrared captors, and surveillance cameras (Ali, George, Vanajakshi, & Venkatraman, 2012a; Saponara & Neri, 2017; Wei, Cappelle, & Ruichek, 2013). Unfortunately, traffic measurements are generally tainted with errors that degrade the preciseness of inferential models and the sensors are costly (Garelli, Casetti, Chiasserini, & Fiore, 2011; Hidayat, Lendek, Babuška, & DeSchutter, 2010). The need for a cost-effective method of traffic data estimation that can accurately predict traffic flow is essential for improving various ITS applications. All over the years, numerous estimation techniques have been developed to estimate data that are challenging or expensive to measure (Sutarto, Boel, & Joelianto, 2015). Model-based estimation techniques are widely applied in the litterature due to their high capacity in parameters estimation (Nantes, Ngoduy, Bhaskar, Miska, & Chung, 2016N, 2016a, 2016n, 2016t, 2016e, 2016s et al., 2016). Major advances in road traffic estimation have been reported and various filter-based traffic estimation methods are suggested like Kalman filters (Wang & Papageorgiou, 2005); such as extended Kalman, particle Kalman (Mihaylova, Boel, & Hegyi, 2007), and Monte Carlo mixture Kalman filters (Sun, Muñoz, & Horowitz, 2003). In (Zhang & Mao, 2015), an interactive multiple models filtering procedure is proposed for estimating traffic state. This mechanism use the Switched Mode Model (SMM) and consider only the fully free and fully congested modes. However, this procedure is time-consuming. In Hidayat et al. (2010), an observer has been designed by transforming a METANET traffic model to the Takagi-Sugeno fuzzy model. In (Morarescu et al., 2010), an estimator, which takes only the congestion wave direction, is designed based on the Luenberger observer and SMM. Other techniques use machine learning mechanisms like neural network (Jithin, Hareesh, & Lelitha, 2016) and altricial-intelligent (Constantinos & Haris, 2006). Recently, intelligent transportation systems (ITS) have been considered as a class of hybrid systems (HDS), where controlling and monitoring these systems remains a fertile domain of research. A traffic system is a physical system with hybrid behavior that can be modeled by considering the interaction between the discrete dynamics (e.g., accident, congestion, free-flow state changing, and traffic lights changing) and the continuous dynamics (e.g., traffic flow and density dynamics). Several efforts have been made to model these hybrid systems. For example, many frameworks have been developed for describing the hybrid behavior of ITS (Muñoz, Sun, Horowitz, & Alvarez, 2006; Zeroual, Messai, Kechida, & Hamdi, 2017). In Zeroual, Harrou, Sun, and Messai (2017), Zeroual, Messai, et al. (2017), a piecewise switched linear traffic model is proposed, it considers both the traffic congestion movement and changes in the traffic flow status with regard to the direction of wave propagation. This model is a macroscopic traffic model that switches among a set of linear subsystems, with each subsystem representing a traffic dynamic. The PWSL model is an improved version of SMM and has the ability to recover most of the phenomena produced by actual traffic (Zeroual, Messai, et al., 2017; Zhang & Mao, 2015). Here, the advantages of the piecewise switched linear (PWSL) model and the features of a model-based estimation methodology are exploited to design an efficient hybrid observer (HO) that accurately estimates road traffic density. An HO is used because of the hybrid nature of the traffic system (i.e., a mix of continuous and discrete dynamics). Moreover, the HO has a good ability to obtain better estimation performance, handle offsets efficiently, increase the rate of convergence, and simplify implementation in real time (Aguilar-López & Martínez-Guerra, 2007; Jarinah, Hoang, Hussain, & Dochain, 2015). This observer provides real-time knowledge about the state of traffic density, permitting us to determine the level of traffic congestion. Also, it compensates for the limitations of sensors and reduces the costs of implementing and maintaining data collection devices. Supervision and road traffic management are essential abilities for the development of intelligent transportation systems so that accidents can be avoided. Reliable detection of traffic congestion provides pertinent information for improving safety and comfort by alerting the driver to crowded roads or providing useful information for rapid decision-making. It helps reduce travel time, wasteful fuel consumption, and pollution, and improves safety. Various detection systems have been developed in recent years for monitoring road traffic congestion. These technologies commonly use inductive loop detectors (sensor-based) and cameras (vision-based). In vision-based techniques, an abnormal traffic flow can be detected based on the features extracted from the collected images. Camera-based surveillance systems become particularly important in traffic monitoring due to their capacity to provide more information and to monitor wide zones (Parkany & Xie, 2005). However, senors-based systems are usually frequently used in traffic monitoring mainly due to their fast response and easy maintenance (Parkany & Xie, 2005). This paper presents a sensor-based approach for estimating and detecting road traffic congestions. An effective traffic congestion detection approach is designed using generalized likelihood ratio (GLR) hypothesis testing (Harrou, Fillatre, Bobbia, & Nikiforov, 2013; Harrou, Fillatre, & Nikiforov, 2014). This methodology has been devised by combining the desirable characteristics of a hybrid observer (HO) with a GLR monitoring chart to uncover abnormal traffic congestion. HO residuals have been exploited as a traffic congestion indicator. HO residuals form Free-flow traffic are around zero due to measurement noise and depart significantly from zero under abnormal traffic congestion. Hence, the GLR approach is applied to HO residuals for monitoring traffic congestion. Furthermore, an exponential weighted moving average (EWMA) is applied to the residual data to reduce high-frequency noise. Thus, as the EWMA filter, make use of all available information from past and actual measurements, it extends the congestion detection abilities of the GLR approach to appropriately detecting congestions and to effectively perform under noisy conditions. The effectiveness of the proposed approach is verified on traffic data from both the four-lane SR-60 freeway in southern California and the three-lane I-210 freeway in the west of California. Results show that the proposed method can effectively reveal potential traffic congestions. Further, we conducted comparisons that highlight the superiority of the proposed method over the conventional Shewhart, GLR, and EWMA methods. The next section briefly reviews related works on traffic monitoring techniques. Section 3 presents the PWSL model. In Section 4, the proposed HO-based estimator, and gives a brief overview of univariate monitoring schemes are described. Section 5 presents the developed HO-GLR approach. Section 6 reviews the experimental results. Finally, conclusions are given in Section 7.","Traffic congestion is a growing problem with the increasing number of vehicles and complex road networks, which has significant economic and developmental implications. As a result, the development of Intelligent Transportation Systems (ITS) has become crucial. Road traffic measurements play a vital role in ITS applications, including traffic congestion management and incident detection. Various sensors are employed to collect traffic data, but they often suffer from errors, and the sensors themselves can be expensive. Therefore, cost-effective methods for accurately predicting traffic flow are essential for improving ITS applications.

Over the years, various techniques have been developed for estimating challenging or costly-to-measure data. Model-based estimation techniques have been widely used due to their ability to estimate parameters accurately. This includes the application of Kalman filters, particle Kalman filters, and Monte Carlo mixture Kalman filters. Additionally, machine learning methods such as neural networks have been used for traffic estimation."
"Abstract Hardaliye is a non-alcoholic beverage produced from red/black grapes by adding mustard seeds and lactic acid fermentation. In this study, it was aimed to determine the total phenolic content (TPC) and total antioxidant capacity (TAC) of hardaliye samples produced with three different grape varieties (Shiraz, Merlot and Cabernet Sauvignon) before and after in vitro digestion, to determine their bioaccessibility, and to investigate their effects on reducing malondialdehyde (MDA) formation in meat products. TPC decreased after in vitro digestion in all three hardaliye samples and their bioaccessibility values were 57.64%, 41.54%, and 52.78% (for Shiraz, Merlot, and Cabernet Sauvignon hardaliye, respectively). After in vitro digestion TAC value according to the DPPH method increased in all samples and according to the CUPRAC method decreased in Merlot and Cabernet Sauvignon hardaliye samples, while it increased in the Shiraz hardaliye. After in vitro digestion, MDA value increased in control meat samples and decreased in the samples treated with hardaliye samples. Although treatment with other beverages was effective in reducing the post-digestion MDA value of some meat samples, the hardaliye samples were more effective in reducing this value and the lowest MDA bioaccessibility (%) values were determined in those treated with hardaliye samples. The samples with the lowest values were meat doner 1 treated with Shiraz hardaliye (10.27%); burger patties 2 treated with Shiraz hardaliye (22.40%); and meatball 2 treated with Cabernet Sauvignon hardaliye (7.12%). These findings indicate that hardaliye has potential beneficial health effects and can be used for the design of healthy eating patterns due to its lipid oxidation reducing potential in the gastrointestinal tract.","
This study examines hardaliye, a non-alcoholic grape-based beverage, focusing on three grape varieties (Shiraz, Merlot, and Cabernet Sauvignon). It assesses their total phenolic content (TPC) and antioxidant capacity (TAC) before and after in vitro digestion, measuring their bioaccessibility. The research also investigates hardaliye's effect on reducing malondialdehyde (MDA) formation in meat products. After digestion, TPC decreases, while TAC values vary depending on the grape variety and assessment method. Notably, hardaliye effectively reduces MDA formation in meat products compared to other beverages, suggesting its potential health benefits and use in healthy dietary patterns."
"Abstract
The main goal of this work was to investigate the impact of impaired mastication on nutrient bioaccessibility of gluten-free bread in the elderly. In vitro boluses were produced with the AM2 masticator by using two types of programming: normal mastication (NM) and deficient mastication (DM). Static in vitro gastrointestinal digestion was performed with the digestive physiology conditions of the elderly. Subsequently, the granulometric properties of the in vitro boluses produced, their starch and protein digestibility, and lipid peroxidation after in vitro oral and gastrointestinal digestion were evaluated. DM boluses presented higher proportions of large particles, resulting in insufficiently fragmented boluses. A delay in oral starch digestion was observed in DM boluses, probably due to the presence of larger particles that limited the bolus-saliva exchanges. Furthermore, DM boluses exhibited a lower degree of protein hydrolysis at the end of gastric digestion, whereas no differences were observed for protein hydrolysis, sugar release, and lipid peroxidation at the end of digestion (intestinal phase). The results of this study show that impaired mastication somewhat delays the nutrient bioaccessibility of the gluten-free bread tested. Such understanding of the effect of oral decline on the nutrient bioaccessibility of foods is crucial when designing food commodities with enhanced functionalities for the elderly.","This research investigates the impact of impaired mastication on the nutrient bioaccessibility of gluten-free bread in elderly individuals. The study simulates in vitro boluses with both normal mastication (NM) and deficient mastication (DM) and subjects them to static in vitro gastrointestinal digestion mimicking elderly digestive conditions. DM boluses contain larger particles, which lead to delayed oral starch digestion. Additionally, DM boluses exhibit reduced protein hydrolysis during gastric digestion, while no significant differences are observed in protein hydrolysis, sugar release, and lipid peroxidation during the intestinal phase. This study highlights the importance of understanding oral decline's effects on nutrient bioaccessibility when designing functional foods for the elderly."
"Introduction Bakery products are consumed all over the world. Fat is an important ingredient in bakery products and its major functions are to tenderise the product and soften the texture, add moistness and richness, increase keeping quality, add flavour, and to assist in leavening when used as creaming agents or when used to give flakiness to puff pastry, pie, dough, and similar products (Gisslen, 1994). However, fat has a disadvantage of getting oxidised rapidly upon exposure to air, moisture, and sunlight, giving rise to an unacceptable flavour. Antioxidants are used as food additives in order to prevent the oxidative deterioration of fats and oils in processed food. Since some of synthetic antioxidants had toxigenic, mutagenic, and carcinogenic effects (Nanditha & Prabhasankar, 2009) and some natural antioxidants were effective in enhancing the shelf life of bakery products but less effective than synthetic antioxidants, there is a great demand for the use of new natural antioxidants in food, especially in bakery products. Some studies have disclosed the potential sources of natural antioxidants on the bakery products. For example, the rye bread showed better antioxidant properties and higher antioxidant contents when compared to wheat roll (Michalska et al., 2007). Toyosaki and Koketsu (2007) studied the antioxidant effects of the water-soluble fraction from baked sponge cake and found that the use of silky fowl eggs could improve the quality and oxidative stability of baked cakes as compared to cake made with White Leghorn eggs. Vergara-Valencia et al. (2007) characterised a mango dietary fibre (MDF) with antioxidant capacity, using the unripe fruit. Both types of bakery products (cookie and bread) with added MDF showed higher total dietary fibre than respective controls, and the products maintained a significant antioxidant capacity associated to their extractable polyphenol content. In addition, Lin, Liu, Yu, Lin, and Mau (2009) found that the buckwheat could be incorporated into bread and provide buckwheat enhanced wheat bread with more functional components and more effective antioxidant properties. Tea is one of the most popular drinks in the world, and its consumption is nearly as great as coffee. Tea has been used for centuries by ancient cultures for its medicinal properties and is popularly consumed in unfermented (green tea), semifermented (oolong), and fermented (black tea) forms. Black tea is commonly consumed in the West whereas the consumption of green tea is especially popular in Asia, mainly for its health benefits. Several studies have reported that green tea extract has antioxidant, antibacterial, antiviral, anticarcinogenic, and antimutagenic functions (Higdon and Frei, 2003, Lin et al., 2008). Green tea contains considerable amounts of catechins, which contribute most to its antioxidant properties. Besides, green tea is also reported to reduce serum cholesterol levels and inhibit hypertension in several experiments (Hodgson et al., 1999, Muramatsu et al., 1986). In addition to its bioactive components, green tea is a rich source of dietary fibre. Dietary fibre is the edible part of plants or analogous carbohydrates resistant to digestion and absorption in the human small intestine with complete or partial fermentation in the large intestine. Dietary fibre includes the polysaccharides, oligosaccharides, lignin, and associated plant substances (Anonymous, 2001). The lack of dietary fibre in the diet has been associated with constipation, diverticulosis, cardiovascular disease, and cancer (Kritchevsky, 2001). Many forms of dietary fibre are often added to foods to lower the incidence of these disorders and dilute calories. Natural antioxidants may inhibit lipid peroxidation in food and improve food quality and safety. Green tea contains antioxidants such as catechins and, added to food as a supplement, can provide beneficial health effects and prevent food from oxidation during processing. Baked food products are enjoyed by consumers all over the world. Because of their high consumption, they are potential carriers of bioactive compounds and dietary fibre. Thus, it would be beneficial to develop a novel formulation of cake production with green tea. The objectives of this research were to make sponge cakes with 0%, 10%, 20%, and 30% replacement of cake flour with green tea powder, to evaluate the influence of green tea powder on sponge cake quality and contents of the functional component as a result of supplementation. The antioxidant properties of sponge cakes were also determined.","The use of fat in bakery products serves multiple purposes, including texture improvement, moisture addition, and flavor enhancement. However, fats are susceptible to rapid oxidation when exposed to air, moisture, and sunlight, leading to undesirable flavors. To counteract this, antioxidants are employed as food additives to prevent fat and oil oxidation in processed foods. Concerns about the toxicity and carcinogenicity of some synthetic antioxidants have led to a growing demand for natural antioxidants in food, particularly in bakery products. Various sources of natural antioxidants have been explored in bakery products, such as rye bread, silky fowl eggs, mango dietary fiber, and buckwheat. Green tea, a popular beverage with numerous health benefits, is rich in antioxidants, particularly catechins, and dietary fiber. This study aims to investigate the incorporation of green tea powder into sponge cakes and assess its impact on cake quality, functional component content, and antioxidant properties, offering a novel approach to enhance the nutritional value of baked goods."
"Introduction Carbohydrates constitute the main fraction of unripe fruits, of these, starch and non-starch polysaccharides (dietary fibre) are the major constituents. From a chemical point of view, dietary fibre (DF) consists of cellulose, hemicellulose, lignin, pectin, β-glucans and gums (Figuerola, Hurtado, Estévez, Chiffelle, & Asenjo, 2005; Gallaher & Schneeman, 2001). In the case of fruits and vegetables, the parenchymatous tissues and cell walls are the DF supply. DF components are grouped in into two major classes: polymers that are soluble in water (SDF), such as pectins and gums, and those water insoluble materials (IDF), where cellulose, hemicellulose and lignin are included (Thebaudin & Lefebvre, 1997). This classification was originally thought as a simple way to predict fibre physiological function, but this has not always been the case (Gallaher & Schneeman, 2001). However, the SDF/IDF ratio seems to be of importance (Figuerola et al., 2005; Jaime et al., 2002; Schneeman, 1987). DF derived from fruits and vegetables have a relatively high proportion of SDF; this kind of fibres show some functional properties, such as water holding, oil holding, swelling capacity, viscosity or gel formation, among others, which have been more useful for understanding the physiological effects of DF, than the chemical composition alone (Femenia, Lefebvre, Thebaudin, Robertson, & Bourgeois, 1997; Figuerola et al., 2005; Gallaher & Schneeman, 2001). The interest in foods rich in DF increased in the recent decades, and the importance of this food constituent has led to the development of a large market for fibre-rich products and ingredients. A high DF intake has been related to several physiological and metabolic effects (Drzikova, Dongowsky, Gebhardt, & Habel, 2005). In the digestive tract, DF exerts a buffering effect that links excess of acid in the stomach, increases the fecal bulk and stimulates the intestinal evacuation; besides, it provides a favorable environment for the growth of the beneficial intestinal flora. Fibre can also bind diverse substances including cholesterol (Jenkins, Kendall, & Ransom, 1998; Jiménez-Escrig & Sánchez-Muniz, 2000). It has been reported that these specific properties of DF play an important role in the prevention and treatment of obesity, atherosclerosis, coronary heart diseases, colorectal cancer and diabetes (Bingham, 2003; Peters, 2003; Terry, 2001). Consumption of certain fibres, particularly highly viscous SDFs, is usually associated with moderate postprandial glycemic responses, a property of importance in the dietetic treatment of diabetes (Jenkins et al., 1998; Schneeman, 1987). There is a trend to find new sources of DF as ingredients for the food industry (Chau & Huang, 2003). The most widespread consumed DF products are those derived from cereals. However, over the past decade high DF materials from fruits (citrus, apple, and others) have been steadily introduced in the occidental world markets. Fruit DF concentrates have, in general, better nutritional quality than those found in cereals, because of their significant contents of associated bioactive compounds (flavonoids, carotenoids, etc.) and more balanced composition (higher overall fibre content, greater SDF/IDF ratio, water- and fat-holding capacities, lower metabolic energy value, and phytic acid content) (Chau & Huang, 2003; Jiménez-Escrig, Rincón, Pulido, & Saura-Calixto, 2001). According to recent reports (Saura-Calixto, 1998), the presence of significant amounts of bioactive compounds, such as flavonoids and carotenoids, in DF from fruits imparts them considerable nutritional value. The antioxidant properties of flavonoids and carotenoids come from their ability to link free radicals that easily attack saturated fatty acids present in cell membranes, causing peroxidation, decreasing permeation and damage of membrane proteins, leading to cellular inactivation. DNA is also subject to free radical-effects producing mutations which may lead to cancer (Ubando, Navarro & Valdivia, 2005; Yen & Hsieh, 1998). Mango is a climacteric fruit that in México and many other countries is consumed in ripe state. For this reason, large quantities of fruit are lost during commercialization, as consequence of deficient postharvest handling. Unripe mango fruit represents an alternative source for DF production, due to a number of reasons such as, starch content of the pulp, high cellulose, hemicellulose, lignin and carotenoid levels, as well as the low cost of the fruit that may allow the preparation of DF concentrates with attractive chemical and functional characteristics. The aim of the present work was to evaluate the chemical and functional properties of DF from unripe mango fruit and its application in a bakery product.","This study focuses on the exploration of dietary fiber (DF) derived from unripe mango fruit, which is rich in various DF components such as cellulose, hemicellulose, lignin, pectin, β-glucans, and gums. DF can be categorized into soluble in water (SDF) and water-insoluble materials (IDF), with the SDF/IDF ratio playing a significant role in its physiological effects. A high intake of DF has been associated with several health benefits, including gastrointestinal regulation, cholesterol reduction, and glycemic control. In recent years, there has been a growing market for fiber-rich products and ingredients due to increased awareness of the health benefits of DF. Fruit-based DF concentrates are gaining popularity due to their nutritional quality and the presence of bioactive compounds like flavonoids and carotenoids, which possess antioxidant properties. Unripe mangoes, often overlooked, represent a potential source of DF with favorable characteristics. This research aims to assess the chemical and functional attributes of DF from unripe mango fruit and its applicability in bakery products."
"Introduction Gluten replacement is nowadays one of the most challenging issues for food science and technology since a lifelong gluten-free diet is essential for patients having gluten-sensitive enteropathy (GSE) or celiac disease. GSE is characterized by small intestinal malabsorption of nutrients after ingestion of prolamins from wheat and also other Triticum species like rye, barley, oat and their crossbred varieties. The number of patients having celiac disease is estimated as one out of 85–500 people in Europe, which changes depending on the country (Farrell & Kelly, 2001). Therefore, alternative food products having the identical quality characteristics as products containing gluten is a very crucial point. Rice (Oryza sativa), which has very low level of gluten, low levels of sodium, protein, fat, fiber and a high amount of easily digested carbohydrates, is one of the most frequently used cereals as a wheat substitute in gluten-free food products (Sivaramakrishnan, Senge, & Chattopadhyay, 2004). However, some food additives such as starches, gums, hydrocolloids or dairy products should be added to the gluten-free food products to obtain the desired quality. Gums are added to the food products mainly for their thickening and gelling properties. In addition, they are used to improve mouth feel and to change the viscosity of solutions due to their high polymeric nature and the interactions between polymer chains when they are dissolved or dispersed (Yaseen, Herald, Aramouni, & Alavi, 2005). In the study of Özboy (2002), five different commercial food grade gums namely xanthan–guar gum blend, carrageenan gum, guar–carrageenan gum blend, xanthan–carrageenan gum blend and locust bean gum, were added to the corn starch to produce low phenylalanine starch–gum bread for phenylketonuria patients. McCarty, Gallagher, Gormley, Schober, and Arendt (2005) optimized gluten-free bread formulation based on mainly rice flour, potato starch and skim milk powder. Rheological information is valuable in product development. In the study performed by Chun and Yoo (2004), the rice flour dispersions showed a high shear-thinning behavior with low magnitudes of Casson yield stress. Sivaramakrishnan et al. (2004) found that the rice dough containing hydroxy propyl methyl cellulose (HPMC) had similar rheological properties as that of wheat flour dough and was suitable for making rice bread. Yoo, Kim, and Yoo (2005) found that rice starch–galactomannan mixtures such as guar gum and locust bean gum showed high shear-thinning flow behaviors with high Casson yield stress. Based on dynamic shear data, glutinous rice flour dispersions at concentrations of 4–8% exhibited rheological behavior similar to weak gels (Yoo, 2006). Rice starch–xanthan gum mixtures at 25 °C have shown shear thinning flow behavior and both consistency index and apparent viscosity of mixtures increased with the increase in gum concentration (Kim & Yoo, 2006). Emulsifiers that have a common use in the baking industry have the ability to provide the necessary aeration and gas bubble stability during the process until the cake structure is set (Sahi & Alava, 2003). Emulsifiers function by reducing the interfacial tension between oil and water and therefore, facilitate the disruption of emulsion droplets. Many researchers have shown in their studies that protein-emulsifier interactions influence the rheology of emulsions (Chen & Dickinson, 1998; Dickinson & Hong, 1995; Dickinson & Yamamoto, 1996; Sakiyan, Sumnu, Sahin, & Bayram, 2004). Microwave baking can be an alternative to conventional baking since microwaves reduce baking time and energy significantly. Since the microwave oven is at ambient temperature, the surface temperature of product is not high enough to promote browning and crust formation during microwave baking. Other quality problems observed in microwave-baked products are, firm and tough texture, rapid staling, lack of color and a dry product. In order to reduce these problems, microwave heating is recently combined with near infrared (IR) heating. IR radiation affects the surface of the product and browning and crisping can occur during baking when halogen lamps are used. Usage of IR-microwave combination baking has been shown to reduce the conventional baking time of breads by 60% recently (Demirekler, Sumnu, & Sahin, 2004). It was possible to produce high-quality cakes in IR-microwave combination oven by reducing the conventional baking time by about 79% (Sevimli, Sumnu, & Sahin, 2005). However, the quality of rice cakes baked in IR-microwave combination oven has not been studied so far. In the literature, there is no study on the rheological properties of gluten-free cake batter made from rice flour containing gums and emulsifier. Therefore, the present study was conducted to model the rheological characteristics of gluten-free cake batter made from rice flour and to compare the impact of different gums on rice batters and cake properties, which was baked in IR-microwave combination oven.","This research addresses the challenge of gluten replacement in food products for individuals with gluten-sensitive enteropathy (GSE) or celiac disease, who require a lifelong gluten-free diet. The study focuses on rice, a naturally gluten-free cereal with low levels of sodium, protein, fat, and fiber but high levels of easily digested carbohydrates. Rice is commonly used as a wheat substitute in gluten-free products, but additives such as starches, gums, hydrocolloids, or dairy products are often necessary to achieve the desired product quality. Gums, known for their thickening and gelling properties, are added to improve texture and viscosity. Emulsifiers are also used to create a stable cake structure. Additionally, the research explores the use of microwave and near-infrared (IR) combination baking to reduce energy consumption and baking time. However, there is a lack of studies on the rheological properties of gluten-free cake batter made from rice flour containing gums and emulsifiers. Therefore, this study aims to model the rheological characteristics of gluten-free cake batter and assess the impact of different gums on rice batter and cake properties when baked using an IR-microwave combination oven."
"Steamed leavened rice cakes made from rice flour, sugar, water, yeast or baking powder were used to study the effects of ingredients on cereal-based cakes. Volume expansion linearly correlates to amylopectin and negatively correlates to amylose content (r2=0·84), with an optimum amylose/amylopectin ratio of approximately 1: 8. Higher amylopectin content resulted in sticky, elastic and unacceptable cake. The optimum water content for volume expansion was in the range of 90±5% by weight of rice flour. Sugar content correlates linearly with volume expansion and tenderness of chemically leavened rice cakes (CLRC) (r2=0·99 and 0·92, respectively). Sugar content above 50% of rice flour weight decreased volume and softness of yeast-leavened rice cakes (YLRC). Tenderness of YLRC correlates linearly to fat content (r2=0·98), but volume expansions correlates negatively to the square root of fat content (r2=0·81 and 0·97 for the two rice cakes). Both tenderness (r2>0·92) and volume expansion (r2>0·93) correlates linearly with emulsifier content up to 3% by weight of rice flour, above which the cake becomes crumbly. A little salt increased hardness, but further increase reduced both volume expansion and hardness of rice cakes. Skimmed milk powder greatly increased the expansion of CLRC. Ovalbumin content correlates linearly to volume expansion of YLRC (r2=0·87) but negatively to the expansion of CLRC (r2=0·96). The proteins that improved the textures of rice cakes were skimmed milk and egg white with an optimum content of 2–4%. Egg yolk, soya protein, whey powder and wheat gluten reduced both tenderness and volume expansion. The effects of the various ingredients interacting together were studied and the optimum formulations was determined using a Random Centroid Optimisation Program. © 1998 SCI.","The study examined the effects of ingredients on steamed leavened rice cakes made from rice flour. It found that the amylose/amylopectin ratio significantly influenced volume expansion, with an optimal ratio of approximately 1:8. Water content within the range of 90±5% of rice flour weight was ideal for maximum volume expansion. Sugar content correlated with volume expansion and tenderness, while fat content affected tenderness and volume expansion negatively. Emulsifier content showed linear correlations with tenderness and volume expansion up to 3% of rice flour weight. Skimmed milk powder enhanced cake expansion, while certain proteins improved texture, with egg white and skimmed milk as optimal additives. Other ingredients had varying effects, allowing for the determination of optimal formulations."
"1. Introduction Curriculum researchers have made many definitions on the subject since the 20th century. Breault and Marshall (2010) mention that these definitions are made in order to clarify individuals' understanding of the curriculum. While making these definitions, two points are especially emphasized. The first is the consistency with the academic point of view, and the second is the consistency between this spiritual and intellectual field and those who put knowledge into practice. What is meant here is the degree of harmony between theoretical and practical fields. Moye (2019, pp. 1–18) etymologically defines curriculum as the path to the goal and mentions three implicit concepts underlying this concept. The curriculum is intended to function as a guide to achieving set goals. Another emphasis is on restricting activities that limit this plan and distract students from reaching the intended place. Finally, it contains an implicit concept for maintaining order, and this concept means structuring the learning process (see Tablo 1, Tablo 2, Tablo 3, Tablo 4, Tablo 5, Tablo 6, Tablo 7, Tablo 8). The field of curriculum studies, which started to evolve in the 1930s, set out from the idea of expanding universal education. It has been noticed that the studies conducted in this field, which gained popularity in the 1970s, contributed to the support of the policies for schools. With the fact that such policies were seen to support the middle class, that is, the interests of the bourgeoisie, many intellectual concepts such as equality and social justice emerged. (Schubert, 2010). According to Flinders (2010), curriculum goals aim to improve a situation or a person. Based on this, he mentions two different curriculum approaches which are understanding the social needs and understanding of individual development. One of the greatest examples of the first approach can be shown as Platonic. According to Plato, taking into account the state's needs, young people should be trained in three areas: artisan, guardian, ruler. Today, education plays a huge role in protecting the interests of the state and ensuring national unity. When we examine the examples of the approach organized especially for social needs and also called social restructuring, there are programs to reduce discrimination such as race, religion, language class, and gender (Tedesco et al., 2014). Connelly and Connelly (2010) mention three curriculum policies. These are formal, implicit, and prudential. Briefly, the official curriculum policy; tells the compulsory subject or learning outcomes that should be taught to students. Covert curriculum policy refers to government-level policies. For example, the No Child Left Behind Act (NCLB). The precautionary curriculum policy covers the subjects that need to be implemented in practice such as staff, administrators, and teachers in the school.","Curriculum research in the 20th century has yielded various definitions, emphasizing alignment with academic perspectives and the harmony between theory and practice. Moye's etymological definition sees the curriculum as a path to a goal, guiding learners and maintaining order. The field of curriculum studies, evolving since the 1930s, aimed to expand universal education, with studies in the 1970s supporting educational policies. Flinders distinguishes curriculum goals focused on social needs and individual development, citing Plato's example. Connelly and Connelly categorize curriculum policies as formal, covert, and precautionary, each serving distinct roles in education. These definitions and concepts shed light on the multifaceted nature of curriculum studies."
"Egerton Ryerson, a Methodist clergyman and a man with many diverse interests, skills, and passions, is considered to be the chief architect of the Ontario School system. After investigating the education programs in Continental Europe and throughout the United States, Ryerson established the premise that a full education system in Upper Canada must be one with high standards for the curriculum; with supervised training, inspection, and examination of teachers; and that used current, locally developed textbooks and teaching resources. Additionally, Ryerson established the need for a library in every school, a Journal of Education to keep teachers informed about educational developments, and two annual professional conference days. Ryerson was also a proponent of the arts, and under his leadership formed the nucleus of the first publicly-funded art collection in all of Canada and the initial holdings of Canada’s first art gallery, Toronto’s Educational Museum, the forerunner of today’s Royal Ontario Museum. An art school, in cooperation with the Ontario Society of Artists, soon followed. (This was the predecessor to the Ontario College of Art and Design.) Ryerson’s philosophy of education centred on the need “to learn in order to practice.” In 1848, Egerton Ryerson declared that music was worthy of inclusion in the public school curriculum (retrieved from http://instruct.uwo.ca/edu/500-001/music/a/). What was the underlying purpose behind a pub","The underlying purpose behind Egerton Ryerson's initiatives in the Ontario School system was to establish a comprehensive and high-quality education system in Upper Canada. Ryerson believed in setting high standards for the curriculum, ensuring that teachers were well-trained and supervised, and using locally developed educational resources. He also emphasized the importance of libraries in schools, keeping teachers informed through a Journal of Education, and promoting professional development through annual conferences. Additionally, Ryerson was a strong advocate for the arts and played a significant role in the establishment of Canada's first art collection and art school. His philosophy of education focused on practical learning, and he recognized the value of including music in the public school curriculum, reflecting his commitment to providing a well-rounded education for students."
"Royal Commission on Learning: For the Love of Learning, 1995
The Royal Commission on Learning, the first major commission of education since Living and
Learning (1968), suggested, among other things, that Grade 13 be abolished—to put Ontario in
line with the other Canadian provinces that had already made this change—and that teacher
training take two years instead of the present one year. It also called for the creation of a
“College of Teachers” to maintain professional standards, for the creation and use of
standardized report cards, and for pre-kindergarten programs to offer schooling for children as
young as three years of age. Gerry Caplan, Co-chair of the Commission, is quoted as saying:
Our bottom line is that we want the vast majority of Ontario students to complete high
school as literate, knowledgeable, creative, and committed young men and women. Our
recommendations are geared to ensuring they know how to solve problems, and think
logically and critically. They will be able to communicate articulately, work
cooperatively, and most importantly, will have learned how to learn. (Retrieved from
http://www.edu.gov.on.ca/eng/general/abcs/rcom/news.html)
The 167 recommendations to produce sweeping change in the education system were
based on four fundamental “educational engines”:
1. Teacher Professionalization and Development
2. Community Alliances
3. Early Childhood Education
4. Information Technology
From Sea to Sea: Perspectives on Music Education in Canada Open Access, Peer-Reviewed Electronic Book 6
Williamhan, L., & Cutler, J. (2007). Music education in Ontario: Snapshots on a long and winding road. In K. Veblen & C.
Beynon (Eds. with S. Horsley, U. DeAlwiss, & A. Heywood), From sea to sea: Perspectives on Music education
in Canada. Retrieved from http://ir.lib.uwo.ca/musiceducationE-books/1/
Music education was not specifically named within any of the recommendations, but the arts
received some spotlight in the report narrative. The description of what a fully educated Ontario
graduate should be included strong statements such as,
The arts are unique as a way of taking in information and as a vehicle for communication
and self-expression. The point is that what is best understood or expressed in music, in
movement, or in a drawing cannot be paraphrased in words. Students denied access to the
arts are denied literacies and are impoverished as learners;
Any school system that fails to open up the spirit of the arts to its students is unworthy of
public support; and
The arts are an integral part of any complete education (The Royal Commission on
Learning: For the Love of Learning, 1995)","
The Royal Commission on Learning in 1995 aimed to bring significant changes to the education system in Ontario. Among its key recommendations were the abolition of Grade 13 to align with other Canadian provinces, extending teacher training to two years, the establishment of a ""College of Teachers"" to maintain professional standards, the implementation of standardized report cards, and the introduction of pre-kindergarten programs for children as young as three years old. The commission's co-chair, Gerry Caplan, emphasized the goal of ensuring that Ontario students complete high school as literate, knowledgeable, creative, and critical thinkers who can solve problems, communicate effectively, collaborate, and continue learning."
"Introduction Teaching materials are based on the syllabus and the actual needs for teachers' instructional materials; they are fundamental to education. Without teaching materials, it is challenging to form a comprehensive educational system. Teaching materials are the dominant classroom resource and determine 80% of the subject's curriculum content (Ou & Hong, 2004). School education in any subject relies heavily on textbooks (Zhong & Wang, 2008). Music teaching materials are the basic premise of music education, which is directly related to the efficiency and quality of musical instruction (Su et al., 2022). To achieve educational goals more comprehensively, school music teaching materials typically utilize nationally unified music textbooks alongside local supplemental teaching materials. Almost every school incorporates music culture from their region as the main content of supplemental materials, which we refer to as local music materials. Local music teaching materials emerged in the early twentieth century. Following the Reform Movement, and with the establishment of new schools in China, “School Music” began to spread nationwide (Wu, 2008). The increase in school music marked the beginning of our country's journey in music education. From the creation of the first music teaching material, “School Singing Collection,” in 1904, the music teaching materials for primary and secondary schools have continuously evolved (Anna, 2014). Concurrently, the Qing government sought to emulate the local education models of Germany and Japan to stimulate patriotic fervor among the populace and to rescue the waning Qing dynasty. Music education and the local education movement were conducted simultaneously, directly fostering the development of local music teaching materials. For an extended period, local music teaching materials have played a unique role in catering to various educational concepts and societal needs as a supplement to unified music teaching materials. Local music teaching materials are particularly effective at awakening people's nostalgia, patriotism, and familial love through music (Jin et al., 2017). The publication of local music teaching materials actively contributes to preserving local musical heritage and promoting students' appreciation for national music (Niu, 2020). The development of “local music teaching materials” can meet the aesthetic needs of primary and secondary students in minority areas, better facilitating aesthetic education and aiming to cultivate a new generation from minority nationalities (Tan, 1994; Yao et al., 2022). Nowadays, with the evolution of pedagogical concepts over time, people have adopted new perspectives on the role of teaching materials (Kuang, 2003; Oubibi, 2023). An increasing number of teachers and students are opting for local music teaching materials, which, in turn, has raised new expectations for their practicality. Critics argue that local music teaching materials currently have low applicability and utilization rates and do not effectively fulfill their intended functions. They advocate for these materials to primarily engage with the core aesthetic function of music, to spark an interest in learning, to preserve the unique heritage of traditional music culture, to foster patriotic sentiments, and to contribute to national rejuvenation, among other roles. Traditional culture nurtures the innocence of youth and shapes the new generation. In our country, there is a concerted effort to implement “five educations simultaneously” and to vigorously advance the education of traditional music culture. The “Compulsory Education Art Curriculum Standards (2022 Edition)"" also prioritizes “evoking emotions of love for the party, patriotism, and one's hometown through musical experiences” as the foremost curriculum objective (Ministry of Education of the People 's Republic of China, 2022; Ji et al., 2022). This signifies an opportune moment to enhance the role of local music teaching materials and to realize the aims of local education. In light of this, the present study analyzes 36 local music teaching materials compiled in various regions from 1936 to 2022. This analysis aims to elucidate the temporal and geographical distribution of teaching materials, the organization and form of teaching content, and the characteristics of the target audience for these materials. Additionally, the study revisits the educational concepts and policies of the times to identify the stages of functional evolution in the development of teaching materials. The progression of teaching materials is categorized into three phases: the initial stage from 1936 to 1948, during which materials primarily served an aesthetic function; from 1949 to 1978, the materials were in a transitional phase of development, primarily serving a political purpose; and since 1979, materials have been in a period of rapid development and transformation, mainly fulfilling a cultural function. It has also been found that the structure and organization of teaching materials exhibit distinct characteristics in each of these periods. This indicates that the compilation of local music teaching materials is largely influenced by the level of educational advancement and the demands of societal development, which offers significant referential value for the compilation of local music materials.","Local music teaching materials have evolved significantly in China since their inception in the early 20th century. Analyzing 36 such materials from 1936 to 2022 reveals distinct phases of development. Initially, they focused on aesthetics, transitioning to serving political purposes from 1949 to 1978. Since 1979, these materials have been primarily aimed at cultural enrichment. Each phase reflects the influence of educational progress and societal demands. This historical analysis provides valuable insights for the compilation of local music materials, which play a crucial role in preserving cultural heritage and fostering patriotism in students."
"Method
3.1. Ways to collect materials
Research commenced on September 1, 2019, for local music teaching materials, involving interviews with educators and researchers. By September 1, 2020, 218 materials were gathered, reducing to 37 after applying selection criteria. Material collection methods were:
1.
Library Archives: Visiting libraries and education archives across Beijing, Shanghai, Zhejiang, and Jiangsu to source materials.

2.
Online Databases: Utilizing academic and literature databases like Duxiu Academic Search, National Newspaper Index, and electronic book databases for relevant materials.

3.
Online Marketplaces: Searching and purchasing on platforms such as Confucius Old Book Network.

4.
Interviews: Engaging with music teachers, researchers, and material experts to gather information and materials.


Consents were obtained in line with the Declaration of Helsinki, and the study was approved by the Ethics Committee of Zhejiang Normal University, College of Education.

3.2. Criteria for selecting teaching materials
Selection criteria were multifaceted:
●
Timeframe: Materials from the beginning of local music teaching materials to 2022 were considered.

●
Content Focus: Exclusively “local music” teaching materials.

●
Completeness: Materials must be intact and fully accessible.

●
Official Publications: Only formally published materials were included.


3.3. Teaching material analysis methods
Materials underwent classical content analysis, revealing implicit values through text and images. The process entailed preliminary reading, latent meaning, background analysis, and interpretive understanding, scrutinizing the material's structure and content.

3.4. Interview method
●
Interviews sought insights from educators and researchers:


Preparation: Drafting questions based on “local music teaching materials' status"".
●
Interviewee Selection: Advertisements attracted candidates meeting specific criteria, including a minimum of a bachelor's degree and experience in music education or research.

●
Data Collection: Information on interviewees' demographics and professional background was systematically recorded and presented in a Table 1.","The study on local music teaching materials commenced in September 2019, collecting 218 materials through diverse methods such as library archives, online databases, marketplaces, and interviews with educators and experts. After applying selection criteria, 37 materials were included. The criteria included the timeframe from the inception of local music teaching materials to 2022, a focus on ""local music,"" completeness, and the status of being formally published. The analysis involved classical content analysis to uncover implicit values within the materials, and interviews with educators and researchers were conducted to gain insights into the status of local music teaching materials. Ethical approval was obtained for the study."
"Abstract The traditional education model is undergoing tremendous changes, and network education has gradually developed and matured. This paper first gives an overview of the development history of the clarinet and the structure of the clarinet and then starts with the performance of the clarinet. This paper analyses and solves the situations that students are prone to encounter in teaching and expresses some opinions on the teaching of performance methods; also gives a brief overview of the psychology of going on stage. Combined with the above, some discussions are made on the teaching of performance methods. Performance requires not only skills but also music. Performance summarizes the characteristics and styles of music in various periods from the classical period to the century, and then discusses how the performer forms his performance style; the performance style is the re-creation and re-creation of the performer based on being loyal to the author's intention. This article compares and studies the performance of the clarinet before the 20th century and the performance of the clarinet today, and deeply explores the reasons why the clarinet performance method has formed the current performance method after a long evolution. The experimental results prove that virtual reality technology has made positive attempts and breakthroughs in the field of clarinet music art teaching. It has created an environment of “self-learning”, and the traditional learning method of “teaching to promote learning” has been replaced by learners through their learning. Interaction with the information environment to obtain a new learning method of knowledge and skills, the optimized local matrix decomposition recommendation algorithm can greatly improve problems such as expensive musical instruments and lessons, scarce teachers, and lack of facilities, making the traditional clarinet Music arts teaching more diverse.","This paper discusses the evolving landscape of education with the emergence of network education and its impact on clarinet music teaching. It provides an overview of clarinet development, performance, and psychology, emphasizing the importance of performance methods that combine skill and musicality. The article examines the historical evolution of clarinet performance methods, comparing the past with contemporary approaches. It also explores the role of virtual reality technology in clarinet music education, highlighting its potential to enhance self-learning and address challenges in traditional teaching methods, such as instrument accessibility and teacher availability.





"
"Introduction With social economy rapidly developing, music education, which is part of the emerging Internet era, is gradually becoming intelligent. The use of computers to automatically recognize musical notes is an emerging interdisciplinary discipline involving human-computer interaction, signal processing and music theory (Daubney & Fautley, 2020). Traditional music teaching involves offline tutoring by professional teachers and repeated practice by students, which is inefficient and expensive (Hasanova, 2021). Repetition is too boring and monotonous, limiting students' musical exploration and creativity, and limiting the effective use of teachers. The high cost of tuition and tutorials also limits the availability of music tuition for students from lower income families. In offline teaching, music note recognition relies solely on the teacher's human ear, which is subjective and inaccurate (Kretschmer & Peukert, 2020). The use of computer technology for music note recognition can greatly improve the accuracy of recognition, and the automatic generation of music scores lowers the threshold for music learning and composition, thus effectively promoting the development of music intelligence. Existing music note recognition systems suffer from poor accuracy in identifying music note features and low accuracy in classifying features (Gómez et al., 2021). Although the existing music note recognition systems have certain application value, it is necessary to design a music note recognition system with higher recognition accuracy and stability. In this context, the study combines the HMM algorithm to design a model that can accurately recognize music note features in order to provide better support for music teaching. Related works With the continuous development of digital entertainment and information technology, computer music has gradually occupied an important position in intelligent multimedia, and more and more researchers have recognized the importance of intelligent music note recognition, and many scholars at home and abroad have carried out research on this. Er and Aydilek (2019) recognized the importance of music emotion recognition and proposed a method to classify music genres for emotion using music spectrograms with frequency domain information and time domain information. The method used a deep learning model to extract deep visual features and the results showed that the method was effective in music emotion recognition. Solanki and Pandey et al. (2022) proposed a method for instrument recognition using a deep convolutional neural network framework in order to better identify polyphonic music, which maps audio data into a matrix format and introduces nonlinearity in the convolutional neural network, and the results show that the method achieves 92.8% accuracy for polyphonic music recognition. Calvo-Zaragoza et al. (2020) developed a method for faster understanding of optical music recognition, established a common terminology for the relationship between optical music recognition and related fields, and proposed a taxonomy of optical music recognition.The results showed that the method enabled researchers without a musical background to understand the intrinsic structure and state of the art of optical music recognition, etc. To improve the accuracy of human speech recognition, Doppler radar was used by Khanna et al. (2019) to capture micro-Doppler signals. And the captured signals were classified by spectral analysis. Experimental results show that the method achieves 97% accuracy. Moscato et al. (2020) proposed a new music recommendation technique to more accurately identify user emotions, which captures user behaviour data from social network logs. And the results show that the method demonstrates the effectiveness of user emotion recognition recommendations. The HMM algorithm plays an important role in music note feature recognition. The research team of Sefati and Navimipour (2021) proposes to combine the HMM model with an ant colony optimization algorithm in order to improve the quality of the IoT service portfolio and to improve the transfer and emission matrices using the Viterbi algorithm optimization. The results show that the method reduces the time cost to improve the service quality. Touloupou et al. (2020) researchers propose a new Markov chain Monte Carlo algorithm in order to improve the computational efficiency of the algorithm, which is an improvement of the before and after filter sampling algorithm and uses interpolated data expansion techniques in the hidden states. The results show that the method is efficient in analyzing models with a large number of hidden chains. Zeng (2020) scholars proposed a hybrid technique combining HMM models with data mining to improve the accuracy of quality assessment of physical education, and used a mathematical method for quality assessment of physical education courses in universities. In the experimental results, this method is feasible in improving the accuracy of quality assessment of physical education teaching. Ye and Han (2022) scholars proposed a new HMM model feature extraction method to improve the accuracy of user behavior detection. The method extracts the user's behaviour data according to the features of time series and uses the extracted features to calculate probability parameters. The accuracy of this method is effectively improved when the data is in a hidden state. In summary, although many researchers and scholars have recognized the importance of music note feature recognition and designed many music note feature recognition models for this purpose, there are still shortcomings in the accuracy of music note feature classification and the accuracy of music recognition. Therefore, the study designs a teaching model for music note feature recognition in universities based on the HMM algorithm in order to achieve a higher recognition accuracy.","This paper discusses the evolution of music education into the digital age, emphasizing the need for intelligent music note recognition systems to enhance music teaching and learning. It highlights the limitations of traditional offline music teaching methods and the potential of computer technology to improve music note recognition accuracy. The study combines the Hidden Markov Model (HMM) algorithm to design a model that accurately recognizes music note features, addressing existing shortcomings in music note recognition systems. The paper also references related works in the field of music emotion recognition, instrument recognition, and optimization techniques, highlighting the significance of accurate music feature recognition."
"Abstract: The wind deflection of overhead contact lines (OCLs) challenges the stable and safe operation of electrified railways. The steady wind causes the static deflection of the contact line, while the fluctuating wind leads to the OCL buffeting. This paper performs a response spectrum analysis of the wind deflection caused by the combined effects of steady and fluctuating winds. Considering the initial configuration of OCL, an absolute nodal coordinate formulation method is employed to model the OCL. A spatial wind field including the fluctuating wind in three directions is constructed and the aerodynamic forces on the OCL are derived. A nonlinear solution procedure is proposed to include the geometrical nonlinearity and dropper slackness in the evaluation of static wind deflection. The pseudo-excitation method is utilised to evaluate the buffeting response of the OCL with stochastic wind load. The analysis results indicate that the dropper slackness has a significant effect on the vertical static deflection. Under an extreme wind speed of 40 m/s, the contact line is always within the safe working range of pantograph head when only the steady wind load is considered. However, the stochastic wind load causes non-negligible fluctuation of OCL, and the contact line may be outside of the pantograph working range under the same wind speed. Sensitivity analyses on the effects of some key parameters to the OCL buffeting suggest that the increases of damping ratio and the tension class are effective measures to improve the wind-resistance capability of OCL.","This paper addresses the wind deflection challenges faced by electrified railways due to overhead contact lines (OCLs). It conducts a comprehensive response spectrum analysis that considers both steady and fluctuating winds. The study utilizes advanced modeling techniques, including the absolute nodal coordinate formulation and spatial wind field construction. It also accounts for geometrical nonlinearity and dropper slackness in static wind deflection analysis. The findings emphasize the importance of factors like damping ratio and tension class in enhancing the wind-resistance of OCLs, especially when subjected to stochastic wind loads that can lead to significant fluctuations."
"Introduction
1.1. Background
Many studies and reviews have shown benefits of music therapy in the forms of individual and group in-person sessions, and in recent years, telehealth sessions. However, as in many other types of therapy, there are barriers to accessing music therapy services, which may include transportation issues, financial difficulties, stigma, time, and illness [1], [2], [3], [4]. Further, there are times when direct input from a therapist ceases or becomes temporarily unavailable for reasons such as treatment termination and short-term employment contracts [5]. Bolger and McFerran [5] proposed sustainable approaches to music therapy practice, through building clients’ capacity to continue using music skills or techniques in their personal lives. As a result, clients can then use music independently to address their health needs. Many studies use the term self-administration (synonyms: self-help, self-directed, self-managed, minimal contact, etc.) to describe this strategy.

Black and Cameron [6] defined self-administered interventions as “interventions that are relatively simple, easily disseminated and require minimal provider assistance” (p. 533). Clients are provided with strategies to help manage physical and/or psychosocial challenges caused by their illness and are assumed competent to use the interventions by themselves with minimal help or assistance from therapists [4], [6]. This strategy offers clients flexibility in terms of when and how to engage with the interventions [4]. Thus, self-administered interventions can offer intensive and frequent use, freedom for the clients to manage their own pace, and cost-effectiveness [4], [7].

Applying the concept of self-administration to music interventions may not only address the barriers to accessing music therapy, but also offer sustainable benefits by supporting clients’ capacity to independently engage with music in an intentional way that addresses their health needs. In this review, we defined self-administered music interventions (SAMIs) as music interventions that are self-administered by an individual to address their own health needs. According to our scoping search, several music therapy and music medicine studies have been conducted using SAMIs. However, to our knowledge, no review has been conducted of research using SAMIs specifically.

1.2. Objectives
We aimed to systematically investigate the use of SAMIs to reveal how previous studies have enabled independent uses of music, explored effectiveness, and implemented interventions. Specifically, we addressed the primary question: How do SAMIs influence psychological wellbeing for people with chronic health conditions? The following sub-questions were posed:
•
How have SAMIs been implemented in research?

•
What is the effect of SAMIs on psychological wellbeing?


We also reviewed qualitative data to explore what factors influence the implementation of SAMIs, how and why they have or do not have an effect, and what recommendations and/or considerations can be made regarding implementation of SAMIs. These qualitative results are presented in a separate article [8].                   ",This study explores self-administered music interventions (SAMIs) as a means to address barriers to accessing music therapy services. SAMIs are defined as music interventions that individuals use independently to address their own health needs. The primary objective is to investigate how SAMIs influence the psychological well-being of people with chronic health conditions. The study also examines the implementation of SAMIs in research and their effectiveness in improving psychological well-being. Qualitative data is reviewed to understand the factors influencing SAMI implementation and their impact.
"Abstract Background Aphasia is an acquired language disorder that occurs secondary to brain injury, such as stroke. It causes communication difficulties that have a significant impact on quality of life and social relationships. Although the efficacy of speech–language therapy has been clearly demonstrated in this population, long-term services are currently limited due to logistical and financial constraints. In this context, the potential contribution of technology, such as smart tablets, is worth exploring, especially to improve vocabulary that is relevant in daily life. Aims The main aim was to investigate the efficacy of a self-administered treatment using a smart tablet to improve naming of functional words in post-stroke anomia. Methods & Procedures Four adults with post-stroke aphasia took part in the study. An ABA design with multiple baselines was used to compare naming performances for four equivalent lists: (1) trained with functional words chosen with the participant; (2) trained with words randomly chosen from a picture database; (3) exposed but not trained; and (4) not exposed (control). Outcomes & Results For all participants, the treatment self-administered at home (four times/week for 4 weeks) resulted in a significant improvement for both sets of trained words that was maintained 2 months after the end of treatment. Moreover, in two participants, evidence of generalization to conversation was found. Conclusions & Implications This study confirms the efficacy of using smart tablets to improve naming in post-stroke aphasia. Although more studies are needed, the use of new technologies is unquestionably a promising approach to improve communication skills in people with aphasia, especially by targeting vocabulary that is relevant to them in their daily lives.","
This study investigates the efficacy of a self-administered treatment using a smart tablet to improve naming of functional words in post-stroke aphasia. Four adults with post-stroke aphasia participated in the study, and the treatment involved self-administration at home for four times a week over four weeks. The results showed a significant improvement in naming performance for both trained sets of words, which was maintained for two months after the treatment. Additionally, evidence of generalization to conversation was found in two participants. This study suggests that smart tablets can effectively improve naming in post-stroke aphasia and holds promise for improving communication skills in this population."
"Abstract Background: In order to comprehend fully a speaker's intention in everyday communication, information is integrated from multiple sources, including gesture and speech. There are no published studies that have explored the impact of aphasia on iconic co-speech gesture and speech integration. Aims: To explore the impact of aphasia on co-speech gesture and speech integration in one participant with aphasia and 20 age-matched control participants. Methods & Procedures: The participant with aphasia and 20 control participants watched video vignettes of people producing 21 verb phrases in three different conditions, verbal only (V), gesture only (G), and verbal gesture combined (VG). Participants were required to select a corresponding picture from one of four alternatives: integration target, a verbal-only match, a gesture-only match, and an unrelated foil. The probability of choosing the integration target in the VG that goes beyond what is expected from the probabilities of choosing the integration target in V and G was referred to as multi-modal gain (MMG). Outcomes & Results: The participant with aphasia obtained a significantly lower multi-modal gain score than the control participants (p<0.05). Error analysis indicated that in speech and gesture integration tasks, the participant with aphasia relied on gesture in order to decode the message, whereas the control participants relied on speech in order to decode the message. Further analysis of the speech-only and gesture-only tasks indicated that the participant with aphasia had intact gesture comprehension but impaired spoken word comprehension. Conclusions & Implications: The results confirm findings by Records (1994) that reported that impaired verbal comprehension leads to a greater reliance on gesture to decode messages. Moreover, multi-modal integration of information from speech and iconic gesture can be impaired in aphasia. The findings highlight the need for further exploration of the impact of aphasia on gesture and speech integration.","This study explores the impact of aphasia on the integration of co-speech gesture and speech in one participant with aphasia and 20 control participants. Participants watched video vignettes in different conditions, including verbal only, gesture only, and verbal gesture combined. The results showed that the participant with aphasia had a significantly lower multi-modal gain score compared to the control participants, indicating impaired multi-modal integration. The findings suggest that impaired verbal comprehension in aphasia can lead to a greater reliance on gesture to decode messages. Further research on this topic is needed to better understand the implications for aphasic individuals."
"Introduction
During pregnancy, women undergo intense transformation including changes in the body, upheaval of hormones, redefining self-identity, changing roles in relationship and careers, and preparing for parenthood (Miller, 2016). For some, it can be “a time of crisis” when one feels vulnerable to effects of adversity or finds the transition challenging (Slade et al., 2018). Prevalence of depression and anxiety is higher during pregnancy, and it is estimated that globally up to 25% of pregnant women can experience symptoms of anxiety (Dennis et al., 2017) and 17% symptoms of depression (Underwood et al., 2016). Prenatal anxiety and depression have been associated with higher rates of obstetric complications during pregnancy and adverse birth outcomes (Yonkers et al., 2017). The effects continue beyond birth with long-term impacts on the mother and the biopsychosocial development of their infant(s) (Field, 2017).

Wadephul et al. (2020) highlight that perinatal wellbeing is a subjective experience and depends on how an individual draws on internal skills and external resources to cope with change and challenging situations. Hence, it is crucial for expectant parents to have access to substantial resources, tools, and support during pregnancy to augment maternal, paternal, and neonatal wellbeing and development.

Music engagement during pregnancy has been found to be beneficial for women and the foetuses (Fancourt and Finn, 2019). Listening to relaxing music during pregnancy is shown to reduce symptoms of anxiety and depression, decrease cortisol and increase the oxytocin level, improve sleep quality in women with disturbed sleep, promote maternal foetal attachment, and reduce anxiety in women waiting for amniocentesis and during transvaginal ultrasound (Fancourt and Finn, 2019; Sanfilippo et al., 2021; Ventura et al., 2012; Wulff et al., 2021).

Evidence also suggests that the positive effect of prenatal music engagement can continue beyond pregnancy. A randomised controlled trial shows that prenatal music listening is associated with a more positive birth experience with shorter labour, higher chances of delivery beginning naturally, less need for medication (García González et al., 2018), higher levels of postnatal maternal wellbeing and reduced symptoms of postnatal depression in the first three months after birth (Fancourt and Perkins, 2018). Singing lullabies during pregnancy has also been associated with stronger postnatal attachment, lower incidence of neonatal crying episodes, infantile colic, and neonatal nightly awakening (Persico et al., 2017). Infants of women listening to music during pregnancy have scored significantly better on the Neonatal Behavioural Assessment scale (Arya et al., 2012) and showed long-term neural effects than those with no prenatal exposure to music (Partanen et al., 2013).

There is an emerging body of literature that describes music therapy as a specialist clinical practice during pregnancy. These include music therapy for vulnerable first-time parents (Lander, 2017), expecting parents with mental health illness (Friedman et al., 2010), women who were hospitalised during antepartum (Corey et al., 2019; Horn et al., 2022), and pregnant women whose foetuses have an incurable diagnosis (Schreck and Economos, 2018). A distinct difference between music therapy and other music interventions is that music therapy involves a process developed between a music therapist and the client(s) to achieve health and therapeutic goals through tailored music experiences (Bonde, 2011). Different music therapy techniques such as music listening, singing, song discussion, song-writing, music-making, and music-assisted relaxation were found to reduce distress (Corey et al., 2019; Horn et al., 2022), normalise the hospital experience (Horn et al., 2022), promote positive parenting (Lander, 2017), increase mother-foetal bonding (Friedman et al., 2010; Horn et al., 2022; Schreck and Economos, 2018), connect the family (Horn et al., 2022; Schreck and Economos, 2018), celebrate life, and create legacy and memories (Schreck and Economos, 2018).

The notion that music can be a personal and public health resource (Clift, 2012; Daykin and Bunt, 2015; Stige, 2005) is gaining wider recognition internationally (Fancourt and Finn, 2019). This applies not only to pregnant women as some studies have suggested that partners can also benefit from perinatal music intervention (Bollard-Marcovitz et al., 2021; Cheung and McCaffrey, 2022). This is reflected in information booklets provided to all parents-to-be by the Health Executive Service in Ireland who describe the use of music as a self-care strategy (Health Executive Service, 2020). Therein it is recommended that parents-to-be listen to enjoyable music to support their mental wellbeing (p.9, 11), use relaxing music as a means of distraction and self-care (p.166), prepare and use music to support labour (p.110, 119), sing songs and lullabies to “bond with the bump” (p.8), and playing calm and soft music to soothe their baby (p. 8, 165). Nevertheless, there is a knowledge gap on how parents-to-be in Ireland view and use music during pregnancy. Particularly, the experiences of partners were rarely investigated in previous studies on perinatal music intervention although the inclusion of paternal role is beginning to be recognised in perinatal studies (Fisher et al., 2021). Hence, this study aimed to gain an understanding of the experiences of both women and partners in using music to support wellbeing during pregnancy and their perspectives on music-based initiatives in perinatal care so that future resources and programmes can be developed according to their needs and preferences. ","
During pregnancy, women experience various physical and emotional changes that can lead to stress and anxiety. Prenatal music engagement has been shown to have positive effects on maternal mental health and even contribute to better birth experiences. Music therapy, a specialized clinical practice, has been used to address the unique needs of pregnant women, including those with mental health issues and high-risk pregnancies. This study aims to explore the experiences of both women and their partners in using music for emotional support during pregnancy and their perspectives on music-based interventions in perinatal care, filling a knowledge gap in this area."
"Discussion
This study is the first to explore the experience of women and partners in Ireland of using music during pregnancy and their perspectives of perinatal music therapy. Whilst the findings reveal differences or association between the variables, this study is descriptive in nature and does not aim to draw any statistical conclusion. Overall, the quantitative and qualitative data are congruent and inform each other. The results highlight the positive role of music in everyday life, in difficult times, and in clinical settings. It features the women's and partners’ uses of music during pregnancy and supports the notion that music can be a personal health resource (Saarikallio, 2017) during pregnancy to promote maternal health, support family bonding, and to cope with psychological and physical distress, hospitalisation, the labour process, and other life challenges such as stress and crises, e.g., miscarriage and the pandemic. The reported positive benefits of using music during pregnancy are consistent with the growing body of evidence forementioned in the introduction. The findings provide insight into music engagement behaviours and preferences of women and partners which can inform the design of music programmes for perinatal wellbeing.

The findings on the music engagement behaviours lends support to a study on maternal engagement during the first nine months post-birth in England, where the majority of respondents reported listening to music regularly and pop music mostly (Fancourt and Perkins, 2017). However, in this study a much smaller percentage of respondents sang to their babies daily (14%) and sang nursery rhymes (11%) as compared to the study by Fancourt and Perkins (59% and 83% respectively) (2017). This suggest the maternal singing behaviours and purpose during pregnancy might be different from during the postnatal period when mothers sang to sooth or entertain the infants.

Although only a proportion (6%) of participants experienced negative effects and barriers in using music during pregnancy, their experiences offer important insights in considering the most effective ways of using music for wellbeing and the future directions of the development of music-based resources and interventions. The few but important cases of negative experiences highlight music is not always beneficial and can be undesirable if used inappropriately (Moss, 2021). Music is shown to evoke memories and can trigger the sensation and feelings of a specific event (Belfi et al., 2016). This explains why it can be a powerful tool to evoke positive memories and a sense of connectedness with loved ones, but also has the potential to trigger sadness and traumatic memories (Samson et al., 2009). It also explains why the key factors which facilitated the use of music for some respondents could be barriers for to some others. This suggests a need for guidance on choosing appropriate music and adjusting listening behaviours to maximise the benefits and to minimise any negative impact. For example, creating playlists containing familiar music that evokes positive feelings or induces relaxation responses for vulnerable situations; listening to preselected playlists, as compared to listening to music through the radio or allowing music applications to select tunes randomly, can give the listener more control over the music so that undesirable impact can be avoided; listening to music through headphones to accommodate personal music choices in shared listening space; and negotiating the need to play music with one's maternity care team in advance of childbirth (Grocke and Wigram, 2006; McCaffrey et al., 2020).

Given the overwhelmingly high percentage of respondents who felt that there was not enough guidance for parents on using music to support pregnancy and childbirth, there is an urgent need to develop more accessible evidence-based guidance, resources, and music-based perinatal programmes. Programmes that can support relaxation, parent-infant bonding, and childbirth would assist parents to use music safely and effectively to promote maternal, infant, and family wellbeing during the perinatal period. The findings indicate that, with enough knowledge, music can be used personally in everyday life to achieve health benefits (Ansdell, 2014). These resources and programmes can offer non-pharmaceutical, alternative strategies for parents to manage the challenges come with pregnancy and birth and promote the wellbeing of both parents and infants on psychological, physical, relational, and environmental levels.

The findings suggest that implementing music and music therapy in standard maternity care might improve the overall maternal experiences of women and tackle some key issues in the Irish maternity service raised by women in a recent study (Hannon et al., 2022). These issues include depersonalised care, lack of pain management options, low regards of women's preferences, and medicalised, chaotic, and noisy environment. The reported benefits in this study, in line with the evidence in the literature, support that appropriate use of music can enhance and normalise the hospital experience, distract women from the noise in the ward, reinforce personal identity and control, manage pain and anxiety during labour, and transform the overall birth experience (Cheung and McCaffrey, 2022; Corey et al., 2019; Horn et al., 2022; McCaffrey et al., 2020).

Limitations and recommendations
The authors were mindful that people who were motivated to take part in a music-related study were likely to have greater interest in music and thus the results might not represent the general population. Moreover, the demographics characteristics of the respondents were predominantly white, with postgraduate or higher education level, and in the higher household incomes group, although this is in line with previous studies which observed that white backgrounds, more educated, and more affluent people were more likely to respond to internet survey than people from minority background and lower levels of education (Couper et al., 2007). For future research to provide an unbiased representation of the national population and a more even distribution of different socioeconomic backgrounds, a mixture of both digital and paper forms of survey and a probability sampling instead of convenience sampling are recommended. This study intended to include the perspectives of partners which was under-investigated, however, the number of partner respondents were far lower than the women and it was not plausible to offer any comparison. The low participation of partners might be due to the lack of fora for partners/fathers in Ireland resulting in an imbalance in the recruitment for women and partners. Although snowball sampling was applied in the advertisement in this study, it might have bigger effectiveness if the invitation to share the survey with their partners were embedded in the end of survey message.        ","This study, the first of its kind in Ireland, explores the experiences of women and partners using music during pregnancy and their perspectives on perinatal music therapy. The findings underscore the positive role of music in various aspects of pregnancy, including mental health, family bonding, coping with distress, hospital experiences, labor, and challenging life situations. However, a small proportion of participants reported negative effects, emphasizing the importance of guidance on appropriate music use during pregnancy. The study highlights the need for evidence-based guidance and music-based perinatal programs to support maternal, infant, and family wellbeing. Integrating music and music therapy into standard maternity care could enhance overall maternal experiences and address existing issues in the Irish maternity service."
"Introduction
Systematic reviews are considered among the best available sources of research evidence and are increasingly relied on to inform decision-making [1]. The past 40 years have seen increasingly rapid methodological advances in the field of systematic reviews and research synthesis. Initial developments mainly focused on meta-analysis for addressing questions on the effectiveness of interventions, and the emphasis was on randomized controlled trials [2], [3]. Since the early 2000s, researchers have shown a growing interest in systematic mixed studies reviews, which combine quantitative, qualitative, and mixed methods studies to address other types of review questions concerned with, for instance, the acceptability of an intervention, participants’ satisfaction, or barriers to implementation (see Supplementary File 1). Systematic mixed studies reviews are particularly useful for providing in-depth answers to complex clinical problems and practical concerns. Several challenges, however, are encountered in these reviews because of the heterogeneity of included study designs. One of these challenges pertains to the critical appraisal of included studies.

Critical appraisal consists in a systematic and careful examination of studies to ensure they are trustworthy, valid, and reliable [4], [5]. It is an essential step in systematic reviews to ensure that their recommendations and conclusions reflect the quality of the evidence reviewed [6]. Since reviewers’ judgment of a same study can vary greatly, critical appraisal tools have been developed to help reviewers appraise study quality in a more consistent, transparent, and reproducible way [7], [8], [9]. A critical appraisal tool (also named quality assessment tool or risk of bias tool) is a scale or checklist in which a list of criteria/domains is suggested to appraise the quality of a study. Extant reviews of critical appraisal tools have identified over 500 tools (see Supplementary File 1). Most of these tools are specific to a particular research design or method. It is, thus, complex and time consuming to conduct systematic mixed studies reviews as reviewers must search for and learn how to use several different tools to complete the critical appraisal of the qualitative, quantitative, and/or mixed methods studies included in each review.

To address the challenge of critical appraisal in systematic mixed studies reviews, a unique tool for assessing the quality of different study designs was developed: the Mixed Methods Appraisal Tool (MMAT) [10]. The MMAT was first published in 2009 and has five sets of criteria for: (a) qualitative (such as case study and grounded theory), (b) randomized controlled trials, (c) nonrandomized (such as cohort studies and case-control studies), (d) quantitative descriptive (such as surveys and case series), and (e) mixed methods studies. When appraising mixed methods studies, three sets of criteria are assessed in no particular order: (a) the qualitative set, (b) a quantitative set (either randomized controlled, nonrandomized or quantitative descriptive studies), and (c) the mixed methods set. In doing so, the MMAT acknowledges the methodological distinctive characteristics specific to each component used in mixed methods studies (i.e., qualitative, quantitative, and mixed methods) [11].

Previous studies on the interrater reliability of the MMAT reported that agreement scores ranged from poor to perfect [12], [13]. This suggests the need for clarification of some criteria in the MMAT, particularly those related to qualitative and nonrandomized studies, for which lower agreement was observed. In addition, in interviews conducted with MMAT users to explore their views and experiences of the MMAT, concerns were raised about whether the tool included enough criteria to judge the quality of studies and criteria that were difficult to judge, in particular the criteria for qualitative and mixed methods studies [14]. This suggests a need to improve the content validity of the MMAT. The content validity of an assessment tool is defined as the degree to which criteria are relevant to and representative of their targeted construct [15]. A conceptual framework on the quality appraisal in systematic mixed studies reviews was developed in which three dimensions of quality were presented: reporting, conceptual, and methodological [16]. Reporting quality relates to the transparency, accuracy, and completeness of the information provided in a paper. Conceptual quality concerns the insight that can be gained about the phenomenon of interest. The methodological quality concerns the validity or trustworthiness of a study and is related to the methodology and methods used and how biases were minimized. In the MMAT, the targeted construct is the methodological quality of studies appraised in systematic mixed studies reviews.

Currently, the existing literature on critical appraisal has focused, for the most part, on randomized controlled trials, cohort studies, and/or case-control studies, and several validated tools can be found for these study designs. This literature will inform the criteria on randomized controlled trials and nonrandomized studies to revise in the MMAT. However, for other designs, such as qualitative, survey, and mixed methods, critical appraisal is more challenging because validated tools are rare and there is no clear consensus on how their quality assessment should be performed [17], [18], [19].

The objective of this study was to improve the content validity of the MMAT by identifying the most relevant methodological criteria for appraising the quality of qualitative, survey, and mixed methods studies. This study focused on these three categories of studies because of the scarcity of literature and lack of consensus.     ","
This study aimed to enhance the content validity of the Mixed Methods Appraisal Tool (MMAT), which is used for critical appraisal in systematic mixed studies reviews. The MMAT is designed to assess the quality of various study designs, including qualitative, survey, and mixed methods studies. The study sought to identify the most relevant methodological criteria for appraising the quality of these types of studies, addressing the challenges posed by the scarcity of literature and lack of consensus in critical appraisal for these designs."
"Introduction
Inspection is defined as a deliberate, in-depth, exacting process that requires more than mere looking or scanning (See 2012). Drury and Prabhu (1992) point out precision, depth, and validity are critical elements of the definition. Inspection processes require a large amount of mental processing, concentration, and information transmission, along with extensive use of both short-term and long-term memory (Gallwey 1982).

Eye tracking studies help to analyze the human visual activities. An eye-tracker is a device for measuring eye positions and eye movement (Jacob and Karn 2003). There are several applications of eye-tracking technologies such as, web usability, advertising, sponsorship, package design, and automotive engineering. In general, commercial eye-tracking studies focus on a sample of consumers and the eye-tracker is used to record the activity of the eye. Michalski and Grobelny (2016) present results of the eye-tracking data for box package designs. Michalski (2017) analysis digital control panels in terms of effectiveness and efficiency. Ozkan and Ulutas (2017a) use eye-tracking to assess knowledge and behavior of medicine information leaflet. Ozkan and Ulutas (2017b) provide results for evaluation of medicine leaflets on screen. Mobile eye-trackers can be used in manufacturing environments such as introduced by Ozkan and Ulutas (2016) that utilize data as an indicator of cognitive workload for forklift drivers. Ulutas and Ozkan (2017a) compare fixation data from expert and novice operators conducting visual control activities for ceramic tile inspection. Apart from manufacturing environments, tower crane operator’s eye tracking data to assess their performance is a pioneering application in construction sites (Ulutas and Ozkan 2017b).

Khasawneh et al. (2003) attract attention to the inspection task during quality control, particularly the search portion and use of eye-tracking technology. See (2015) provides the first empirical data to address the reliability of visual inspection for precision manufactured parts. In a recent study, See et al. (2017) summarize the factors influencing inspection performance and suggest to explore new research areas in terms of visual inspection by considering automated inspection. Gramopadhye et al. (1997) focus on importance of visual inspection and the principles of effective training. Speed (2015) summarizes the issues associated with quantifying expert, domain-specific visual search behavior in operationally realistic environments.

By examining a series of fixations and saccades it is possible to generate information about the attention shifting process that accompanies visual task executions. The fixation position depends on the location of the previous fixation. Ellis and Stark (1986) suggest that scan paths can be modeled by a stochastic first-order Markov process. Observable eye movements can be associated with overt attention while hidden states from HMM are coupled with shifting covert attention (Findlay and Gilchrist 2003). HMM tools allow for finding stochastic relations between observations and hidden states and, thus, are very useful in broadening the basic knowledge about attentional visual processes.

Two-states HMM that corresponds to covert attention (local and global) registered during visual analysis of printed advertisements saccades’ lengths are illustrated by Liechty et al. (2003). Chuk et al. (2014) identify two specific attention patterns (holistic and analytic) for the analysis of the face recognition task. During textual information search, Simola et al. (2008) HMM scan paths investigation provide evidence for existing three consecutive hidden states (scanning, reading, and the answer). Grobelny and Michalski (2016) estimate four HMMs with three hidden states for the digital control panels examined.

One of the applications of HMMs in the industrial management context is concerned with fall detection and localization of the operator. Kianoush et al. (2015) use HMMs to monitor various worker’s postures and detect a fall event by analyzing the changes in the radio-frequency signal quality.

Given more and more accessible mobile eye-trackers that are becoming increasingly accurate, a more ecological approach is started being more appreciated in psychology of human visual behavior (e.g., Tatler et al. 2011). Lukander et al. (2017) describe a number of further studies in this field. They review eye-tracking experiments where visual behavior is recorded during everyday activities outside research laboratories. One of the directions in this trend focuses on providing classifications and models based on eye-tracking data. For example, Greene et al. (2012) use a linear discriminant classifier to verify if the complex mental states to be inferred from eye tracking data as it was suggested by Yarbus (1967) whereas Coutrot et al. (2018) provide a method for scan path modeling and classification using variational HMMs and discriminant analysis. Similar methods, also involving HMMs are also employed by Kit and Sullivan (2016) for naturalistic eye movement behavior, while an interesting and comprehensive review and comparative analysis is provided by Boisvert and Bruce (2016).

Though a number of papers recently have been published that involve HMMs in eye-tracking data analysis, most of them focus on classification problem. Moreover, studies on how these models can be used in work environment analyses are very scarce. Among the few research in this area, Sodergren et al. (2010) utilize data of subjects using eye-tracker when performing natural orifice translumenal endoscopic surgery. Unfortunately, HMMs are only used for profiling subjects and the authors did not include any substantial analysis of participants’ visual attentional behavior. Another possible application of employing HMMs in the industrial environment may be related to automatic face recognition. A number of studies published in this domain are rather concerned with improving the effectiveness of this method in general (e.g., Chuk et al. 2014), than to examine if and how it might be useful in the industrial environment.

Based on the accessible literature, it can be said that data obtained by use of eye-tracking technologies in real life manufacturing environments are not analyzed by use of HMM. Therefore, this study focuses on the visual activity of quality inspection operator tasks. Basic research question is defined as the qualitative differences between subjects’ visual activities and the analyses are carried out in the HMM perspective. Second section summarizes the basics of HMM. Following section explains the control panel experiment. Then, the outcomes of the HMM simulation results are discussed and the paper is concluded with directions for future studies.      ","This study explores the application of Hidden Markov Models (HMMs) in analyzing visual activities during quality inspection tasks in a manufacturing environment. Inspection is a meticulous process that demands deep concentration and information processing. Eye-tracking technology is used to record eye movements and analyze the attention-shifting process during visual tasks. HMMs are employed to model the patterns of eye movements and hidden states of attention. While previous research has applied HMMs to various domains, their use in industrial manufacturing environments is limited. This study aims to fill this gap and provide insights into operators' visual behaviors during quality inspections.





"
"Introduction
Cancer is a negative event, and its occurrence may negatively affect patients and their families, in terms of economic, social, psychological and other aspects (Garlo et al., 2010; McPherson et al., 2007b; Ullrich et al., 2017). In the past, although some scholars have pointed out that patients have felt a sense of burden toward others (Cohen-Mansfield et al., 1992; Gilbar, 1994), self-perceived burden (SPB), as an emerging research concept, was first formally proposed by Cousineau et al. in a study on hemodialysis patients in 2003 (Cousineau et al., 2003). The authors in the latter report pointed out that in the process of caring, patients generally have concerns about the impact of their illness on their caregivers, causing physical, emotional, economic, and social burden to them, and then producing a number of negative psychological feelings, collectively called SPB (Cousineau et al., 2003). Based on phenomenological interviews with patients with advanced cancer, McPherson et al. further held the view that SPB is a transference worry arising from an individual’s disease and care needs that affect others, leading to negative experiences such as guilt, depression, pain, a sense of burden, and a reduced sense of self (McPherson et al., 2007b). In conjunction with the above, SPB in this review was defined as a negative experience arising from an individual’s illness and care needs affecting others, which can lead to adverse physical and psychological effects on the patient themselves and impact on subsequent treatment decisions (Cousineau et al., 2003; McPherson et al., 2007b).

According to the Cognitive Stress Theory (Folkman, 1984; Pitceathly and Maguire, 2003), stress has a special relationship between people and their environment. Individuals determine the meaning of a stressful event through a process of primary and secondary appraisals (Folkman, 1984). The patients could identify the cancer as a kind of stressful event through primary appraisal. On the basis of primary appraisals, cancer patients evaluate the available resources they have to cope with the stressful event during the process of secondary appraisals (Folkman, 1984). After an appraisal evaluation, SPB is one of the outputs of cancer patients at an emotional level. Both primary appraisal and secondary appraisal are inevitably affected by personal beliefs, experience, social resources and other factors. Patients’ SPB builds on their own perceptions of cancer as a stressor, so the factors related to SPB are mostly patient-related. Further, these factors can be grouped into three aspects, including physiological/disease ones, psychological ones and social factors (Cousineau et al., 2003; Tian et al., 2011).

To better understand patients’ SPB, McPherson et al. proposed that a patient’s SPB can be understood from a social-psychological perspective through the Equity Theory (McPherson et al., 2007b). The Equity Theory assumes that individuals strive to maintain a balance between benefits (including obtaining assistance and support) and dedications (including offering assistance and support) (Walster et al., 1973). When imbalance occurs, it has a negative impact on both patients and their caregivers, potentially leading to the emergence of SPB in patients. The reason for the generation of SPB is intuitively reflected in the fact that the patient is cared for by another person, i.e., family caregiver. The care provided by the caregiver is perceived by the patient as increasing the caregiver’s burden, promoting the possibility of the patient developing SPB as a result. Whether from the perspective of Cognitive Stress Theory or Equity Theory, SPB involves not only cancer patients, but also their caregivers who inevitably interact with patients (Kim et al., 2008). Some studies have shown that among relational traits, patients’ SPB is associated with greater caregiver burden (Beattie et al., 2017; Kuo et al., 2018), although this correlation is only weak to moderate. In addition, the caregiver type (for example, children, spouses, or parents) was also associated with patients’ SPB (Oeki et al., 2012). However, few studies have comprehensively investigated associations of caregiver-related factors with patients’ SPB (Gauthier et al., 2007; Kowal et al., 2012; McPherson et al., 2007). To better understand SPB, caregiver-related factors should also be considered.

To present the process of developing SPB more clearly through Cognitive Stress Theory and Equity Theory, we undertook a process which is summarized in Fig. 1. Cancer can be directly considered as a stressor, identified and evaluated in the primary and secondary appraisal by patients, with different outputs, depending on the individual’s different cognitive and coping abilities. SPB occurs as a negative result that may be one kind of an output. At the same time, cancer leads to patients’ care need that may drive an unequal relationship between patients and their caregivers. The imbalance between them can be another stressor, prompting cognitive recognition by patients, which can potentially lead to SPB.         ","
Self-perceived burden (SPB) is a concept emerging in the context of cancer care, referring to the negative experiences and feelings that cancer patients have about the impact of their illness and care needs on others, leading to adverse physical and psychological effects. This review explores the factors related to SPB in cancer patients, including physiological, psychological, and social factors. It also discusses how SPB can be understood through Cognitive Stress Theory and Equity Theory, highlighting the role of caregiver-related factors in patients' SPB. Understanding SPB is essential for improving the quality of cancer care and support for both patients and their caregivers."
"Introduction
Dementia is a global public health issue, with the healthcare sector calling for evidence-based approaches to enable people living with dementia (PwD) to live at home wherever possible.1 Family caregivers provide vital community care for PwD; however, behavioural and psychological symptoms of dementia (BPSD), such as agitation, depression, apathy, and aggression, can override caregivers’ capacity to cope, increasing their risk of developing physical or psychological illnesses.2 With the escalating lifetime costs of care, there is an urgent need to implement affordable, accessible, and effective non-pharmacological approaches to BPSD management that can be delivered by caregivers. Clinic-based caregiver programs that adopt cognitive-behavioural or psychoeducational interventions are ineffective in managing BPSD and caregiver wellbeing because of low attendance at training sessions.3 It is yet to be determined whether home-based caregiver training programs have higher attendance and result in better management of BPSD.

Music interventions provided by qualified music therapists reduce the severity of BPSD and associated distress experienced by caregivers,4,5 including clinically significant effects (Cohen's = 2.32).4 Suggested mechanisms for the positive effects of music in dementia care include activation of neuroplastic and neurochemical processes, auditory-motor coupling, neural entrainment, arousal-mood pathways, and autobiographical and implicit memory.6 A preliminary study of family caregivers trained in targeted music use suggested the interventions were feasible.7 However, it has yet to be determined whether family caregivers implementing music interventions in the home context can reduce BPSD. Such reductions in BPSD may have flow on effects such as: enabling PwD to live at home longer, improving life and relationship quality for both caregiver and PwD, and may be a cost-effective approach to support PwD to remain living in their home. Home-based music programs might prevent or delay care home or hospital admissions.

HOMESIDE is a translation of the research evidence for music therapy in a residential aged care context to a home-care context, and instead of music interventions being directly delivered by qualified therapists, caregivers provide therapy-informed music interventions, following training from qualified therapists.8,9 We asked, whether caregiver-delivered music interventions decrease BPSD after 90 days in dementia patients, in comparison to standard care (UC). In addition, we assessed the effects of caregiver-delivered music on depression and quality of life of the PwD, as well as caregiver distress derived from BPSD, depression, resilience, sense of caregiver competence, and quality of life and caregiver-PwD relationship quality (secondary outcomes). We also examined whether an active control (reading intervention delivered by caregivers) influenced the same primary and secondary outcomes. Reading was chosen as an active control intervention due to preliminary indications of its positive impact on BPSD.10          ","Dementia is a global public health concern, with family caregivers playing a crucial role in providing care to people living with dementia (PwD). Behavioral and psychological symptoms of dementia (BPSD) can strain caregivers and impact the well-being of both caregivers and PwD. This study investigates the effectiveness of caregiver-delivered music interventions in reducing BPSD in dementia patients compared to standard care. Secondary outcomes include the effects on depression, quality of life, caregiver distress, and caregiver-PwD relationship quality. An active control intervention involving reading is also examined for its impact on similar outcomes. This research aims to provide evidence for affordable and accessible non-pharmacological approaches to BPSD management in home-based care settings."
"Background
Synthesis of multiple randomized controlled trials (RCTs) in a systematic review can summarize the effects of individual outcomes and provide numerical answers about the effectiveness of interventions. Filtering of searches is time consuming, and no single method fulfills the principal requirements of speed with accuracy. Automation of systematic reviews is driven by a necessity to expedite the availability of current best evidence for policy and clinical decision-making.

We developed Rayyan (http://rayyan.qcri.org), a free web and mobile app, that helps expedite the initial screening of abstracts and titles using a process of semi-automation while incorporating a high level of usability. For the beta testing phase, we used two published Cochrane reviews in which included studies had been selected manually. Their searches, with 1030 records and 273 records, were uploaded to Rayyan. Different features of Rayyan were tested using these two reviews. We also conducted a survey of Rayyan’s users and collected feedback through a built-in feature.

Results
Pilot testing of Rayyan focused on usability, accuracy against manual methods, and the added value of the prediction feature. The “taster” review (273 records) allowed a quick overview of Rayyan for early comments on usability. The second review (1030 records) required several iterations to identify the previously identified 11 trials. The “suggestions” and “hints,” based on the “prediction model,” appeared as testing progressed beyond five included studies. Post rollout user experiences and a reflexive response by the developers enabled real-time modifications and improvements. The survey respondents reported 40% average time savings when using Rayyan compared to others tools, with 34% of the respondents reporting more than 50% time savings. In addition, around 75% of the respondents mentioned that screening and labeling studies as well as collaborating on reviews to be the two most important features of Rayyan.

As of November 2016, Rayyan users exceed 2000 from over 60 countries conducting hundreds of reviews totaling more than 1.6M citations. Feedback from users, obtained mostly through the app web site and a recent survey, has highlighted the ease in exploration of searches, the time saved, and simplicity in sharing and comparing include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.           ","The development and testing of Rayyan, a web and mobile app designed to expedite the initial screening of abstracts and titles in the context of systematic reviews, are discussed in this background section. The app was tested for usability and accuracy against manual methods using two published Cochrane reviews as test cases. Rayyan's features, including its prediction model, were evaluated, and user feedback highlighted its ability to save time in the screening process and facilitate collaboration among reviewers. As of November 2016, Rayyan had over 2000 users from 60 countries conducting numerous reviews with more than 1.6 million citations."
"The practice of evidence-based medicine (EBM) involves applying the best and most up-to-date evidence, in the form of published literature, to patient care decision making.1,2 While the original vision of EBM appeared to require physicians directly searching the primary literature for evidence applicable to their patients, the modern conception of EBM relies heavily on distillations of the primarily literature in the form of systematic reviews (also called evidence reports),3,4 such as those produced by the Cochrane Collaboration and the Evidence-based Practice Centers (EPCs) of the Agency for Healthcare Research and Quality (AHRQ).5 AHRQ reports are available to the public (http://www.ahrq.gov/clinic/epcindex.htm/) and abstracts of Cochrane reviews are also available (http://www.cochrane.org/reviews/).

The Department of Medical Informatics and Clinical Epidemiology at the Oregon Health and Science University is home to one of the AHRQ EPCs (http://www.ohsu.edu/epc/). The EPC has focused on providing comprehensive literature reviews comparing classes of drugs used for treating specific conditions. To date, the Oregon EPC, Southern California EPC, and Research Triangle Institute/University of North Carolina (RTI/UNC) EPC have completed and published 15 evidence reports, evaluating the efficacy of medications in drug classes such as oral opioids, skeletal muscle relaxants, and estrogen replacement.6–8

Making these evidence reports comprehensive and keeping them up to date is a labor-intensive process.9,10 Like any systematic review, those of drug classes identify thousands of articles that must be located, triaged, reviewed, and summarized. Potentially relevant articles are located using an iteratively refined query-based search of biomedical electronic databases, such as MEDLINE and EMBASE. These queries are developed by starting with the optimized clinical queries proposed and studied by Haynes et al.11–13 and refined based on the experience and knowledge of the EPC staff. For the 15 systematic drug reviews mentioned above, the staff created queries for randomized controlled trials by combining terms for health conditions and interventions with the Haynes et al. research methodology filters for therapy.

Articles are then triaged in a two-step process. First the abstract is reviewed, and, if the abstract meets the inclusion criteria, the entire article is read. If the full text article proves to meet the inclusion criteria, the evidence presented in the article is summarized and included in the EPC report. Advances in clinical evaluation and pharmacology require that EPC drug reviews be updated on a periodic basis. This inevitably leads to the workload of the center increasing over time as reviewers must both produce new reviews as well as monitor and update the old ones.

The process of creating these drug reviews is very methodical. Reviewers keep detailed records of their search methods, the articles for which they have reviewed the abstracts and read full text, and, finally, which articles include sufficient high-quality evidence to warrant inclusion in the systematic review. This process motivated our interest in using these data to train an automated classification system that would have the ability to predict which new articles were most likely to include evidence warranting inclusion in a review update. An automated classification system would function to triage (or filter) new articles that match the search criteria of the original study. This would be useful to the reviewers in several ways. First, by monitoring the number of new articles on a given topic containing high-quality evidence (as determined by the classification system), the reviewers would have a simple and clear indication when substantial new information exists on a topic and the report needs to be revised. Second, the classification system could decrease the number of articles that require manual review and therefore reduce one of the most time-consuming steps in preparing or updating a systematic review. Third, classifying the most likely documents to contain high-quality evidence can help reviewers prioritize which articles are read first and which are read only if there is sufficient time. This paper presents the investigators' application of a machine learning–based classification system to reduce the labor required and improve the efficiency of keeping drug reviews up to date.

We are unaware of any prior work that applies automated classification of literature for topic-specific evidence-based drug or therapy reviews similar to the work we present here. The closest research is the work of Aphinyanaphongs et al.,14 who have published work investigating the use of machine-learning algorithms to improve information retrieval of high-quality articles useful for evidence-based medicine in the nontopic-specific high-level categories of etiology, prognosis, diagnosis, and treatment. Their research focuses on improving performance over the clinical query filters first proposed by Haynes et al.,11–13 using all the articles published in ten journals from 1986 through 1991, and whether those articles were included in the ACP Journal Club as a gold standard.

There has been much more work in the related area of automated document classification to assist curator annotation of biomedical databases. Like the work of Aphinyanaphongs et al.,14 the goals of these tasks are to place articles into one of a few high-level, nontopic-specific categories. The results of these high-level automated tasks vary because the recall requirements are different and are difficult to compare to the topic-specific classification presented here. Dobrokhotov et al.15 used a combination of NLP and statistical classification techniques to achieve a recall of 0.4477 at a precision of 0.6716 for identifying articles containing information about human genetic diseases and polymorphisms, using a test set where 15% of the original articles were relevant. The TREC 2004 Genomics track included a task to identify articles containing information on mouse gene function for Gene Ontology (GO) annotation. With a utility function giving recall 20 times the importance of precision, the best results achieved were a normalized utility of 0.6512, and precision of 0.1579 at a recall of 0.8881, resulting in an F-measure of 0.2681.16       ","
The practice of evidence-based medicine (EBM) relies on applying the latest evidence from systematic reviews to inform patient care decisions. These reviews involve screening thousands of articles to identify those with relevant evidence. The Department of Medical Informatics and Clinical Epidemiology at Oregon Health and Science University is involved in creating and updating systematic reviews, especially regarding drug classes. This process is labor-intensive, motivating the development of an automated classification system to predict which new articles are likely to contain evidence for inclusion in review updates, improving efficiency. This paper presents their application of machine learning for this purpose, which is a novel approach in the field of evidence-based medicine."
"Statistical analysis
The statistical analysis was outlined in a detailed plan prior to database lock.11 Changes made post-unmasking are detailed in appendix p 2. A total of 495 dyads (165 per arm) were needed to detect an absolute mean difference of 3-points in the NPI-Q severity score between the music and UC arm at 90-days, assuming a conservative standard deviation (SD) of 7.5 points, no correlation between baseline and post-baseline measurements (conservative), and including 20% attrition (90% power, two-sided alpha 5%).

All available data was included according to the randomised assignment of the dyad (i.e. intention-to-treat). The NPI-Q severity score of the PwD was analysed using a likelihood-based longitudinal data analysis model24 to obtain an estimate of the intervention effect (i.e., absolute mean difference between arms in the change from baseline to 90-days) irrespective of the dyad's adherence or experienced intercurrent events, except for death, in which case the worst possible score was assigned to the subsequent visit. The model included site and used an unstructured variance-covariance among the repeated measurements. In an additional analysis, the pre-specified potential prognostic variables dementia type, gender of PwD, and caregiver's relationship with PwD were added to the primary model. A further analysis including all randomised dyads provided an estimate of the intervention effect among those dyads who adhered to their randomised intervention using a complier average causal effect (CACE) analysis.25 Adherence (yes/no) was derived for the music and reading groups using diary and phone call data. As the primary model provides valid inference under the missing-at-random assumption, multiple imputation was performed before conducting the CACE analysis. A post-hoc analysis based on the delta-adjustment method to assess sensitivity to NPI-Q data missing not at random was added. Continuous secondary outcomes were analysed using a model similar to the primary model of the primary outcome. Adverse events were summarised by actual intervention group. Perceived effects (positive, neutral/unsure, or negative) and durations of music and reading intervention sessions recorded in the participant diaries were summarised by intervention group, country, and type of activity as a post-hoc analysis.

Point estimates and two-sided 95% confidence intervals are provided alongside two-sided P values. The comparison of music vs UC and reading vs UC occurred at the 5% level of significance. The comparison of music with reading was planned only if music vs UC was statistically significant (i.e., P value <0.05). No adjustment for multiple testing was planned. Eight pre-specified subgroup analyses were performed for the NPI-Q severity score of the PwD using baseline characteristics: gender of the PwD, gender of the caregiver, dementia type, dementia severity, time of onset of dementia, caregiver's relationship to PwD, country, length of time living with dementia (continuous) and four post-hoc subgroup analyses consisting of current use of music and reading in daily life (PwD and caregiver) at baseline. Analyses were performed in Stata/SE, version 16.1 (Stata Corporation, College Station, TX, USA).

The trial was overseen by an independent data safety and monitoring board, no interim analyses were conducted.

Role of the funding source
The study was undertaken independently of any input from funding bodies. Funders have had no role in the study design; in the collection, analysis, and interpretation of data; in the writing of the report; and in the decision to submit the paper for publication. Public and Participant Involvement (PPI) was embedded throughout the study with an overarching international committee and active PPI committees for public engagement for each country, including people with lived experience. All authors had access to the data and contributed to interpreting the data, revising the manuscript, and approving the final version of the manuscript. All authors had final responsibility for the decision to submit for publication.                  ","The statistical analysis plan for the study was detailed in advance, with adjustments documented post-unmasking. A total of 495 dyads (165 per group) were required to detect a 3-point mean difference in NPI-Q severity scores at 90 days. The analysis included all available data based on the randomized assignment, employing a likelihood-based longitudinal model. Subgroup and sensitivity analyses were performed. The trial was overseen by an independent data safety and monitoring board, with no interim analyses conducted. The study was conducted independently of funding body influence, and all authors had access to and interpreted the data. Public and Participant Involvement (PPI) was integrated into the study."
"Introduction
Mental injury is a severe health issue requiring treatment to enable patients with mental illness to live better. People may look sound but are mentally injured, suffering health challenges that may eventually lead to physical damage. Typically, mental illness adversely affects a person's mood, thinking, behaviour and overall mental state in their day-to-day life (Atwoli et al., 2015). The World Health Organization (2019) says that mental health generally entails perception, emotions, and a combination of a person's thoughts. Exposure to potentially traumatic events is one of the causes of mental injury. Do et al. (2019) note that exposure to trauma is one of the leading causes of mental injury. Atwoli et al. (2015) opine that trauma exposure often occurs in less developed countries than in developed nations. Fitch et al. (2018) attributed the increased instances of potentially traumatic events in developing countries to various factors like conflicts, lower levels of control over daily life, unstable political situations, and disparities in living conditions among the citizens. When people are exposed to traumatic events, it leads to Post Traumatic Stress Disorder (PTSD).

PTSD symptoms can be defined as severe mental disorders that people experience due to exposure to frightening events. For example, the events that could trigger PTSD symptoms could be natural such as earthquakes, an accident such as motor accidents, rape, terror attack, war or conflict, and kidnapping, among other unfortunate incidences. Bisson et al. (2015) define PTSD as a mental disorder caused by exposure to an exceptionally traumatising event or series of events. According to Chu et al. (2013) continuous exposure to frightening information could result in an individual's development of PTSD symptoms. A good example is a person who may be continuously exposed to media messages about violence within their neighbourhood. Such accumulated exposure will result in internal tension and gradually lead to PTSD symptoms. Also, the National Health Service of England (2018) notes that exposure to a single severe event leads to PTSD symptoms; examples include kidnapping, and a terror attack, among others.

As a mental health disorder, PTSD has serious negative consequences for those suffering from it. For example, those who suffer from PTSD lack concentration at work or focus. They live in perpetual fear and trauma due to the continuous recall of such events that caused them trauma, negatively impacting productivity. Pacella et al. (2013) conducted a systematic review to

ascertain the impact of PTSD on physical health. The researchers examined 62 studies related to the effect of PTSD on physical fitness and quality of life. Their result showed that PTSD has a negative impact on the physical health of patients, their quality of life, and their cardio-respiratory and gastrointestinal health. Later studies (Brudey et al., 2015; Magruder et al., 2016; Olff et al., 2020) also reported that PTSD has a severe negative consequence on the health and the general welling of patients.

Based on the above background, this study aims to examine the impact of art and dance therapies delivered through interactive media on reducing PTSD symptoms among school children with abduction experiences.     ","This study focuses on investigating the effectiveness of art and dance therapies delivered through interactive media in reducing PTSD symptoms in school children who have experienced abduction. PTSD, resulting from exposure to traumatic events, has severe consequences on mental health and well-being, affecting concentration and quality of life. The research aims to assess the positive impact of these therapies in mitigating PTSD symptoms among this vulnerable group of children.





"
"Abstract
Although loving relationships form part of everyday life, the contribution of personality to the dynamics of these relationships remains relatively unexamined. Research has yet to demonstrate how individuals high in vulnerable Dark Triad (DT) traits behave in such relationships. Across three studies, we compare capacity for love and love styles in vulnerable DT individuals and those high in primary psychopathy and grandiose narcissism. In study 1 (N = 128), reduced capacity for love explained relationships between primary psychopathy, and love styles of agape (selfless), eros (passionate), pragma (logical) and storge (friendship), although no effects were found for secondary psychopathy or vulnerable narcissism. In study 2 (N = 274), contrasting findings emerged in that reduced capacity for love partially mediated relationships between borderline personality disorder traits, agape and eros, only, yet indrirect effects were not observed for primary psychopathy, secondary psychopathy and associated love styles. In study 3 (N = 197), reduced capacity for love partially explained the relationship between vulnerable narcissism and agape, eros, ludus and storge, but not those between grandiose narcissism and related love styles. Findings demonstrate how vulnerable DT traits differ across psychological and behavioural domains compared to primary psychopathy and grandiose narcissism.            ","
This series of three studies examines the role of personality traits, specifically vulnerable Dark Triad (DT) traits, in romantic relationships. The studies compare individuals high in vulnerable DT traits with those high in primary psychopathy and grandiose narcissism, assessing their capacity for love and love styles. The findings reveal that reduced capacity for love mediates the relationship between vulnerable DT traits and specific love styles, highlighting differences between vulnerable DT traits, primary psychopathy, and grandiose narcissism in the context of romantic dynamics."